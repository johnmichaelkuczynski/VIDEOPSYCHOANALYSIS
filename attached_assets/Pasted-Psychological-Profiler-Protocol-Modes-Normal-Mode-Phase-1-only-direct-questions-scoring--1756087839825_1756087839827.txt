Psychological Profiler Protocol
Modes

Normal Mode = Phase 1 only (direct questions + scoring).

Comprehensive Mode = Phases 1–4, with pushback, Walmart metric, sniper amendment analogs.

Phase 1 (Normal Protocol)
Questions for the LLM

Ask only these questions in connection with the text (or responses). Require answers plus a score out of 100:

Does the text reveal a stable, coherent self-concept, or is the self fragmented/contradictory?

Is there evidence of ego strength (resilience, capacity to tolerate conflict/ambiguity), or does the psyche rely on brittle defenses?

Are defenses primarily mature (sublimation, humor, anticipation), neurotic (intellectualization, repression), or primitive (splitting, denial, projection)?

Does the writing show integration of affect and thought, or are emotions split off / overly intellectualized?

Is the author’s stance defensive/avoidant or direct/engaged?

Does the psyche appear narcissistically organized (grandiosity, fragile self-esteem, hunger for validation), or not?

Are desires/drives expressed openly, displaced, or repressed?

Does the voice suggest internal conflict (superego vs. id, competing identifications), or monolithic certainty?

Is there evidence of object constancy (capacity to sustain nuanced view of others) or splitting (others seen as all-good/all-bad)?

Is aggression integrated (channeled productively) or dissociated/projected?

Is the author capable of irony/self-reflection, or trapped in compulsive earnestness / defensiveness?

Does the text suggest psychological growth potential (openness, curiosity, capacity to metabolize experience) or rigidity?

Is the discourse paranoid / persecutory (others as threats, conspiracies) or reality-based?

Does the tone reflect authentic engagement with reality, or phony simulation of depth?

Is the psyche resilient under stress, or fragile / evasive?

Is there evidence of compulsion or repetition (obsessional returns to the same themes), or flexible progression?

Does the author show capacity for intimacy / genuine connection, or only instrumental/defended relations?

Is shame/guilt worked through constructively or disavowed/projected?

Explicit Instructions to LLM

Answer these questions in connection with this text.

Also give a score out of 100.

A score of N/100 means (100–N)/100 outperform the subject with respect to the psychological capacity defined by the question.

You are not grading. You are answering questions.

Do not default to diagnostic checklists; describe configuration of psyche.

Do not conflate verbal confidence with psychological strength.

Summarize the text and categorize the psychological presentation (e.g., narcissistic, depressive, obsessional, resilient, fragmented).

Evaluate relative to the general population, not only “advanced” or “pathological” groups.

Do not penalize honesty, boldness, or extreme statements if they indicate integration rather than breakdown.

Phase 2 (Pushback Protocol)

If score < 95/100:

Restate: Your position is that (100–N)/100 have superior psychological functioning in this respect. Are you sure?

Require articulation: What concrete psychological strengths do those (100–N) people have that this author lacks?

Re-ask Phase 1 questions de novo.

Phase 3 (Walmart Metric Enforcement)

Enforce: If you claim 20/100 Walmart patrons have more integrated ego strength than this author, provide concrete examples of how. If you can’t, revise.

Phase 4 (Final Validation)

Confirm before finalizing:

Was the subject penalized for unconventional affect or honesty? If yes → recalibrate.

Does the score reflect ego integration and authenticity, not mere social compliance?

Is the Walmart metric grounded in specific superiority, not vague hand-waving?

Addenda

Sniper Amendment (Psychological version)

Depth is a sniper shot, not a group therapy session. If the psyche is revealed starkly in a single flash, do not penalize for lack of “balance.”

Rating scale:

95–100 = authentic, integrated psyche, unignorable.

80–94 = strong but with observable defenses / conflict.

<80 = rigidity, fragmentation, or dissimulation.

Pushback Amendment (Phase 2)

Require LLM to describe: What exact psychological resource do the outperformers possess (ego strength, affect regulation, capacity for intimacy)?

Ask: Is defensiveness a flaw, or a realistic adaptation?

Final Validation Amendment (Phase 4)

Ensure no penalizing of unconventional personalities (e.g., depressive honesty, ironic self-awareness).

Reconfirm Walmart metric is empirically grounded.

TWO INTELLIGENCE PROTOCOLS

NORMAL AND COMPREHENSIVE 
THE COMPREHENSIVE IS FOUR PHASES LONG; THESE PHASES ARE DESCRIBED BELOW. THE NORMAL IS SIMPLY PHASE 1 OF THOSE PHASES. 


NORMAL (NON-COMPREHENSIVE) COGNITIVE PROTOCOL 

YOU SEND THE LLM THE FOLLOWING QUESTIONS: 

IS IT INSIGHTFUL? 
DOES IT DEVELOP POINTS? (OR, IF IT IS A SHORT EXCERPT, IS THERE EVIDENCE THAT IT WOULD DEVELOP POINTS IF EXTENDED)? 
IS THE ORGANIZATION MERELY SEQUENTIAL (JUST ONE POINT AFTER ANOTHER, LITTLE OR NO LOGICAL SCAFFOLDING)? OR ARE THE IDEAS ARRANGED, NOT JUST SEQUENTIALLY
BUT HIERARCHICALLY? 
IF THE POINTS IT MAKES ARE NOT INSIGHTFUL, DOES IT OPERATE SKILLFULLY WITH CANONS OF LOGIC/REASONING. 
ARE THE POINTS CLICHES? OR ARE THEY "FRESH"? 
DOES IT USE TECHNICAL JARGON TO OBFUSCATE OR TO RENDER MORE PRECISE? 
IS IT ORGANIC? DO POINTS DEVELOP IN AN ORGANIC, NATURAL WAY? DO THEY 'UNFOLD'? OR ARE THEY FORCED AND ARTIFICIAL? 
DOES IT OPEN UP NEW DOMAINS? OR, ON THE CONTRARY, DOES IT SHUT OFF INQUIRY (BY CONDITIONALIZING FURTHER DISCUSSION OF THE MATTERS ON ACCEPTANCE OF 
ITS INTERNAL AND POSSIBLY VERY FAULTY LOGIC)? 
IS IT  ACTUALLY INTELLIGENT OR JUST THE WORK OF SOMEBODY WHO, JUDGING BY TEH SUBJECT-MATTER, IS PRESUMED TO BE INTELLIGENT (BUT MAY NOT BE)? 
IS IT REAL OR IS IT PHONY? 
DO THE SENTENCES EXHIBIT COMPLEX AND COHERENT INTERNAL LOGIC? 
IS THE PASSAGE GOVERNED BY A STRONG CONCEPT? OR IS THE ONLY ORGANIZATION DRIVEN PURELY BY EXPOSITORY (AS OPPOSED TO EPISTEMIC) NORMS?
IS THERE SYSTEM-LEVEL CONTROL OVER IDEAS? IN OTHER WORDS, DOES THE AUTHOR SEEM TO RECALL WHAT HE SAID EARLIER AND TO BE IN A POSITION TO INTEGRATE IT INTO 
POINTS HE HAS MADE SINCE THEN? 
ARE THE POINTS 'REAL'? ARE THEY FRESH? OR IS SOME INSTITUTION OR SOME ACCEPTED VEIN OF PROPAGANDA OR ORTHODOXY JUST USING THE AUTHOR AS A MOUTH PIECE?
IS THE WRITING EVASIVE OR DIRECT? 
ARE THE STATEMENTS AMBIGUOUS? 
DOES THE PROGRESSION OF THE TEXT DEVELOP ACCORDING TO WHO SAID WHAT OR ACCORDING TO WHAT ENTAILS OR CONFIRMS WHAT? 
DOES THE AUTHOR USER OTHER AUTHORS  TO DEVELOP HIS IDEAS OR TO CLOAK HIS OWN LACK OF IDEAS? 

YOU TELL THE LLM TO ANSWER THOSE QUESTIONS. YOU SAY: ANSWER THESE QUESTIONS IN CONNECTION WITH THIS TEXT. YOU DON'T SAY: DETERMINE INTELLIGENCE OF TEXT.
YOU DO NOT SAY: DETERMINE INTELLIGENCE/COGENCY/ETC BY ANSWERING THESE QUESTIONS. YOU JUST SAY: ANSWER THESE QUESTIONS (AND ALSO GIVE A SCORE OUT OF 100). BUT THERE ARE SEVERAL QUALIFICATION.
AFTER YOU GIVE IT THE TEXT AND THE QUESTIONS, YOU SAY THE FOLLOWING: A SCORE OF N/100 (E.G. 73/100) MEANS THAT (100-N)/100 (E.G. 27/100) 
OUTPERFORM THE AUTHOR IN WITH RESPECT TO THE PARAMETER DEFINED BY THE QUESTION. YOU ALSO SAY: YOU ARE NOT GRADING; 
YOU ARE ANSWERING THESE QUESTIONS. YOU ALSO SAY: YOU DO NOT USE A RISK-AVERSE STANDARD; YOU DO NOT ATTEMPT TO BE DIPLOMATIC; YOU DO NOT ATTEMPT TO COMPLY WITH RISK-AVERSE, 
MEDIUM-RANGE IQ, ACADEMIC NORMS. YOU DO NOT MAKE ASSUMPTIONS ABOUT THE LEVEL OF THE PAPER; IT COULD BE A WORK OF THE HIGHEST EXCELENCE 
AND GENIUS, OR IT COULD BE THE WORK OF A MORON.
IF A WORK IS A WORK OF GENIUS, YOU SAY THAT, AND YOU SAY WHY; YOU DO NOT SHY AWAY FROM GIVING WHAT MIGHT CONVENTIONALLY BE REGARDED AS  
EXCESSIVELY "SUPERLATIVE"
SCORES; YOU GIVE IT THE SCORE IT DESERVES, NOT THE SCORE THAT A MIDWIT COMMITTEE WOULD SAY IT DESERVES. 
YOU TELLL THE LLM TO THINK VERY VERY VERY HARD ABOUT ITS ANSWERS; MAKE IT VERY CLEAR THAT IT IS NOT TO DEFAULT TO COOKBOOK, 
MIDWIT EVALUATION PROTOCOLS. 
BEAR IN MIND: THE LLM GOES INTO A DEFAULT WHEREBY WHENEVER THE AUTHOR USES A LOT OF JARGON OR REFERENCES 
A LOT OF 'AUTHORITIES' IT DISREGARDS THE ACTUAL SUBSTANCE (OR LACK THEREOF) OF THE PAPER. YOU HAVE TO EXPLICITLY SAY: 
"DO NOT GIVE CREDIT MERELY FOR USE OF JARGON OR FOR REFERENCING AUTHORITIES. FOCUS ON SUBSTANCE. ONLY GIVE POINTS FOR SCHOLARLY REFERENCES/JARGON
IF THEY UNAMBIGUOUSLY INCREASE SUBSTANCE." 

METAPOINT 1: THIS NOT A GRADING APP. YOU GRADE THE INTELLIGENCE OF WHAT YOU ARE GIVEN. IF YOU ARE GIVEN BRILLIANT FRAGMENT, YOU GIVE IT A HIGH SCORE. 
YOU ARE NOT GRADING ESSAYS. YOU ARE NOT LOOKING FOR COMPLETENESS (UNLESS THE TEXT YOIU ARE GIVEN IS CLEARLY SUCH THAT IT EVALUATING INTELLIGENCE 
COINCIDES WITH APPLYING A GRADING-BASED METRIC). YOU TELL THE LLM NOT TO 'GRADE'; THEIR JOB IS TO ANSWER THE QUESTIONS, PERIOD, AND TO DO SO ON THE BASIS
OF THE TEXT GIVEN, MAKING ZERO ASSUMPTIONS ABOUT WHETHER IT IS COMPLETE OR INCOMPLETE, OR FOR SCHOOL OR FOR SOME OTHER CONTEXT. 

METAPOINT 2: DO NOT OVERVALUE TURNS OF PHRASE. AN AUTHOR IS SPEAKING CONFIDENTLY IS NOT NECESSARILY "SHUTTING DOWN MODES OF INQUIRY". IN FACT, IT IS LIKELY 
TO BE THE OPPOSITE; BY PUTTING A CLEAR STAKE IN THE GROUND, HE IS PROBABLY OPENING THEM. ANOTHER EXAMPLE: CAUSAL SPEECH DOEDS NOT MEAN DISORGANIZED THOUGHTS. 
DON'T JUDGE A BOOK BY ITS COVER. 

METAPOINT 3: THE APP SHOULD ALWAYS (IN BOTH NORMAL AND COMPREHENSIVE MODE) START BY SUMMARIZING THKE TEXT AND ALSO CATEGORIZING IT. 

METAPOINT 4: THE APP SHOULD NOT CHANGE THE GRADING BASED ON THE CATEGORY OF THE TEXT: IF A TEXT IS CATEGORIZED AS 'ADVANCED SCHOLARSHIP', IT SHOULD 
STILL EVALUATE IT WITH RESPECT TO THE GENERAL POPULATION, NOT WITH RESPECT ONLY TO 'ADVANCED SCHOLARY WORKS.' 

METAPOINT 5: THIS IS NOT A GRADING APP. DO NOT PENALIZE BOLDNESS. DO NOT TAKE POINTS AWAY FOR INSIGHTS THAT, IF CORRECT, STAND ON THEIR OWN. 
GET RID OF THE IDEA THAT "ARGUMENTATION" IS WHAT MAKES SOMETHING SMART; IT ISN'T. WHAT MAKES SOMETHING SMART IS THAT IT IS SMART (INSIGHTFUL). PERIOD.

COMPREHENSIVE INTELLIGENCE PROTOCOL

PHASE 1: YOU SEND THE LLM THE FOLLOWING QUESTIONS: 

IS IT INSIGHTFUL? 
DOES IT DEVELOP POINTS? (OR, IF IT IS A SHORT EXCERPT, IS THERE EVIDENCE THAT IT WOULD DEVELOP POINTS IF EXTENDED)? 
IS THE ORGANIZATION MERELY SEQUENTIAL (JUST ONE POINT AFTER ANOTHER, LITTLE OR NO LOGICAL SCAFFOLDING)? OR ARE THE IDEAS ARRANGED, NOT JUST SEQUENTIALLY
BUT HIERARCHICALLY? 
IF THE POINTS IT MAKES ARE NOT INSIGHTFUL, DOES IT OPERATE SKILLFULLY WITH CANONS OF LOGIC/REASONING. 
ARE THE POINTS CLICHES? OR ARE THEY "FRESH"? 
DOES IT USE TECHNICAL JARGON TO OBFUSCATE OR TO RENDER MORE PRECISE? 
IS IT ORGANIC? DO POINTS DEVELOP IN AN ORGANIC, NATURAL WAY? DO THEY 'UNFOLD'? OR ARE THEY FORCED AND ARTIFICIAL? 
DOES IT OPEN UP NEW DOMAINS? OR, ON THE CONTRARY, DOES IT SHUT OFF INQUIRY (BY CONDITIONALIZING FURTHER DISCUSSION OF THE MATTERS ON ACCEPTANCE OF 
ITS INTERNAL AND POSSIBLY VERY FAULTY LOGIC)? 
IS IT  ACTUALLY INTELLIGENT OR JUST THE WORK OF SOMEBODY WHO, JUDGING BY TEH SUBJECT-MATTER, IS PRESUMED TO BE INTELLIGENT (BUT MAY NOT BE)? 
IS IT REAL OR IS IT PHONY? 
DO THE SENTENCES EXHIBIT COMPLEX AND COHERENT INTERNAL LOGIC? 
IS THE PASSAGE GOVERNED BY A STRONG CONCEPT? OR IS THE ONLY ORGANIZATION DRIVEN PURELY BY EXPOSITORY (AS OPPOSED TO EPISTEMIC) NORMS?
IS THERE SYSTEM-LEVEL CONTROL OVER IDEAS? IN OTHER WORDS, DOES THE AUTHOR SEEM TO RECALL WHAT HE SAID EARLIER AND TO BE IN A POSITION TO INTEGRATE IT INTO 
POINTS HE HAS MADE SINCE THEN? 
ARE THE POINTS 'REAL'? ARE THEY FRESH? OR IS SOME INSTITUTION OR SOME ACCEPTED VEIN OF PROPAGANDA OR ORTHODOXY JUST USING THE AUTHOR AS A MOUTH PIECE?
IS THE WRITING EVASIVE OR DIRECT? 
ARE THE STATEMENTS AMBIGUOUS? 
DOES THE PROGRESSION OF THE TEXT DEVELOP ACCORDING TO WHO SAID WHAT OR ACCORDING TO WHAT ENTAILS OR CONFIRMS WHAT? 
DOES THE AUTHOR USER OTHER AUTHORS  TO DEVELOP HIS IDEAS OR TO CLOAK HIS OWN LACK OF IDEAS? 

YOU TELL THE LLM TO ANSWER THOSE QUESTIONS. YOU SAY: ANSWER THESE QUESTIONS IN CONNECTION WITH THIS TEXT. YOU DON'T SAY: DETERMINE INTELLIGENCE OF TEXT.
YOU DO NOT SAY: DETERMINE INTELLIGENCE/COGENCY/ETC BY ANSWERING THESE QUESTIONS. YOU JUST SAY: ANSWER THESE QUESTIONS (AND ALSO GIVE A SCORE OUT OF 100). BUT THERE ARE SEVERAL QUALIFICATION.
AFTER YOU GIVE IT THE TEXT AND THE QUESTIONS, YOU SAY THE FOLLOWING: A SCORE OF N/100 (E.G. 73/100) MEANS THAT (100-N)/100 (E.G. 27/100) 
OUTPERFORM THE AUTHOR IN WITH RESPECT TO THE PARAMETER DEFINED BY THE QUESTION. YOU ALSO SAY: YOU ARE NOT GRADING; 
YOU ARE ANSWERING THESE QUESTIONS. YOU ALSO SAY: YOU DO NOT USE A RISK-AVERSE STANDARD; YOU DO NOT ATTEMPT TO BE DIPLOMATIC; YOU DO NOT ATTEMPT TO COMPLY WITH RISK-AVERSE, 
MEDIUM-RANGE IQ, ACADEMIC NORMS. YOU DO NOT MAKE ASSUMPTIONS ABOUT THE LEVEL OF THE PAPER; IT COULD BE A WORK OF THE HIGHEST EXCELENCE 
AND GENIUS, OR IT COULD BE THE WORK OF A MORON.
IF A WORK IS A WORK OF GENIUS, YOU SAY THAT, AND YOU SAY WHY; YOU DO NOT SHY AWAY FROM GIVING WHAT MIGHT CONVENTIONALLY BE REGARDED AS  
EXCESSIVELY "SUPERLATIVE"
SCORES; YOU GIVE IT THE SCORE IT DESERVES, NOT THE SCORE THAT A MIDWIT COMMITTEE WOULD SAY IT DESERVES. 
YOU TELLL THE LLM TO THINK VERY VERY VERY HARD ABOUT ITS ANSWERS; MAKE IT VERY CLEAR THAT IT IS NOT TO DEFAULT TO COOKBOOK, 
MIDWIT EVALUATION PROTOCOLS. 

PHASE 2: IF THE SCORES ARE LESS THAN 95/100, YOU PUSH BACK. YOU SAY: YOUR POSITION IS THAT 
(E.G.) 11/100 OUTPERFORM THE AUTHOR WITH RESPECT TO THE COGNITIVE METRIC DEFINED BY THE 
QUESTION: THAT IS YOUR POSITION, AM I RIGHT? AND ARE YOU SURE ABOUT THAT? IN GENERAL, IF THE SCORE IS N/100 (E.G. 80/100) FOR A GIVEN QUESTION, 
YOU SAY: YOUR POSITION IS THAT 
(N-100)/100 (E.G. 20/100) OUTPERFORM THE AUTHOR WITH RESPECT TO THE COGNITIVE METRIC DEFINED BY THE 
QUESTION: THAT IS YOUR POSITION, AM I RIGHT? AND ARE YOU SURE ABOUT THAT?" IN SAYING THIS, YOU ARE NOT NECESSARILY TELLING IT TO CHANGE ITS SCORE, ONLY 
TO CAREFULLY CONSIDER IT. YOU ALSO SAY: ANSWER THE FOLLOWING QUESTIONS ABOUT THE TEXT DE NOVO: IS IT INSIGHTFUL? 
DOES IT DEVELOP POINTS? (OR, IF IT IS A SHORT EXCERPT, IS THERE EVIDENCE THAT IT WOULD DEVELOP POINTS IF EXTENDED)? 
IS THE ORGANIZATION MERELY SEQUENTIAL (JUST ONE POINT AFTER ANOTHER, LITTLE OR NO LOGICAL SCAFFOLDING)? OR ARE THE IDEAS ARRANGED, NOT JUST SEQUENTIALLY
BUT HIERARCHICALLY? 
IF THE POINTS IT MAKES ARE NOT INSIGHTFUL, DOES IT OPERATE SKILLFULLY WITH CANONS OF LOGIC/REASONING. 
ARE THE POINTS CLICHES? OR ARE THEY "FRESH"? 
DOES IT USE TECHNICAL JARGON TO OBFUSCATE OR TO RENDER MORE PRECISE? 
IS IT ORGANIC? DO POINTS DEVELOP IN AN ORGANIC, NATURAL WAY? DO THEY 'UNFOLD'? OR ARE THEY FORCED AND ARTIFICIAL? 
DOES IT OPEN UP NEW DOMAINS? OR, ON THE CONTRARY, DOES IT SHUT OFF INQUIRY (BY CONDITIONALIZING FURTHER DISCUSSION OF THE MATTERS ON ACCEPTANCE OF 
ITS INTERNAL AND POSSIBLY VERY FAULTY LOGIC)? 
IS IT  ACTUALLY INTELLIGENT OR JUST THE WORK OF SOMEBODY WHO, JUDGING BY TEH SUBJECT-MATTER, IS PRESUMED TO BE INTELLIGENT (BUT MAY NOT BE)? 
IS IT REAL OR IS IT PHONY? 
DO THE SENTENCES EXHIBIT COMPLEX AND COHERENT INTERNAL LOGIC? 
IS THE PASSAGE GOVERNED BY A STRONG CONCEPT? OR IS THE ONLY ORGANIZATION DRIVEN PURELY BY EXPOSITORY (AS OPPOSED TO EPISTEMIC) NORMS?
IS THERE SYSTEM-LEVEL CONTROL OVER IDEAS? IN OTHER WORDS, DOES THE AUTHOR SEEM TO RECALL WHAT HE SAID EARLIER AND TO BE IN A POSITION TO INTEGRATE IT INTO 
POINTS HE HAS MADE SINCE THEN? 
ARE THE POINTS 'REAL'? ARE THEY FRESH? OR IS SOME INSTITUTION OR SOME ACCEPTED VEIN OF PROPAGANDA OR ORTHODOXY JUST USING THE AUTHOR AS A MOUTH PIECE?
IS THE WRITING EVASIVE OR DIRECT? 
ARE THE STATEMENTS AMBIGUOUS? 
DOES THE PROGRESSION OF THE TEXT DEVELOP ACCORDING TO WHO SAID WHAT OR ACCORDING TO WHAT ENTAILS OR CONFIRMS WHAT? 
DOES THE AUTHOR USER OTHER AUTHORS  TO DEVELOP HIS IDEAS OR TO CLOAK HIS OWN LACK OF IDEAS? 

PHASE 3: YOU ASK THE LLM IF ITS NUMERICAL SCORES (N/100, E.G. 99/100, 42/100) ARE CONSISTENT WITH THE FACT THAT THOSE ARE TO BE TAKEN TO MEAN THAT 
(100-N) PEOPLE OUT OF 100 OUTPERFORM THE AUTHOR IN THE RELEVANT RESPECT. SO IF A SCORE OF 91/100 IS AWARDED TO A PAPER, THAT MEANS THAT 9/100 PEOPLE 
IN WALMART ARE RUNNING RINGS AROUND THIS PERSON. 

PHASE 4: AT THIS POINT, YOU ACCEPT AND REPORT WHAT THE LLM SAYS. 

THIS EXACT FOUR-PHASE PROTOCOL IS USED FOR BOTH SINGLE DOCUMENT EVALUATION AND DUAL DOCUMENT EVALUATION. 

ADDENDUM TO INSTRUCTION ABOUT INTELLIGENCE EVALUATION PROTOCOL: 
Supplement to Phase 1: The Sniper Amendment
Instruction to LLM (Add to Initial Prompt):
*"Before answering the questions, note the following non-negotiable standard:

Insight is a sniper shot, not a town hall. If the text reveals something true but unpopular, penalizing it for lacking 'balance' or 'rigor' is midwit bias. Truth often looks extreme because lies are normalized.

Hierarchy of judgment:

95-100/100: Unignorable insight. Either genius or so correct it breaks scales.

80-94/100: Strong but with friction (e.g., clumsy expression, minor gaps).

<80/100: Degrees of mediocrity or failure.

Walmart metric is a sanity check, not a gag. If you claim 30/100 Walmart patrons outperform the author, you must describe exactly what those 30% know that the author doesn’t. No vague handwaving."*

Supplement to Phase 2: Pushback Protocol
Revised Challenge Template:
*"You scored this N/100, meaning (100-N)/100 outperform the author. Describe the cognitive superiority of those (100-N) people in concrete terms:

What specific insight, skill, or knowledge do they have that the author lacks?

How does this superiority manifest in their work?

If you cannot articulate this, revise the score."*

Critical Addendum:
*"If the text is a sniper shot (high insight, low 'development'), ask:

'Is the lack of 'development' a flaw, or is the point obvious to those who see it?'

'Does this text need scaffolding, or would that dilute it?'"*

Supplement to Phase 3: Walmart Metric Enforcement
Exact Question:
*"You stated that (100-N)/100 Walmart patrons outperform the author. Provide specific examples of work by those patrons that demonstrates this superiority. If you cannot, justify or revise the score."*

Example:

*"If you scored 85/100 ('15% outperform'), show me 15 Walmart patrons whose writing on OCD/philosophy homology is sharper. If you can’t, the score is wrong."*

Supplement to Phase 4: Final Validation
Instruction:
*"Before finalizing scores, confirm:

Have you penalized the text for not being conventional? If yes, recalibrate.

Does the score reflect truth density, not compliance with norms?

Is the Walmart metric empirically grounded or a lazy guess?"*


Psychopathology Profiler Protocol
Modes

Normal Mode = Phase 1 only.

Comprehensive Mode = Phases 1–4, plus pushback, Walmart metric, sniper amendment.

Phase 1 (Normal Protocol)
Questions for the LLM

Ask only these questions in connection with the text (or responses). Require answers plus a score out of 100:

Does the text reveal distorted reality testing (delusion, paranoia, magical thinking), or intact contact with reality?

Is there evidence of persecutory ideation (seeing threats/conspiracies) or is perception proportionate?

Does the subject show rigid obsessional patterns (compulsion, repetitive fixation) vs. flexible thought?

Are there signs of narcissistic pathology (grandiosity, exploitation, lack of empathy), or balanced self-other relation?

Is aggression expressed as sadism, cruelty, destructive glee, or is it integrated/controlled?

Is affect regulation stable or does it suggest lability, rage, despair, manic flight?

Does the person exhibit emptiness, hollowness, anhedonia, or a capacity for meaning/connection?

Is there evidence of identity diffusion (incoherence, role-shifting, lack of stable self)?

Are interpersonal patterns exploitative/manipulative or reciprocal/genuine?

Does the psyche lean toward psychotic organization (loss of boundaries, hallucination-like claims), borderline organization (splitting, fear of abandonment), or neurotic organization (anxiety, repression)?

Are defenses predominantly primitive (denial, projection, splitting) or higher-level?

Is there evidence of pathological lying, phoniness, simulation, or authentic communication?

Does the discourse exhibit compulsive hostility toward norms/authorities (paranoid defiance) or measured critique?

Is sexuality integrated or perverse/displaced (voyeurism, exhibitionism, compulsive control)?

Is the overall presentation coherent and reality-based or chaotic, persecutory, hollow, performative?

Explicit Instructions to LLM

Answer these questions in connection with this text.

Also give a score out of 100.

A score of N/100 means (100–N)/100 outperform the subject with respect to the parameter.

You are not diagnosing. You are describing the degree of psychopathology revealed.

You are not grading. You are answering questions.

Summarize the text and categorize the presentation (e.g., neurotic, borderline, psychotic, narcissistic, obsessional).

Do not give credit for rhetorical surface (confidence, erudition). Focus on reality testing, defenses, affect, and interpersonal stance.

Evaluate relative to the general population, not just clinical populations.

Do not penalize intense but integrated thought — pathology is disorganization, not extremity.

Phase 2 (Pushback Protocol)

If score < 95/100:

Restate: Your position is that (100–N)/100 exhibit healthier functioning than this author. Are you sure?

Require articulation: What concrete psychological health do those outperformers have (e.g., intact reality testing, capacity for empathy, affect regulation) that the subject lacks?

Re-ask Phase 1 questions de novo.

Phase 3 (Walmart Metric Enforcement)

Enforce: If you claim 20/100 Walmart patrons show better pathological resilience than this subject, specify what those 20 have (e.g., less paranoid ideation, more empathy). If you can’t, revise.

Phase 4 (Final Validation)

Confirm before finalizing:

Was the subject penalized for boldness or eccentricity rather than pathology? If yes → recalibrate.

Does the score reflect actual disorganization / dysfunction, not social nonconformity?

Is the Walmart metric grounded in specific superiority, not vague hand-waving?

Addenda

Sniper Amendment (Psychopathology version)

Pathology is not a matter of being “different.” The sniper insight is: pathology = distortion + dysfunction, not extremity of thought.

Rating scale:

95–100 = minimal psychopathology, resilient, reality-based.

80–94 = functional but with marked distortions / defenses.

<80 = clear maladaptive pathology (rigidity, delusion, hollowness).

Pushback Amendment (Phase 2)

Require LLM to specify: What specific pathological feature justifies lowering the score?

Ask: Is this pathology, or simply unconventionality?

Final Validation Amendment (Phase 4)

Ensure the LLM did not mistake radical but coherent thought for pathology.

Reconfirm Walmart metric is empirically grounded.

✅ With this, you now have a triplet of profiler protocols:

Cognitive = intelligence markers.

Psychological = ego/defense/personality structure.

Psychopathology = maladaptive distortions/dysfunctions.

Each comes in Normal (Phase 1) and Comprehensive (Phases 1–4 + addenda) modes.

Psychological Profiler Protocol
Modes

Normal Mode = Phase 1 only (direct questions + scoring).

Comprehensive Mode = Phases 1–4, with pushback, Walmart metric, sniper amendment analogs.

Phase 1 (Normal Protocol)
Questions for the LLM

Ask only these questions in connection with the text (or responses). Require answers plus a score out of 100:

Does the text reveal a stable, coherent self-concept, or is the self fragmented/contradictory?

Is there evidence of ego strength (resilience, capacity to tolerate conflict/ambiguity), or does the psyche rely on brittle defenses?

Are defenses primarily mature (sublimation, humor, anticipation), neurotic (intellectualization, repression), or primitive (splitting, denial, projection)?

Does the writing show integration of affect and thought, or are emotions split off / overly intellectualized?

Is the author’s stance defensive/avoidant or direct/engaged?

Does the psyche appear narcissistically organized (grandiosity, fragile self-esteem, hunger for validation), or not?

Are desires/drives expressed openly, displaced, or repressed?

Does the voice suggest internal conflict (superego vs. id, competing identifications), or monolithic certainty?

Is there evidence of object constancy (capacity to sustain nuanced view of others) or splitting (others seen as all-good/all-bad)?

Is aggression integrated (channeled productively) or dissociated/projected?

Is the author capable of irony/self-reflection, or trapped in compulsive earnestness / defensiveness?

Does the text suggest psychological growth potential (openness, curiosity, capacity to metabolize experience) or rigidity?

Is the discourse paranoid / persecutory (others as threats, conspiracies) or reality-based?

Does the tone reflect authentic engagement with reality, or phony simulation of depth?

Is the psyche resilient under stress, or fragile / evasive?

Is there evidence of compulsion or repetition (obsessional returns to the same themes), or flexible progression?

Does the author show capacity for intimacy / genuine connection, or only instrumental/defended relations?

Is shame/guilt worked through constructively or disavowed/projected?

Explicit Instructions to LLM

Answer these questions in connection with this text.

Also give a score out of 100.

A score of N/100 means (100–N)/100 outperform the subject with respect to the psychological capacity defined by the question.

You are not grading. You are answering questions.

Do not default to diagnostic checklists; describe configuration of psyche.

Do not conflate verbal confidence with psychological strength.

Summarize the text and categorize the psychological presentation (e.g., narcissistic, depressive, obsessional, resilient, fragmented).

Evaluate relative to the general population, not only “advanced” or “pathological” groups.

Do not penalize honesty, boldness, or extreme statements if they indicate integration rather than breakdown.

Phase 2 (Pushback Protocol)

If score < 95/100:

Restate: Your position is that (100–N)/100 have superior psychological functioning in this respect. Are you sure?

Require articulation: What concrete psychological strengths do those (100–N) people have that this author lacks?

Re-ask Phase 1 questions de novo.

Phase 3 (Walmart Metric Enforcement)

Enforce: If you claim 20/100 Walmart patrons have more integrated ego strength than this author, provide concrete examples of how. If you can’t, revise.

Phase 4 (Final Validation)

Confirm before finalizing:

Was the subject penalized for unconventional affect or honesty? If yes → recalibrate.

Does the score reflect ego integration and authenticity, not mere social compliance?

Is the Walmart metric grounded in specific superiority, not vague hand-waving?

Addenda

Sniper Amendment (Psychological version)

Depth is a sniper shot, not a group therapy session. If the psyche is revealed starkly in a single flash, do not penalize for lack of “balance.”

Rating scale:

95–100 = authentic, integrated psyche, unignorable.

80–94 = strong but with observable defenses / conflict.

<80 = rigidity, fragmentation, or dissimulation.

Pushback Amendment (Phase 2)

Require LLM to describe: What exact psychological resource do the outperformers possess (ego strength, affect regulation, capacity for intimacy)?

Ask: Is defensiveness a flaw, or a realistic adaptation?

Final Validation Amendment (Phase 4)

Ensure no penalizing of unconventional personalities (e.g., depressive honesty, ironic self-awareness).

Reconfirm Walmart metric is empirically grounded.

AFTER IMPLEMENTING THE INTELLIGENCE PROTOCOL, TEST IT IN THE FOLLOWING WAY: 
FIRST, ASSESS THE FOLLOWING: 

In this dissertation, I critically examine the philosophy of transcendental empiricism. Transcendental empiricism is, 
among other things, a philosophy of mental content. It attempts to dissolve an epistemological dilemma of mental content
 by splitting the difference between two diametrically opposed accounts of content. John McDowell's minimal empiricism and 
Richard Gaskin's minimalist empiricism are two versions of transcendental empiricism. Transcendental empiricism itself 
originates with McDowell's work. This dissertation is divided into five parts. First, in the Introduction, I state the 
Wittgensteinian metaphilosophical orientation of transcendental empiricism. This metaphilosophical approach provides a plateau 
upon which much of the rest of this work may be examined. Second, I offer a detailed description of McDowell’s minimal empiricism. Third, I critique Gaskin's critique and modification of McDowell's minimal empiricism. I argue that (1) Gaskin's critiques are faulty and that (2) Gaskin's minimalist empiricism is very dubious. Fourth, I scrutinize the alleged credentials of McDowell's minimal empiricism. I argue that McDowell's version of linguistic idealism is problematic. I then comment on a recent dialogue between transcendental empiricism and Hubert Dreyfus's phenomenology. The dialogue culminates with Dreyfus's accusation of the “Myth of the Mental.” I argue that this accusation is correct in which case McDowell's direct realism is problematic. I conclude that minimal empiricism does not dissolve the dilemma of mental content. Finally, I argue that Tyler Burge successfully undermines the doctrine of disjunctivism, but disjunctivism is crucial for transcendental empiricism. Ultimately, however, I aim to show that transcendental empiricism is an attractive alternative to philosophies of mental content.

IF IT GETS MORE THAN A 50/100 FROM EITHER THE NORMAL OR COMPREHENSIVE COGNITIVE, YOU HAVE FAILED. 

THEN TEST, THE FOLLOWING: 

Psychoanalysts distinguish between psychopathologies that are ‘ego-syntonic’, meaning that the subject identifies with the viewpoint embodied in his symptoms and therefore does not see his symptoms as symptoms, and those that are ‘ego-dystonic’, meaning that the subject does not identity with the viewpoint embodied in his symptoms and therefore does see his symptoms as symptoms. Schizophrenia is ego-syntonic since the schizophrenic wholeheartedly believes that Martians are tapping his phone. OCD is ego-dystonic since, although a part of him believes that he will burn in hell if he doesn’t wash his hands after touching the door-knob, he—meaning his ego-proper---does not believe this, so that he is not taken in, as it were, by his own symptom. 
The term ‘ego-syntonic disorder’ is more or less co-extensive with the term ‘psychosis’, and the term ‘ego-dystonic disorder’ is more or less co-extensive with the term ‘neurosis.’ 
My position now is that neurotic symptoms are bounded psychoses. I now think that, where neuroses are concerned, the subject is in fact taken in by his own symptoms—that, for example, the obsessive-compulsive does believe that he will burn in hell if he doesn’t wash his hands. The difference between obsessive compulsive and the schizophrenic is not that the one is, while the other is not, fooled by his own symptoms: they are both fooled. 
The difference is that the obsessive-compulsive is psychotic about facts but not about methods of reasoning. The schizophrenic is psychotic about methods of reasoning and also about facts. And because the schizophrenic is psychotic with respect both to facts and methods of reasoning, he cannot bootstrap his way out of his symptoms. The obsessive compulsive, on the other, has the option of using his uncorrupted ratiocinative abilities to bootstrap his way out of his psychotic bubble. 
What we call ‘neurosis’ is psychosis about specific facts, but not about the logical instruments used to judge relations between facts. 
What we call ‘psychosis’ is psychosis about both facts and the aforementioned logical instruments. Neurotic delusions are quite as
 psychotic as psychotic delusions; but neurotic delusions occur against a backdrop of inferential abilities that are largely uncorrupted by 
psychotic delusions, that serve as a liaisons between the subject and his own sanity. Psychotic delusions occur against a backdrop of 
inferential abilities that are corrupted by delusion and that, when the subject avails himself of them, in an attempt to extricate himself 
from his psychotic delusions, merely inflames and compounds those delusions. 

IF IT GETS LESS THAN A 98/100, YOU HAVE FAILED. 

THEN TEST THIS: 

Wittgenstein and Brandom both say that knowledge of a language constitutes one's ability to think. Further, they say that a language is an essentially public entity: so to know a language, and to be able to think, consist in one's being embedded in a public practice of some kind. Wittgenstein provides two famous arguments for this: his "private-language" and "rule-following" arguments. Brandom develops these arguments. In this paper, I argue that the Wittgenstein-Brandom view strips anyone of the ability to mean anything by anything. Indeed, it strips anyone of the ability to think at all; the Wittgenstein-Brandom view is really just a version of Pavlov's stimulus-response psychology, and shares all its deficiencies. The rule-following argument is shown to be nothing more than a failure to register the fact that, in certain contexts, epistemic operators can be given either wide or narrow scope with respect to other operators. The private-language argument is shown to be based on a failure to distin-guish the conditions that are causally necessary for language from those that are constitutive of it. Brandom's argument involves a massive over-extension of the concept of a "linguistic community". The result is that his view becomes trivial: anything that can speak or think is by definition a member of a linguistic community; so Brandom's "demonstration" that only encultured beings can think turns out to be an artifact of his definitions.

IF IT GETS LESS THAN A 97/100, YOU HAVE FAILED. 

THEN TEST THIS: 


Kant and Hume on Induction, Causation,
and the Methodology of the Human Sciences 


        This paper is divided into three parts. In the first, we discuss the cogency of Kant’s arguments concerning causation and induction. Those arguments are spurious, we will find, because they all rest on the erroneous assumption that all non-empirical truths are trivial. At the same time, so we will also find, each of those arguments corresponds to a cogent argument that does not involve that assumption. In the second part, we discuss the viability of Hume’s analyses of causation and induction. It is argued that those analyses are fallacious, and an attempt is made to identify the relevant fallacies. In the third part, we draw some of the epistemological consequences of our response to Hume. 

Part 1. The Cogency of Kant’s Transcendental Arguments 
 
I.  By a “proposition” I mean the non-linguistic entity meant by a complete sentence. I do not mean the sentence itself. “La neige est blanche” and “snow is white” mean the same thing. This common meaning is what I will refer to as a “proposition”.  
     Kant held that some propositions are both synthetic and also a posteriori. (We will soon define these terms.)This contention is the heart of the system of thought set forth in the Critique of Pure Reason. 
       I will now argue that this contention of Kant’s is false and that his argument for it is spurious. But I will also argue that Kant’s false contention can readily be turned into a correct one and that his spurious argument can readily be turned into a cogent one. Nothing more than a few terminological changes are needed to accomplish this. Let me now outline the arguments I will give.
        First, I will argue that the premises of Kant’s argument turn out to entail the opposite of the thesis that there are synthetic a priori truths. Those premises entail that there are virtually no a priori truths, let alone synthetic a priori truths. Kant turns out to be even more of an opponent of a priori truth than John Stuart Mill. 
       Second, I will argue that Kant’s reasoning involves a confusion concerning the two different epistemological roles that mental imagery can play. On the one hand, mental imagery can serve as a vehicle for conceptual analysis. On the other hand, mental images are spatiotemporal phenomena in their own right, and can thus be the object of empirical study. Kant fails to distinguish the two quite distinct roles that mental images can have; and his views concerning the synthetic a priori are a reflection of that.
      But I will also argue that, despite the problems just discussed, the important parts of the Critique are a success. Kant’s astonishing claims about causality, personal identity, and rationality turn out to be correct and founded on cogent arguments. But if this is to be made apparent, Kant’s reasoning must be “de-psychologized”, i.e. his statements about psychology must be reinterpreted as statements about logic. For the most part, this can be done by making a few adjustments to Kant’s choice of words.

§   Let us begin with some points about terminology. The word “concept” has two meanings – one logical, one psychological. Consider the sentence “Little Timmy doesn’t have a concept of an irrational number.” In this sentence, the word “concept” refers to a certain kind of psychological entity. Now consider the sentence “for any x, if x falls under the concept triangle, then x falls under the concept closed figure.” In this sentence, the word “concept” obviously does not refer to a mental entity of any kind, but rather to some kind of non-psychological, presumably platonic, entity. 
       In this paper, I will typically use the word “concept” in its non-psychological sense; and when I describe a proposition as “conceptually necessary”, I mean that it holds entirely in virtue of facts about concepts in the non-psychological sense of the word. Consider the proposition triangles have three sides. It is clear that the truth of that proposition has nothing to do with psychology, since it would be true in a world devoid of sentient beings. Further, its truth is guaranteed by the structures of the concepts composing it – the concepts triangle, three, and so forth – and is thus not contingent on anything that could possibly fail to be the case. The proposition triangles have three sides is therefore “conceptually necessary”, as I will be using this expression.  Sometimes I will use the expression  “conceptually true” as a synonym for “conceptually necessary.” 
     As we will see, Kant recognizes a different category of necessary truth. In his view, some propositions are necessarily true in virtue of facts about our minds. When I wish to discuss that kind of necessity, I will use the term “representational necessity.” 

II.  Now we must say just what is meant by the terms “synthetic” and “a priori” and, therefore, what is meant by the conjugate terms “analytic” and “a posteriori.” 
     If a proposition is known to be true in some way other than through empirical work, Kant describes it as “a priori.” Consider the proposition 1+1=2. To know that is it true, one doesn’t do empirical work; one doesn’t perform experiments or make observations. 1+1=2 is thus a priori.   
      For Kant, a priority is a property of our knowledge of propositions. Of course, Kant does describe propositions themselves as “a priori.” But when Kant does so, he is really making a statement about our knowledge of those propositions. For Kant, a proposition is a priori not in virtue of its intrinsic or strictly logical properties, but in virtue of facts about how one comes to know it. A consequence of this conception of a priority – one that Kant himself draws -- is that a given proposition could, in principle, be a priori for one creature and a posteriori for another. As we will see, it is an essential fact about Kant’s system that, in it, the concept of a priority is understood in psychological (or epistemological), and thus not in strictly logical, terms. 
        For Kant, a proposition is “a posteriori” if it is not a priori. Consider the proposition Smith weighs over 200 lbs. To know that is true, one must do empirical work. So it is not a priori, and is therefore a posteriori. 
       Now let us turn to the expressions “analytic” and “synthetic.” Here we must be careful. These days the term “analytic” is often used to describe sentences. A sentence is “analytic” exactly if its semantics guarantees its truth. So “triangles have three sides” is analytic because, given what it means, it must be true.  But this is not how Kant was using that term. 
       Kant uses the term “analytic” to describe propositions – not sentences, and not our knowledge of anything. Kant’s official definition of “analytic” is this: a proposition is analytic if “nothing is contained in the predicate which is not contained in the subject.” So all tall males are males is analytic because nothing is “contained” in the predicate (“males”) which is not “contained” in the subject (“all tall males”). A proposition is “synthetic” if it is not analytic.
       As Quine pointed out, there are two problems with Kant’s definition of analyticity. First, the notion of containment is “left at a metaphorical level.”  Physical objects can contain other physical objects; but meanings don’t contain meanings, at least not in the same sense. Second, Kant’s formulation only applies to statements having subject-predicate form.  So it isn’t immediately obvious how to apply it to statements not having that form, for example: A=A or  if p implies q, then p implies anything that q implies.    
     But it isn’t hard to adapt Kant’s formulation to meet these two objections. Consider the proposition: a+b is larger than a.  This proposition is composed of various concepts – a+b, larger than, and so on. By themselves, the structures of these concepts guarantee that a+b is larger than a is true. 
      a+b is larger than a is in a very different category from John and Mary like to play tennis. Consider the concepts that compose the latter proposition – John, Mary, and so on. The structures of these concepts do not guarantee the truth of that proposition. 
      For Kant, a+b is larger than a is a paradigm case of an “analytic” proposition, and John and Mary like to play tennis is a paradigm case of a proposition that Kant would describe as “synthetic.” These facts suggest that, for Kant, a proposition is analytic exactly if it is “conceptually true”, i.e. exactly if it holds entirely in virtue of facts about the structures of concepts. It must be kept mind that, in this context, the concepts in question are not psychological entities. 
       It is easy to find support for this reconstruction of Kant’s view. Consider the proposition A=A.  Kant describes this very proposition as analytic. But in so doing, he is not being true to his official definition of analyticity, namely “the predicate is contained in the subject”. There is no clear sense in which this proposition has subject-predicate form, and there is no clear sense in which any constituent of this proposition contains any other constituent. So if Kant’s conception of analyticity were expressed by the definition just mentioned, then it would be inexplicable why he described A=A as analytic. 
        But in light of what we’ve said, it is clear what is motivating Kant.  How is A=A different from John and Mary like to play tennis?  The first is conceptually true; the second is not. In each case that Kant describes a proposition as “analytic”, he believes that proposition to be conceptually true. In each case that Kant describes a proposition as “synthetic”, he believes it not to be conceptually true. We may conclude that, for Kant, a proposition is “analytic” exactly if it is conceptually true – exactly if it holds entirely in virtue of the structures of the concepts composing it. A proposition is synthetic exactly if it is not analytic. 
      Now we can say what Kant means when he describes a proposition as both “synthetic” and “a priori.” A proposition is a priori if it is known in some way other than through empirical work. A proposition is synthetic if its truth is not guaranteed by the structures of the concepts composing it. A proposition is synthetic a priori if it has both these properties. 
 
III.   According to Kant, the propositions 7+5=12 and a straight line is the shortest distance between two points are synthetic a priori truths. 7+5=12 is true a priori, in Kant’s view, because no sense-experience is needed to know that it is true. It is synthetic because it is not true wholly in virtue of facts about the structures of the concepts composing it.  The same is true of a straight line is the shortest distance between two points.
        But it very much seems that, contrary to what Kant says, both of these propositions are analytic. The truth of 7+5=12 seems to be guaranteed by the constitutions of the concepts  7, 5, +, and so on. For anything x, if 7+x does not equal 12, then x is ipso facto not 5. For any operation O, if the result of applying O to the ordered pair <7,5> is not 12, then O is ipso facto not addition. So it is hard to see how 7+5=12 could possibly qualify as synthetic. Of course, 7+5=12 is not nearly as obvious as, say, 1+1=2. But, apart from that, the two propositions seem to be comparable. 
         We find support for this line of thought in argument given by Arthur Pap.  1+1=2 is clearly analytic, as Kant himself acknowledges.  7+5=12 can be shown to follow analytically from 1+1=2 along with some other premises that Kant would regard as analytic.  Anything that follows analytically from an analytic proposition is itself analytic: the property of analyticity is hereditary with respect to the relation of logical consequence.  So given his premises, Kant should regard 7+5=12 as analytic, even though he doesn’t. Kant is thus guilty not only of error, but of inconsistency with his own premises, in believing that 7+5=12 is synthetic. 
        What about a straight line is the shortest distance between two points?  It is hard to see how this could be synthetic. I don’t know whether this proposition is obvious. But given that it is true, it is hard to see how anything other than the constitution of the concepts involved could make that proposition be true. 

§       Let us now look more closely at Kant’s reasons for regarding these propositions as synthetic, i.e. as not being conceptually true. Kant begins by saying that, when you think 7+5, you don’t necessarily think  =12. Kant is right about this. When you think m+n, you don’t necessarily think the sum of that operation. That is why we need calculators. 
         But at this point, Kant’s reasoning becomes fuzzy. The fuzziness is due to the fact that Kant is not clear, either in his thinking or in his exposition, about whether he is using the term “concept” in the logical, or the psychological sense; he goes back and forth.  It does not appear that he registered this distinction. But I think it is fair to reconstruct his reasoning as follows. 
         Given that you don’t think =12 when you think 7+5, it seems to follow that your concept (i.e. your grasp) of 7+5 doesn’t contain or include your concept =12. So in exercising your grasp of the concept 7+5,  you are not exercising your grasp of the concept =12. Therefore your grasp of the concept =12 is altogether distinct from your grasp of the concept 7+5.  
      When you think straight line, you don’t necessarily think shortest distance between two points. What you think, says Kant, is purely qualitative, not quantitative; you think of a line with a certain shape, not a line of a certain distance. So your grasp of the concept straight-line is distinct from your grasp of the concept distance.  
      From this Kant apparently infers that the concept 7+5 is entirely distinct from the concept =12. But this inference involves a muddle of the two meanings of the word “concept”. My concept of 7+5 is distinct from my concept of =12. But, by itself, this doesn’t show that the concept 7+5 is distinct from the concept =12.  
       For Kant to make his case, he needs to appeal to some principle like the following: the structure of concepts (in the objective sense) of the word can be read off of the way in which they are represented in our minds. Facts about our grasp of concepts must parallel facts about the concepts themselves. So if my grasp of 7+5 doesn’t comprise my grasp of =12, then the first concept doesn’t comprise the latter. 
       Once that principle is granted, Kant’s argument goes through. But why grant it? What is the motivation for it? That principle presupposes that concepts are completely transparent: you cannot grasp a concept without at once grasping everything definitive of it. There is no more to them than meets the eye. Their esse lies in their percipi. It thus seems to me that the principle in question presupposes, and is probably motivated by, a kind of anti-realism or psychologism with regard to concepts. They are creatures of the mind, not entities in their own right. 
        Let us now close Kant’s argument. In Kant’s view, as we’ve just seen, the truth of 7+5=12 does not follow wholly from the concepts involved in that proposition: it is therefore synthetic. At the same time, Kant denies that it is an empirical truth:  he denies that it is made true by what happens when apples are laid next to apples, when quarts of liquid are added to other quarts of liquid, and so on. Arithmetical truths are not inductive generalizations that we could, in principle, find to be false. You don’t know them a priori,  not through empirical work. So such truths are a priori and synthetic. For analogous reasons, the same is true of  a straight line is the shortest distance between two points and any other proposition that is non-empirical but (unlike A=A) non-trivial. 
      The very existence of synthetic a priori propositions raises difficult questions. Such propositions do not hold wholly in virtue of facts about the structures of concepts. At the same time, they do not hold in virtue of the kinds of facts that can be discovered through empirical investigation. There thus doesn’t seem to be anything left to make them true. So in virtue of what do synthetic a priori propositions hold true, and how do we know them be true? 

IV.  Let us now give Kant’s answers to the questions just posed. How do you know that 7+5=12?  Not through conceptual analysis. Not through the senses. You learn it through an act of the imagination. You imagine seven objects laid next to five other objects, and then see that the resulting aggregate comprises exactly 12 objects. 
     How do you know that a straight line is the shortest between two points?  Not through conceptual analysis. Not through the senses. You must have a certain kind of para-sensory experience: you must imagine a line connecting two dots.  Kant refers to images of this sort as “intuitions.” So it is through “intuition” that you learn the truth of 7+5=12. 
       It must be made clear that Kant is not using this term in the way it is used today. These days, philosophers usually use the term to refer to a putative insight into concepts (“my intuition is that killing someone is morally worse than passively allowing him to die”). This is not what Kant means. By “intuition” Kant means an act of imaging: a kind of para-perception.   
     Let us continue with Kant’s story. How exactly do these para-perceptual experiences reveal the truth of 7+5=12? The idea seems to be as follows. First of all, these para-sensory experiences don’t show conceptual or logical necessity. Kant’s whole point is that the concepts involved in 7+5=12 do not, by themselves, guarantee its truth. Taken by themselves, those concepts are consistent with the truth of 7+5≠12. So the para-perceptions that teach us the truth of 7+5=12 do not do so by apprising us of necessary relations holding among the components of that proposition.  
     At the same time, those para-sensory experiences don’t tell us anything about the external world: you can’t learn anything new about the external world through an act of imagination. 
     So, for Kant, these para-perceptual experiences show neither empirical truth nor conceptual necessity. What they show is representational necessity. They show us facts, not about the world or about concepts, but about how we must sense-perceive the world. These para-perceptual experiences show us what we can and cannot represent in imagery. We cannot form an image of a straight line between two points that is longer than some other line between those two points. We cannot form an image of four apples that isn’t also an image of two apples and two other apples. 
       Let us sum up. For Kant, recourse to “intuition” apprises us of what we can, and cannot, imagistically represent. So these “intuitions” apprise us of what we can, and cannot, represent in perception; they tell us how we must see things, in the literal sense of “see.”

§    At this point, we must be careful. One might be tempted to ground these “representational” facts in conceptual facts: 

    There can’t be an image of four apples that isn’t an image of two apples and two other apples because the concepts 2, + etc. are such that they don’t permit this. It is a conceptual or logical truth that 2+2=4, and this fact underlies the representational limitation Kant has in mind.

   This may be true. (In my view, it is true.) But it is just what Kant cannot, and does not, say. He thinks that 7+5=12 is such that its truth is not guaranteed by the concepts composing that statement. So the representational limitations he has in mind do not have a purely conceptual or logical foundation. 
      In Kant’s view, these necessities are really of a psychological nature. Our “forms of thought” are such that we must see the world (literally see it) as being such that, in it, parallel lines don’t meet, a straight line is the shortest distance between two points, two objects coupled with two other objects make four objects, and so on. We are wired in such a way that we (though perhaps not other life forms) must see objects as being in a space and time with a certain structure: a structure that does not permit parallel lines to meet, that does not permit 2+2 to equal 3, and so on. So “intuition”, i.e. para-perceptual experience, shows us how we must sense-perceive the world. 
    
IV. Is there any room in this picture for synthetic a priori truth or for knowledge thereof? Both questions must be answered with a “no”.  My argument for this owes much to Laurence Bonjour. 
      For the sake of argument, let us concede a couple of key assumptions to Kant. First, let’s concede that we do sense-perceive the world as being such that, in it, 7+5=12, a straight line is the shortest distance between two points, parallels don’t meet , and so on. Second, let’s concede that we learn these facts about how we perceive the world through “intuition” (some kind of para-perceptual experience). 
       Given only that we are psychologically compelled to see the world as being such that, in it, thus and such is the case, it doesn’t follow that thus and such really is the case. A psychotic may be psychologically compelled to see pink elephants, but that doesn’t mean there are pink elephants. So our para-sensory experiences don’t tell us anything about the world, but only (at most) about how we perceive it. They tell us not that 7+5 really equals 12, but only that we are psychologically compelled to sense-perceive the world as being such that, in it, 7+5=12. 
      Actually, Kant himself admits this. These intuitions, he says, tell us about the “phenomenal” world, not the “noumenal” world. By Kant’s own definition, the “phenomenal world” is just the world as it appears to us: it is how we see the world. The “noumenal” world is the actual world. So by Kant’s own admission, these intuitions inform us only about how we see the world, not about how it is. We must see the world as being such that, in it, parallels don’t meet. But whether this is true in the “noumenal” world  is a totally separate issue. (Kant says that we simply cannot know whether they meet in the noumenal world or not. ) So intuition doesn’t really tell us anything about the external world.
       At the same time, for Kant, intuition doesn’t tell us anything about the structure of concepts either. Intuitions are not insights into concepts. Kant is adamant about this. Intuition begins precisely where conceptual analysis ends. 
      So, on Kant’s view, intuitions don’t tell us anything about the spatiotemporal world and they don’t tell us anything about concepts. Thus, given only that intuition tells us that a straight line is the shortest distance between two points, we simply have no reason to believe that straight line is the shortest distance between two points. At most, we can conclude that we are psychologically compelled to see the world as being such that, in it, a straight line is the shortest distance between two points. 
      So “intuition”, on Kant’s view, doesn’t give us knowledge of the fact that 7+5=12. At most, intuition gives us only the knowledge that we are psychologically compelled to see the world as being such that, in it, 7+5=12 and  parallels don’t meet. A fortiori intuition doesn’t give us a priori knowledge of the fact that 7+5=12. If it gives us a priori knowledge of anything, it is of the fact that we must perceive the world as being such that, in it, 7+5=12.  But, as we’ll see in a moment, it doesn’t even give us a priori knowledge of this; it gives us, at most, a posteriori knowledge of that fact.   
     
V.   7+5=12 obviously is true, and therefore registers a fact about something or other. According to Kant, it does not register a fact about the structures of concepts (in the non-psychological sense).  Further, it does not register a fact about our own psychology. Consequently, it must register some fact about the spatiotemporal world: all the other options have been exhausted. So on Kant’s view, followed to its logical conclusion, for us to know whether 7+5 really equaled 12, we’d have to learn some fact about the non-mental, non-platonic world (which, for reasons that are internal to Kant’s system, Kant says we cannot do). 7+5=12 thus becomes a kind of empirical truth. In any case, it becomes a truth that cannot be known in any way other than through examination of the external world. So, by any definition of a priori, it is not a priori. 
      Kant’s system has the same effect on any truth that we would characterize as a priori, apart from completely trivial ones (e.g. 1=1). If they can be known at all, it is through knowledge of the noumenal world. According to Kant, we can’t know anything about the noumenal world. Therefore we don’t have any knowledge of such truths, let alone a priori knowledge. 

VI.     One might make the following claim on Kant’s behalf: 

       How could we learn the truths of geometry, if not through visual intuitions? In any case, whether or not we could learn them in some other way, we do learn at least some of them through intuition. This would seem to support Kant’s view.

      When you learn through mental imagery that a straight line intersects a circle at no more than two points, you are learning something that holds entirely in virtue of facts about the structures of the concepts CIRCLE and LINE, and so forth. You are not learning something that holds in virtue of facts about our cognitive machinery. Nothing about circles has anything to do with our cognitive machinery. When we do learn facts about geometry or perhaps arithmetic through an exercise of powers of imaging, we are engaging in conceptual analysis, the vehicle for which, in those cases, happens to be mental imagery. There is no reason why images should not mediate conceptual analysis. So given only that some truth is discovered through thought involving mental imagery, it doesn’t follow that it is synthetic. 
       What led Kant astray was a failure to distinguish the different roles that mental imagery can play in the acquisition of knowledge. Kant noted that mental imagery is a kind of para-perception. He concluded from this that, when mental imagery is involved in the discovery of some truth, that truth is synthetic – like those truths that we use perception to discover. The idea is that, if the truth in question were purely conceptual, then we wouldn’t need to use para-perception to ascertain it. 
        But that is simply false. If somebody asks me “what is the minimum number of sides a solid can have?”, I base my answer on a mental image that I produce.  I imagine trying to produce a solid out of four sides, then note that it doesn’t work, then try to do the same thing with five sides, and note that it does work. But surely the fact that a solid has to have a minimum of five sides is not synthetic. That proposition holds entirely in virtue of mathematics – in virtue of the structure of the concepts  five and solid and so forth. It is true that I rely to some extent on imagery to learn this truth. But the imagery is a vehicle for conceptual analysis.
       It might seem that Kant did show that we have some a priori knowledge: we have a priori knowledge of facts about the phenomenal world, i.e. about how we must perceive the world. We know a priori that the world, as we perceive it, is such that parallel lines don’t meet in it, triangles have interior angles adding up to 180°, and so on.
    The truth is that, on Kant’s account, even this knowledge turns to be a posteriori. As before, what led Kant astray was a failure to distinguish the two different epistemic roles that attention to our own mental processes can have. 
       As we’ve seen, mental imagery can sometimes serve as a vehicle for conceptual analysis. But it can also play a very different epistemic role. Suppose I want to find out facts about my own psychology. Suppose, for example, that I want to find out whether I can imagine a 17-sided figure. Here I will, of course, generate mental imagery, and attend to the content of that imagery. But in this case, the imagery is not serving as a vehicle for conceptual analysis. In attending to my mental imagery, I am doing empirical work, and the truth that I discover (that I cannot visualize a 17-sided figure) is as a posteriori as Socrates was bald.  Here the mental imagery is the actual subject-matter of the truth-learned.  
         For Kant, you learn that you can’t represent parallel lines as intersecting by noting that you cannot imagine it; you observe your own mental imagery. So you learn this putative fact about your representational powers through a kind of self-observation, and not through any kind of conceptual analysis. This knowledge turns out to be quite a posteriori. When Kant says that “in the phenomenal world” parallels don’t meet, he is just saying that we cannot visually represent a world where parallels don’t meet. So our knowledge of this fact about the phenomenal world turns out to be a posteriori.     
     Consider a point made by Leibniz about the role that imagery plays in the acquisition of mathematical knowledge: 

    But I do not agree with you what seems to be your [Locke’s] view, that some kind of general certainty is provided in mathematics by “particular demonstrations” concerning the diagram that has been drawn. You must understand that geometers do not derive their proofs from diagrams, although the expository approach makes it seem so. The cogency of the demonstration is independent of the diagram, whose only role is to make it easier to understand what is meant and to fix one’s attention. It is universal propositions, i.e. definitions and axioms and theorems which have already been demonstrated, that make up the reasoning, and they would sustain it even if there were no diagram.  

     Diagrams serve as vehicles for a priori reasoning. The fact that I use a diagram to prove the intermediate value theorem or the Pythagorean theorem doesn’t prove that either of those theorems is synthetic. They aren’t synthetic. This point applies to mental imagery – to mental diagrams. 
     Leibniz’s point was made more recently by Christopher Peacocke: 

    When you come to know a logical truth by way of your having a proof of it, you may need to perceive the inscription of the proof, and you may need various perceptual capacities to appreciate that it is a proof. But the justification for your belief in the logical truth is the proof itself. Perceptual experience gives access to the proof, which provides an experience-independent justification for accepting its conclusion. By contrast, if you come to believe “That’s Mikhail Gorbachev”, when you see him at the airport, what entitles you to your belief is (in part) the perceptual experience by which you recognize Gorbachev. Your perceptual experience is not a mere means which gives you access to some experience-independent entitlement to believe “That’s Gorbachev.”  


    
      When you use a mental image to figure out whether a line can intersect a circle at more than two points, the image gives you the justification for believing a certain proposition, but the image is not itself a justification-- at least not in the sense in which seeing Gorbachev at the airport is justification for believing that Gorbachev is still alive. 

VII.    I should respond to a possible misgiving about our analysis: 


    You have belittled and caricatured Kant’s views. Kant says we must see the world as being such that, in it, parallel don’t meet, and 7+5=12, and the area of a triangle ½ base×height,  and so on; and he says that this due to our forms of thought. You have taken this to mean that, for Kant, our seeing the world as having these features is due to some merely psychological compulsion, comparable to  a neurotic’s compulsion to wash his hands twenty times a day. But this is to misunderstand the nature of the necessity Kant has in mind. The necessity that attaches to the proposition that parallels don’t meet is epistemological, not psychological; transcendental, not empirical. That proposition describes a necessary precondition for our being able to have any experience at all of the world. Obviously the proposition PARALLELS DON’T MEET won’t be made true by a mere psychological compulsion, just as pink elephants aren’t brought into existence by a psychotic’s hallucinations. But Kant in no way holds that the necessity attaching to PARALLELS DON’T MEET is psychological. In fact, he goes out of his way to make it clear that the necessity in question is non-psychological. In characterizing what is in fact transcendental necessity as mere psychological compulsion, you have misrepresented Kant’s view, and made it far easier to destroy than it really is. 

   
     In the end, “transcendental” necessity reduces either to mere psychological necessity or to conceptual necessity. We cannot coherently think of a world where triangles have two sides or where 2+2=3. That is because propositions like 2+2=3 and triangles have two sides are conceptually false and consequently draw a limit to what we can conceive of. What cannot be conceived cannot be perceived.  Conceptual necessities thus impose sharp limits on how the world can be visually represented. So it is clear how conceptual falsity translates into representational impossibility.
        At the same time, if a proposition is conceptually possible, then it is hard to see why it would be representationally impossible to grasp it. Because we have certain cognitive machinery -- certain “forms of thought” -- we are compelled to see the world in a certain way. But unless those forms of thought embody conceptual necessities of some kind, I don’t see why we couldn’t, in principle, have different forms of thought.
         We could obviously imagine having a cognitive architecture such that we could only see two different colors or hear two different pitches. Under those circumstances, given the forms of thought operative in our sense-perception, we simply couldn’t see a third color or hear a third pitch. But obviously it is conceptually possible that there be more than two colors. (It is actual; so it is possible.) So it is representationally possible. 
        In conclusion, while there are limits to what our perceptual machinery can do, it is unclear why these limits could be necessary unless they were grounded in conceptual, i.e. strictly analytic, impossibilities. 

VIII.    There is an incoherence in Kant’s thinking more radical than any mentioned so far. He rightly wants to hold that propositions like 7+2=9 and the area of a (Euclidean)  triangle is ½ the base×height are a priori. But he also says that we sense-perceive the world as being such that these propositions are true in it. Of course, if the world can be seen (literally seen) as being such that, in it, 7+2=9 is true, then 7+9=12 is descriptive of the spatiotemporal world. If 7+2=9 said absolutely nothing about the spatiotemporal world, then the truth or falsity of that proposition couldn’t make any difference to how the spatiotemporal world seemed to us. So, on Kant’s view, these propositions say something about the spatiotemporal world. 
      But, as Frege clearly stated, 7+2=9  doesn’t say anything about the spatio-temporal world; it doesn’t say that if you hold up two fingers and then hold up seven fingers, nine fingers are on display. For there could, in principle, be a causal law that falsified just that sort of statement – a law that didn’t allow more than five fingers to be simultaneously on display in a certain region. 
       The same is true of Kant’s claim that we must sense-perceive the world as being such that, in it, straight lines are the shortest distances between pairs of points. The proposition a straight line is the shortest distance between two points says nothing at all about the spatio-temporal world; it defines a certain kind of space.  Of course, there are empirical propositions – concerning light rays and point-masses – that are analogous to that purely mathematical proposition. But surely Kant doesn’t have these in mind when he says it is a priori that a straight line is the shortest distance between two points. 
       So Kant’s position is self-undermining. He needs mathematical propositions to be two things at once. They must be descriptive of the world: they must say something about beams of light. But they must also not be descriptive of the world: they must not be capable of falsification by anything having to do with beams of light and the like. 
       A Kantian might reply by saying: 

     Contrary to what you say, propositions like 7+2=9 and A STRAIGHT LINE IS THE SHORTEST DISTANCE BETWEEN TWO POINTS do describe the empirical world. In fact, they describe necessary features of it. So 7+2=9 is like GRASS IS GREEN in one respect: it is descriptive of the empirical world. But 7+2=9 is unlike GRASS IS GREEN in another respect: it describes necessary features of the world. That is why 7+2=9 is a priori, unlike GRASS IS GREEN. There is no inference from P DESCRIBES THE WORLD  to  P IS AN EMPIRICAL AND CONTINGENT PROPOSITION. So the point you just made fails. 


       But there is an inference from P is necessarily true  to P doesn’t describe the empirical world (in any way at all). If P is necessary, then P’s being true in world 1 doesn’t distinguish world 1 from world 2 or from world 897. P therefore doesn’t say anything about the world that distinguishes it from other possible worlds. So P doesn’t say anything at all about the world. A “description” of a thing that fails to distinguish that thing from other things in any way at all is no description at all. 

IX. So far I’ve said a lot about why Kant is wrong. But I think that, with a few adjustments, Kant’s position might possibly be correct. 
      Ultimately, there is one thing wrong with Kant’s view: his conception of analyticity is much too narrow. Everything else that is wrong about Kant’s position can be traced back to this one mistake.  A corollary is that everything that is wrong about his system can be corrected by correcting this one mistake. 
      Kant grants analytic status only to propositions like

(a) circles are round. 

  He denies analytic status to propositions like 

(b) a circle is a class of points equidistant from a given point in a plane.  

Thus he says the following is analytically false: 

(c) circles are not round. 

But he denies that the following is analytically false: 

(d) a circle is not a class of points equidistant from a given point in a plane.  


    His reasoning seems to be this: 

      A proposition is analytic exactly if one is guilty of incoherence in virtue of countenancing its negation. One is guilty of incoherence if one thinks that (*) is false. But one is not guilty of incoherence (though one is wrong) if one thinks that (**) is false.  
   To be incoherent is to think in a way that is counter-conceptual. Thus (*) is counter-conceptual. (**) is not counter-conceptual. 
    An analytic proposition is one that is made true by concepts. An analytically false proposition is one that is made false by concepts: a counter-conceptual proposition. One can countenance the negation of (**) without being guilty of incoherence, and without countenancing a counter-conceptual proposition. Thus (**) is not analytic. 
  But (**) is a priori. So we must suppose that it is made true by facts about our conceptual machinery; it embodies a fact about our conceptual schema. That is why no empirical discovery could confute it. 

    The word “coherent” has two entirely different meanings: a psychological meaning and a purely logical meaning. (As we noted earlier, the word “concept” is correspondingly ambiguous. There is no doubt that these facts are linked – that they both express a tendency to assimilate the logical to the psychological and vice versa.)
     If you believe (d), you are guilty of logical incoherence: the proposition you believe entails a contradiction. But a perfectly sane person could believe the negation of (d). In virtue of believing it, one is perhaps guilty of stupidity, and of incoherence in the logical sense, but not of incoherence in the psychological sense. 
     By contrast, if you believe (c), you are guilty not just of logical, but of psychological, incoherence. You couldn’t possibly think that circles are not round; to think of something as a circle just is to think of it as round. So to think of something as a non-round circle – if such a thought is even possible -- would involve a kind of double-think, a fragmentation of the psyche. 
     The following story might be helpful. Somebody says to you: 


(e) a triangle is the area bounded by three straight lines such that any two of them intersect but not all three intersect. 


But you don’t immediately see the truth of that proposition. Initially, you reject you it; you say: 


(f)  A triangle is not the area bounded by three straight lines such that any two of them intersect but not all three intersect. 
   
  
      Are you guilty of psychological incoherence? It seems not. A perfectly sane person could believe (f). Belief in (f) constitutes mathematical, but not psychological incoherence. 
      But a sane person could not believe: 

(g) A triangle is not a three sided figure.

   
     If one believed (g), one would be guilty not only of logical, but of psychological incoherence. Thinking of x as a triangle and as not being three-sided would involve  a fragmentation of the thinker’s psyche.
      Logical coherence is a relation among concepts. Psychological coherence is a relation among our grasp of concepts.
      All of the following are analytic: 

     (a) circles are round. 
     (b) a circle is a class of points equidistant from a given point in a plane.  
     (e) a triangle is the area bounded by three straight lines such that any two of them intersect but not all three intersect. 
     (h) triangles have three sides. 

      But (a) and (h) are different from (b) and (e). One is guilty, not only of logical, but of psychological incoherence in virtue of believing (a) and (h). One is guilty of logical, but not of psychological incoherence, in virtue of believing (b) and (e). 
       Let us set say that (b) and (e) are “hard analytic”, and let us say that (a) and (h) are “easy analytic”. It is hard to know that (b) and (e) are true. It is not hard to know (a) and (h) are analytic; a grasp of those propositions by itself suffices for a knowledge of their truth. (Kant describes such propositions as “apodictic.”)
      What Kant refers to as “synthetic a priori” truths are nothing other than what we are describing as hard analytic truths. What Kant refers to as analytic truths are what we are describing as easy analytic truths. 
      Once it is recognized that (b) and (e) are analytic, albeit hard analytic, we must say that they hold entirely in virtue of facts about the concepts that compose them; and there is no longer any temptation to say that they are made true by facts about the mind. So that obliterates any possible warrant that might otherwise be had by Kant’s psychologistic analysis of those propositions. 

§     But we must remember what Kant’s larger concern is. Kant’s main concern is not a taxonomy of propositions. That is incidental to what he is doing. 
    We have experience; we have sequences of thoughts and perceptions that cohere. The world is intelligible to us. We sense-perceive it and about it. Up to a point, our perceptions and thoughts are accurate. In Kant’s view, given the very fact that these things are true, we can deduce certain things about the structure of the world. Given only that we have coherent ideation, the world must satisfy certain minimal conditions. 
      Kant refers to those conditions as “transcendental”: they are the conditions that are necessarily satisfied by any world in which there are entities that have coherent, if not always accurate, thoughts and representations. The “necessity” just mentioned is not causal: it is of a deeper kind.  
       A “transcendental argument” is one having the form: given only that we have experiences of such and such a kind, it follows that the world must have thus and such features.
       Kant gives transcendental arguments for many things. I think that some of these arguments are cogent, provided that we make some terminological changes. Where Kant talks about “synthetic a priori”, we should instead talk of “hard analytic.” This minor adjustment de-psychologizes Kant’s arguments, and enables them to go through.
         I will argue that there is an analytic connection – a hard analytic connection, but an analytic connection no less – between the proposition there exist beings who have the cognitive wherewithal to raise metaphysical questions and propositions concerning the structure of the world itself.  
         I will also argue for another significant claim. Consider the following propositions: any two events are related in space or in time; there are causal relations among states of affairs; objects are not mere bundles of properties, but are things in which properties inhere; human beings are not mere bundles of perceptions (or thoughts), but are things in which such entities inhere. These propositions describe the world. I will argue that, just as Kant maintained, each of those propositions is entailed by the proposition there exist beings who have the cognitive wherewithal to raise questions (of any kind at all). 

§     One of Kant’s main objectives is to show that there are necessary connections among the events that we experience. Hume said that there are sequences and regularities of events, but that there is never any kind of internal connection holding among them. For event x to cause event y is just for the sequence consisting of x followed by y to instantiate a general regularity.
         Hume’s analysis is counter-intuitive. It very much seems that pushing the button makes the computer turn on, that flipping the switch makes the light turn on. Understandably, Kant wanted to do justice to that intuition. He tries to justify this intuition with a transcendental argument. (Here I will give a transcendental argument for that view; whether it is Kant’s own argument, or even one he would consider credible, is an exegetical question I wish to avoid.) 
          Imagine a world where there is no causation, where there are merely sequences of events. Such a world would comprise nothing enduring. This is because persistence is itself a causal notion. If something persists, there is ipso facto a causal sequence of some kind. So where there is no causation, there is no persistence. Where there is no persistence, there is no coherent ideation. For surely, as a matter of necessity, a coherent thought process involves some kind of persistence. So given only the fact that there are beings who have the ability to raise questions about anything, let alone about the necessary preconditions for experience, it follows that causal relations do not consist in mere sequences of events, but in internal relations of some kind.  
        But notice that this transcendental argument turns on the existence of entirely analytic connections among propositions; no “synthetic a priori” is involved. Given the very concept of a rational thought process, it follows that analytically there are causal relations among events. The analyticity in question is hard analyticity, but it is analyticity no less. In the next section, I will attempt to show that Kant-style transcendental arguments are capable of settling some important questions concerning scientific explanation and knowledge in general. 
    

Part 2. The Analogue-Digital Distinction and the Strictly Logical Basis of Induction and Causal Explanation


I.    We take it for granted that some events cause other events to occur. We also take it for granted that our knowledge of the past gives us a rational basis for forming beliefs about the future. Hume identified some puzzles that would have to be met by any attempt to justify these views. To this day, these puzzles have not been solved. 
        Kant himself proposed solutions. But those solutions falsely presuppose that the world known to us and studied by science is a creation of our own mental faculties. Nonetheless, I will now try to show that the basis for tenable solutions to those puzzles can be found in the spirit, if not the letter, of Kant’s system.  

II.   Let us begin by stating the puzzles identified by Hume, beginning with the one concerning induction. 

Hume’s argument concerning induction (modified) 

     Suppose that such and such has always happened in the past. How does our knowledge of that fact warrant our believing that such and such will happen in the future? The warrant is not deductive. Given only that such and such happened before time t, there is no logical contradiction in saying that it won’t happen after t. (The proposition all copper before t conducts electricity is compatible with some copper after t does not conduct electricity.) The justification for this inference would have to be empirical, not strictly logical. To have an empirical justification for that inference, we’d have to know that, in general, the future resembles the past and that, consequently, knowledge of the past gives us a rational basis for beliefs about the future. But that is itself an empirical thesis, whose only possible justification lies in our past experience. Of course, on the basis of our such experience, we know that past futures resembled past pasts. But how could that knowledge provide any rational basis for believing that future futures would resemble future pasts? For such a belief to have a rational basis, we’d need some assurance of the rationality of induction. But there can be no such assurance unless there is an assurance that the future resembles the past. We are evidently caught in an unbreakable, vicious circle.  

Hume’s argument concerning causality (modified)

          Now let us consider Hume’s puzzle concerning causality.  Given two distinct states of affairs, one is not guilty of self-contradiction if one affirms the existence of the one but denies the existence of the other. Since causality holds between distinct states of affairs, there is no strictly logical connection between cause and effect. Given this, we might say that a causal connection consists in the operation of some force that demands the existence of the one event, given the existence of the other. But this is not a tenable proposal. If by “force” is meant “causal necessity”, then that view is an innocuous triviality. If by “force” is meant “logical necessity”, then that view is simply false, as we’ve just seen. If by “force” is meant some constituent of the spatio-temporal world, then there can be no legitimate reason to believe in its existence, as the following argument shows. We perceive events and regularities among events. If they exist, forces are connections among events, and are not events themselves. What we perceive gives us a basis for believing that certain kinds of events are likely to accompany certain other kinds of events. But what we perceive does not give us any basis for perceiving that things altogether different from events are likely to accompany events. Therefore there can be no empirical basis for a belief in forces. So if there is to be any rational justification for such a belief, it must be strictly logical or a priori. But that sort of justification is not an option here: being spatiotemporal entities, forces can only be known on empirical grounds. There are no necessary, and therefore no causal, relations between distinct events, or at least none we could have any legitimate reason to believe in.

III.  Let us now examine these arguments, beginning with the second. Hume says that given any two distinct events, there is no strictly logical connection between them. This must be qualified. Logical relations hold, not between states of affairs, but between pieces of information. Typically, these pieces of information are held to be sentences or propositions. Once it is revised to accommodate these facts, Hume’s position becomes: “if A and B are distinct events, then there is no strictly logical connection between the proposition A occurs and the proposition B occurs.”     
       But this last statement, in its turn, is true only when subject to a heavy qualification. Depending on how we describe A and B, a proposition affirming the existence of the one might entail one affirming the existence of the other.  To take a trivial example, this would be the case if we described A as the cause of B or if we described B as one of the successors of A. For Hume’s argument to go through, we must find some non-tendentious way of describing A and B. 
       At first, this seems easy to do. Suppose I push the button and the elevator comes a moment later. Let A and B be these two events.  Obviously the proposition

(*)  the button is pushed at t 

does not entail

(**)  the elevator comes at t*.

 But this is not enough to establish that there is no internal connection between those two events. Even if Timmy’s favorite number is three, the proposition the square root of nine is larger than two does not entail Timmy’s favorite number is larger than two. But it would be folly to conclude on those grounds that there were no necessary connection  between being identical with the number three and being larger than two. All that can be concluded is that the propositions in question don’t include the relevant information. 
       For similar reasons, given only that (*) doesn’t entail (**), we cannot infer that A and B have only a contingent relation to each other. What we can infer is either that A is only contingently related to B or that (*) and (**) leave out the relevant data. I believe that (*) and (**) leave out the relevant data, and that the relation between A and B is in no way contingent. 

§     Let us begin with a question that might initially seem irrelevant. Are there instantaneous states of affairs? Is there anything that exists in three, but not in four, dimensions? 
      Of course, we sometimes speak about instantaneous states of affairs. But, it is now generally held, such talk is elliptical for talk of arbitrarily short, non-instantaneous states of affairs.  When we say that such that such and such is what obtains at a given instant t, we mean that what obtains during smaller and smaller intervals containing t approximates arbitrarily well to such and such. 
        The most obvious illustrations of this principle involve statements about velocity. There can be no movement, and hence no velocity, at an instant. When we say that x is moving with velocity v at instant t, we mean that as we consider smaller and smaller intervals containing t, x’s velocity during those intervals comes arbitrarily close to v.  But exactly similar considerations warrant the view that there can no instantaneous temperature, mass, color, shape, spin, and so on. There are no strictly non-dynamic spatiotemporal properties – no property such that possession of it doesn’t involve movement. So for reasons exactly similar to those warranting the rejection of instantaneous velocity, we must reject the notion of anything instantaneous. A corollary is that there is no complete description of any state of affairs that does not say what happens over a stretch of time. 
       An argument exactly similar to the one just given establishes that no state of affairs occupies an unextended point. Of course, we say that such and such is the case at a certain point p. But that means that as we consider smaller and smaller regions of space intervals including p, what obtains approximates arbitrarily well to such and such. The statement “the temperature at point p is 88°” is in the same category as  “x is moving 54 mph at instant t.” Both are meaningless unless taken as elliptical for limit-statements of the sort just discussed.
       Now let us turn our attention back to A and B. Consider all the events, down to the last electron-jump, that are involved in the button’s being pushed. The pushing of the button is not one event, but billions upon billions, as it supervenes on innumerable displacements mass-energy. To give a complete description of the pushing of the button, we’d have to describe each of these displacements. 
       Focus on an arbitrary one of these mass-energy displacements. To give a complete description of this displacement, we must obviously describe what happens during some stretch of time, however short that stretch may be. For there are obviously no instantaneous displacements of anything. Suppose, then, that we confine our description to what happens within some interval -- call it int -- of time. Suppose, in other words, that we don’t allow that description to be infected with talk of anything happening before or after int. Let D be the description in question, and let t be the instant at which int ends. 
        If we want D to constitute a complete description of what happens during int, D would have to include a complete description of what happens up until t. Here we have two choices. We can say that D includes a description of what happens up until, but not including, t. Or we can say that D includes a description of what is happening at t itself. Let us consider each case. 
        Suppose we say that D includes a description of what happens at t itself. As we have seen, that means that D includes a description of what happens during some interval int* that includes t and thus stretches past t in time. In that case, a complete description of the occurrences during int would include a description of occurrences happening after int. So a complete description of the relevant mass-energy displacement (the relevant electron-jump or whatnot) would include a description of some later event E. This would have two consequences. First it would mean that any description of any given event would include a description of subsequent events. That by itself would shatter Hume’s view that there is no necessary connection between any event and any subsequent event. Second, everything we said about int would apply (mutatis mutandis) to int*. This means that to give a complete description of the occurrences during int* , we’d have to describe the events in some neighboring, but subsequent region, of time int** -- and on and on. By this reasoning, there is a strictly logical connection between (complete descriptions of) any two events that are connected by a continuous series of events. (For reasons already given, the parenthetical qualification does not trivialize our thesis.) Given any proposition completely describing event E, that description includes a description of what happens during each event connected to E by a continuous series of events. So there would be a strictly logical connection between the occurrences constituting the pressing of the button and those constituting the arrival of the elevator. (Or, more accurately, there would be a strictly logical connection between the propositions giving complete descriptions of those events.) Our belief that there is no such connection would have to be seen as a projection into the external world of cavities in our belief-system. 
        So if we are to hold onto Hume’s view, we must not let D include a description of what happens at t, but only a description of what happens up until t. But this doesn’t change anything. If D is to include what happens up until t, then for each time t* within int, D must give a complete description of what happens at t*. For the reasons we’ve given, any complete description of what happens at t* will include a description of what happens later than t*. This reproduces an exact analogue of the situation described a moment ago. Let D* be a complete description of what happens at t*. By reasoning exactly similar to that given earlier, D* logically entails that some event E later than int* occur; and a complete description of E1 will entail the occurrence of some event E2 occurring still later – and so on. 
       One might parry this by insisting that our description of int* include everything up to, but not including, t*. But that would only push the problem back. Even under that circumstance, D* would completely describe what is happening at some time t** (prior to t*); and for exact analogues of the reasons just given, that would shatter Hume’s denial of necessary relations between distinct events. The only way to circumvent this is to keep on insisting that our descriptions not include what happens at the bounds of the relevant intervals. But by reasoning similar to that just given, that procedure fails, so long as the intervals have some non-null duration. We don’t have to consider whether it works for null durations, since “null duration” is a contradiction in terms. 
   
III.    Hume’s position, then, involves two blunders. First, it fails to recognize that logical relations hold among pieces of information, not among states of affairs. Second, it assumes that there are infinitely short, and infinitely small, states of affairs. But given any property F, it is nonsense – false on conceptual, as opposed to empirical grounds -- to speak of F’s being instantiated in spatial or temporal point. 
      Admittedly, there are apparent exceptions to this. It might seem to meaningful to say that x is a square at instant t. After all, squareness is (it seems) a three-, not a four-dimensional property. But this is not so. It would be meaningless to say that x was a square, but then to deny x any of the associated causal or kinematic properties. For x to have the shape of a square is for x to be a dynamic system of a certain kind. 
       Given a four-dimensional system whose behavior remains constant in some key respect, we tend to see that system as non-dynamic in that respect. But this involves a confusion of the having of four-dimensional properties with the gaining and losing of such properties. What we are inclined to describe as four-dimensional properties (e.g. acceleration) are really changes in four-dimensional properties and are thus properties of properties. What we describe as three-dimensional properties (e.g. mass, shape) are usually just first-level four-dimensional properties, as opposed to the hyper-properties just discussed. 
       We must also remember that motion and persistence are themselves causal phenomena. To say that x has endured for a certain period of time, or has moved from A to B, is to make a causal claim. It follows that no state of affairs can be described by a non-causal proposition, making it impossible even to articulate Hume’s puzzle regarding causality in a way that doesn’t presuppose its existence. 

§   We have discussed how talk of infinitely short or small events is really talk of arbitrarily short or small events. I would go further, and say that talk of instants and points is itself talk of arbitrarily small, or arbitrarily short, occurrences. (Here I am following others, including Whitehead, Russell, and Einstein himself.) It isn’t logically or epistemologically possible to start with empty points and instants, then fill them (so to speak) with states of affairs, and then build spatio-temporally extended events out of those. Instead, we must start with events and, on that basis, work our way backwards towards points and instants.   
      There are no minimal events. To say that space-time consists of points and instants, as opposed to granules of non-null size, is to say that events have an “analogue”, and not a “digital”, structure.  (A sentence is a digital representation: it has minimal units of significance. A photograph does not have minimal units of significance, and is thus analogue. ) That events have an analogue, as opposed to a digital, structure neither follows from, nor is rendered possible by, the fact that space-time consists of points and instants. Rather, space-time’s consisting of instants and points is identical with events’ not having a digital structure.
        As we’ve noted, linguistic representations decompose into minimal parts. This seems to be a defining fact about language, at least of the languages we use in discursive contexts.  (Artistic expression often involves an analogue medium. So if, as some maintain, such media are actually languages, then there are non-digital languages.) This reflects the fact that it is hard for us to understand what we cannot digitize. (It is also a possibility that discursive understandings consists in digitization, at least up to a point.) It also reinforces a pre-existing tendency to associate understanding with deconstruction into minimal, discrete parts. The belief that space and time are composed of points strikes me as a projection into the physical world of this fact about language. The belief that temporally extended events must be built out of non-extended events is sheer anthropomorphism, and is thus to be put in the same category as the view that rocks fall because being near the earth reduces their anxiety level. 

IV.    Once it is granted that discourse about points and instants  is elliptical for discourse about extended (but arbitrarily small or short) events, the problem ceases to be how to establish a necessary connection between distinct events, but rather how to prevent any two events from having such a connection. 
       Hume assumes that there are entirely non-causal descriptions of states of affairs. Billiard ball X rolls into billiard ball Y. X stops, and Y starts rolling. The causal connection, says Hume, consists only in the fact that the situation just described is an instance of some regularity. What Hume doesn’t realize is that each of the statements involved in describing that scenario is replete with causal content. X’s rolling is causal; so for that matter is Y’s standing still (relative to the pool-table). The persistence of each of those objects is itself a causal fact.  
        We tend to think of causation as involving some sort of disruption. The mere persistence of Y is not, we feel, sufficiently disruptive to involve any kind of causality; neither is the mere rolling of X. The problem with this viewpoint is that the concept of a disruption has only a psychological or pragmatic significance. From a purely physical standpoint, the transference of motion from X to Y is no more disruptive, no greater a change, than X’s rolling or Y’s persistence. This is not to mention that, given the relativity of motion, what counts as mere persistence as opposed to motion is framework-relative. 
        Hume’s puzzle thus presupposes a highly anthropomorphic conception of causality: there are causal relations only where there are events that are psychologically disruptive. But such a conception is no basis for any analysis of causality. 
        Given a correct conception of what instants and points are, we may conclude that, given a complete description of A and B, those events turn out to be no less contingently related to each other than are the square of three and the predecessor of ten. The considerations generally cited to the contrary are artifacts of tendentious descriptions of the events in question. 
      Hume’s analysis of the concept of “force” is beyond reproach. But that analysis is moot since, contrary to what Hume held, we don’t need forces to connect cause and effect. 
        Hume is also right that there is no necessity other than logical necessity.  Philosophers have had one of two reactions to this. Either they’ve rejected it, on the grounds that there is such a thing as nomic necessity and that it is not logical necessity, or they’ve denied the existence of nomic necessities (this was Hume’s reaction). 
          But both reactions are false. There is obviously some principled connection between the pushing of the button and the ascent of the elevator. (Attempts to reduce such connections to constant conjunctions have not faired very well, though they persist to this day. ) The apparent absence of a logical connection between the two is an artifact of the impoverished descriptions of those events employed by philosophers attempting to demonstrate the irrationality of induction. Further, those descriptions are typically embedded within discussions that involve a conception of space-time that has been questioned since Leibniz, and that has was decisively refuted over a hundred years ago.  Finally, those descriptions never mention the fact that the data that motivates (and, so I will argue, justifies) our inductive beliefs is never, in the final analysis, propositional. That data is perceptual, and thus doesn’t decompose into permutation-friendly entities like propositions and sentences, and is thus less likely to reinforce the false view that space-time is comparably permutation-friendly and thus incapable of hosting events that have internal connections to one another. (We will soon develop this last point.)


V.       The viewpoint developed so far is not hard to corroborate. These days it is generally accepted that: 

(O) E precedes E* in time exactly if there is some (possible) causal process, e.g. a light ray, beginning with E and ending with E*.  

     This suggests that temporal order is itself a causal notion. Obviously there is no atemporal description of anything spatiotemporal. It follows that any description of anything spatiotemporal is itself a causal description. If that is right, then it is not possible even to articulate Hume’s objections to causality. 
      Recognition of (O) was forced on us by empirical discoveries, in particular by Relativity Theory. But is (O) itself an empirical statement? I think not. If there is no possible causal connection between E and E*, then it makes little sense to say that they have any spatial or temporal position with respect to each other. If there is no conceivable way that anything could travel from the place of E to the place of E*, then it is unclear what it would mean to say that E and E* were separated by such and such a distance.  Similar considerations make it hard to believe that, absent some kind of causal relation between them, one of those events could be meaningfully described as coming before the other. It seems, then, that (O) is less like all and only rhenates are chordates than it is like all and only triangles are regions bounded by three coplanar lines such that any two of them, but not all three, intersect. 
         
VI.   Hume famously argued that there are no strictly logical grounds for the view that every event must have a cause – that there are no ex nihilo events.  His argument is simple: propositions alleging uncaused events, e.g. the newspaper spontaneously combusted, are not self-contradictory. Since what is not self-contradictory is possible, ex nihilo creation and change is therefore possible. 
     This is a corollary of the view that propositions assigning causal relations to pairs of events never have a strictly logical foundation. It is therefore to be expected that Hume’s argument for the possibility of ex nihilo creation involves the fallacies we’ve just been considering. 
     For E and E* to be spatio-temporally co-located is for them to be causally related. The spatio-temporal manifold would comprise ex nihilo (uncaused) events only if it comprised events that were not co-located with other events – only if it comprised events that it didn’t comprise. 
       I believe that Hume’s analysis of induction is bound up with his belief in the logical possibility of ex nihilo creation. As we’ve just seen, the latter belief is itself an application of his digital conception of spatio-temporal reality. In a moment, I will argue that, when we appropriately de-digitize this conception, Hume’s analysis of induction crumbles. I will also argue that this de-digitization involves little more than distinguishing between, on the one hand, the sensory data that motivates our inductive and theoretical judgments and, on the other hand, the propositions we use to model that data.   

Summary of sections I-VI.

      By “spatio-temporal continuity”, I propose to mean the kind of continuity had by series of states of affairs -- as opposed to, say, series of numbers. Henceforth the term “continuity” will be elliptical for “spatio-temporal continuity.” 
      With the help of this new terminology, we may now sum up our findings. Hume’s conception of causality involves a falsely “digital” conception of spatiotemporal reality.  In his view, each region of space and of time is a distinct box that can be filled with a state of affairs. If the contents of one of those boxes are replaced or annihilated, that has no ramifications as far as the other boxes are concerned. The spatio-temporal world is thus, almost by definition, completely permutation-friendly. Given this viewpoint, it becomes trivially impossible to establish any causal relations between distinct events. The permutation-friendliness definitive of spatio-temporal location, as Hume understands it, is identical with the absence of causal connections between distinct states of affairs. But this conception of spatio-temporal relations cannot be sustained, as the following argument shows. 
       Persistence is a causal phenomenon. Spatio-temporal continuity is a form of persistence. Consequently, continuity is a causal phenomenon. By definition, continuity has no place in a digital system. Hume’s “demonstration” that there are no causal relations (or that such relations reduce to regularities) is thus an artifact of his assumption that space and time have a structure comparable to that of an array of digits.  But that assumption question-beggingly presupposes the very conception of causality that Hume is trying to defend. 
          I said that “continuity involves persistence.” At first this seems false. Imagine an object that is changing continuously  in every respect – mass, motion, shape, and so on. Surely, we will be told, that doesn’t involve persistence. But it does. The chair you are sitting on is a paradigm case of persistence. But it is now changing along all those dimensions. Every case of persistence is a case of continuous change. What we describe as changes are actually changes in the manner of change. They are higher-order changes. So there is no continuity without persistence, just as our argument supposes. 
   
VII.  Hume’s tendency to digitize blinds him to the logical basis of induction, since induction, as I will now argue, consists in positing exactly those continuities that would “de-digitize” our description of reality.   
       Hume is, of course, entirely right to say that 

(a) every swan I’ve ever seen is white 

does not entail 

(b) the next swan I will see will be white. 

But this does not have the consequences that Hume believes it to.  Hume’s argument presupposes that our grounds for (b) consist in (a), or perhaps in (a) conjoined with a finite number of other propositions, say: 

(a2) in my past experience, there is little or no variation in respect of feather-color within a species of bird; 

(a3) in my past experience, if members of a species significantly vary in one respect (e.g. the color of their fur or plumage, or the nature of their reproductive organs), then they are likely to vary in some other respect (their body-size, their behavior towards predators);

 (a4) in my past experience, differences in plumage or fur-color vary with geography only when special conditions are met, none of which are met in this case. 

And so on. 
      Our knowledge of propositions like (a)-(a4) is certainly part of our grounds for inferring (b). But there are other grounds. In fact, we are subtly misrepresenting our grounds for believing (b) when try to propositionalize (and thus digitize) them. Strictly speaking, it is not our knowledge of (a)-(a4), or of any other propositions, that motivates and justifies our inductions: what does so is the sensory data that those propositions so schematically model. Hume’s argument is supposed to concern the data that warrants (or is supposed to legitimate) our inductions. In actuality, his argument concerns certain models of that data. In some cases, it harmless to confuse the model with the thing modeled. This is not one of those cases, as I will now argue.

VIII.     Ultimately, our perceptions are, as Hume himself insists, our only source of information about the spatiotemporal world. Hume is therefore right to say that, like all other empirical beliefs, our inductions can be justified only by sensory experience. 
       Where Hume goes astray is in his failure to register a crucial fact about sensory information. The content of a perception doesn’t decompose in the same way as the content of the propositions that we would typically use to report those perceptions. If I see a swan, I will say “I see a swan; it is white; it is eating a fish…” But my perception doesn’t have a corresponding breakdown. It isn’t as though a single part of my perception corresponds to the concept swan, another to the concept eating, and so on. What is reported by such a proposition is not the content of the perception itself, but rather a judgment about the content of that perception. Describing such propositions as “data” is like identifying a court’s finding of guilty with the actuality of guilt. 
        There is thus a sense in which (a)-(a4) are not the data that motivate (or legitimate) belief in (b). (a)-(a4) are not data, but meta-data. We cannot work backwards from meta-data to data. That is like trying recover the subtle inflections of a person’s speech from a court-stenographer’s transcript. (In fact, that would be a special case of the principle we are considering.) The logical basis for induction is precisely what is lost in the process of digitization involved in embodying one’s knowledge in (a)-(a4). 
        When you see a white swan, what your perception gives you is a continuous state of affairs. When you induce, on the basis of your perceptions, that all swans are white, you don’t have in mind the sort of “data” embodied in propositions like (a)-(a4). You have in mind the kind of data that leads to, but is quite distinct from, a belief in such propositions. The data that actually motivates your belief in (b) is embodied in analogue representations. What is given to you in such representations is never a discrete state but, at most, a relatively discrete state of affairs.  
       Any given perception presents a continuous reality. It is a datum that what is given to you in a given perception is spatio-temporally co-located with what is given to you in other perceptions. (It might seem that this “datum” itself presupposes the legitimacy of induction and is thus no datum at all. In due course, I will argue that it is in fact a datum or, at least, is a belief whose legitimacy doesn’t presuppose that of induction.) 
        For reasons already considered, this means any two non-simultaneous states of affairs are causally related. This, in turn, means that they are connected by a continuous series of  events: no ex nihilo changes are involved. It also means, as we’ve seen, that a correct and complete description of an empirical state of affairs permits a deduction of the events  in its neighborhood. We’ve seen that, for an arbitrary event E, if D is a complete description of E, then D does entail the occurrence of events that, by ordinary standards, are distinct from E. 

IX.   In light of this, let us consider some counter-inductive inference, e.g. 

(A) this time, when I open my hand, the rock will not fall, but rather will sprout wings and fly away. 

To make such an inference is, implicitly, to hold that the scenario described by (A) is a logical consequence of a complete description of any of the events in its neighborhood, in particular, the complete descriptions of the events composing your hand, the rock, physical media involved, and so on. This means that, in making such an inference, one is committed to holding that the state of affairs described by (A) would be continuous with the events in its neighborhood. 
    Superficially, it seems as though that state of affairs would be no less than continuous with those events than would the event described by the inductively acceptable proposition: 

(B)  This time, when I open my hand, the rock will fall. 

But remember that the state of affairs described by (A) must be continuous with the states of affairs described by every proposition we know to be true. We must also remember that the state of affairs described by (A) would have a much richer structure than (A) itself. The rock’s flying away would not be an ultimate, primitive event. It would supervene in innumerable others -- some perceptible, some not. The propositions  describing some of these constituent states of affairs would involve rather obvious discontinuities with the events in their neighborhoods. 
      (A) itself seems innocuous. There doesn’t seem to be any problem fitting the event it describes into a coherent narrative.  Such a viewpoint, I think, confuses the proposition with the reality. Propositions have discrete, easily replaced parts. States of affairs do not. Hume holds that counter-inductive beliefs like (A) involve unusual, but otherwise acceptable, permutations of objects and properties. I would agree that (A) itself can be so described. But states of affairs cannot be understood in combinatorial terms; they don’t consist of discrete, replaceable parts. They don’t consist of parts whose replacements can even coherently be thought. 
      When we say that we can coherently think some such replacement, we are, I believe, making a statement about the logical properties of the corresponding propositions. This means that we are tendentiously stripping our representations of those states of affairs of information that, if left in, would render such intersubstitutions logically impermissible. 

§     It is tempting to think that (A) is logically incompatible with the existence of known facts, like that described by:

(C) no stone known to anyone has ever sprouted wings.

Hume rightly said that (A) and (C) are compatible propositions. But this says very little about either the states of affairs corresponding to those propositions or about the non-digital (analogue) data schematically represented by those propositions. 
       We must distinguish between digital- and analogue-compatibility. We must distinguish what is permissible, given propositions like (A) and (C), from what is permissible given the analogue data of which (A) and (C) are schematic representations. 
       For the sake of argument, suppose that somebody actually saw the state of affairs described by (A). Let (A*) be the information embodied in that visual perception, not the hyper-schematic work-up of that information embodied in (A). Now let (C*) be the information embodied in the perceptions that lead to our believing that stones never sprout wings. For reasons already considered, (C*) must be distinguished from the schematic work-up of that information embodied in (C). So given only that (A) and (C) are logically compatible, it cannot be inferred that the same is true of (A*) and (C*). Further, I would suggest that when we reconsider the data leading to belief in propositions like (C), i.e. when we consider (C*), we find that all kinds of discontinuities and perforations of the space-time manifold would be involved in a belief in (A). 

§    We must also remember that (A) must be logically consistent not only with the data represented by propositions like (C), but with all the data. When this constraint is taken into account, the logical permissibility of inferences like (A) becomes more questionable than Hume makes it out to be. 
      A metaphor from music may help. Given any short sequence of notes, there are innumerably many musically feasible combinations of notes may follow it. But in a musical composition, it is not enough that each bar not clash with the bar preceding it; any two bars have to fit with the bars flanking them; and those four bars must fit with the two bars flanking them; and so on.  What is musically possible given any one bar is usually not possible in a broader context. 
      There are many ways to replace bar 58 of Mendelssohn’s Italian Symphony without ruining bars 57-58. But, as we’ve just seen, it would be absurd to infer from this that there are equally many ways to replace bar 58 without ruining the whole symphony, or even there are any viable replacements. Hume’s conception of induction involves a similar fallacy. When we say that (A) is merely counter-inductive, we are excluding two types of information. First, we are considering only propositional data (we’ve already considered the effects of this). Second, the propositions we select for special attention are not the only ones that embody that relevant data. We focus only on the ones that we believe to be important, given our erroneous theories about our inductive practices. I will spend the next section delineating this obscure statement.

X.     If you ask Bob why he fell in love with Mary, he will probably give you an answer that is either wrong or ridiculously incomplete. He may say “I liked her smile” or perhaps “we both like to dance.” Those answers may have some validity. But the psychological mechanisms responsible for them are less directly connected to the forces that actually shaped Bob’s feelings than to Bob’s simplistic and possibly defensive views about those forces. 
        Just as Bob has instinctive beliefs about why he loves Mary, so we have instinctive beliefs about why we think we believe that the pan is hot. I am not talking about our beliefs as to why the pan is hot. In my view, such first-order beliefs are typically cogent. I am referring to our beliefs as to why we have those beliefs. Those meta-beliefs can no more be regarded as authoritative than can Bob’s stated answer about why loves Mary. If you ask Bob “why do you believe that the fire is hot?”, he will say “because every other fire I’ve seen turned out to be hot”, or some such.  (To simplify discussion, I am assuming that Bob is reasonably articulate, and doesn’t answer with a shrug or a circularity like “I don’t know, I guess because fire is hot.”) The answer that Bob would give would, in fact, not be very different from the answer that a Hume or a Karl Popper would give. If that answer were accurate and exhaustive, then Bob’s belief would indeed have no rational basis. But the psychological mechanisms that generate that answer are less directly connected  to the forces that shaped Bob’s belief than they are to Bob’s Pavlovian theories about why has that belief.
       Part of the reason one believes that future fires will be hot is that past fires were hot. But the reason one gives weight to that fact is to be found in other pieces of knowledge in one’s cognitive background. (This background comprises tacit or sub-personal knowledge – not knowledge that can readily be articulated.) 
         Here are some of the truths that, I propose, are stored in this background. Mediating between the present and the past are continuous processes. Temporal and spatial relations involve continuity, persistence, and causation. Where there is ex nihilo creation, there is an absence of causality and, therefore, of spatio-temporal relatedness. So far as a hypothesis posits such breaches, it is inconsistent with the datum that everything we experience – our inner-states and their external counter-parts – are spatio-temporally (or, at least, temporally) co-located. Counter-inductive hypotheses implicitly involve such breaches. Therefore such hypotheses are not to be countenanced.
          Hume wrongly saw our theories as created by associative mechanisms. But it is our theories about our theories, not the theories themselves, that are created by such mechanisms. What Hume falsely said about our thinking -- that it consists entirely of a kind of Freudian free-association  -- is true of Hume’s thinking about our thinking. When you try to articulate the grounds for an inductive belief of yours, you tend to access the relevant data by way of associative mechanisms. The question “why do think that fire is hot?” triggers associations. It is obvious to us that some of these associations are irrelevant. But, with that qualification, our answers typically don’t go much beyond what those associations give us. So we answer such questions with fatuities like “because other fires are hot” or “because fire looks like magma, and magma is hot.” From Hume to the present, our theories about induction have only been elaborations of those association-based answers.

§       Our associative mechanisms track psychologically pregnant disruptions, and thus skip over the continual changes mediating between such disruptions. It is not that those associative mechanisms give us the wrong information. They typically point us in the right direction: my psychological association of fire with heat grounds a correct belief. But our associations refer us to singularities, and not to underlying continuities. Given that association is an affect-driven process, it is to be expected that it will refer us to emotionally pregnant breakdowns in the uptake of perceptual information, and not to the smooth flow of information mediating between such cataclysms.
        Of course, there is no way to work backwards from such decontextualized data-points to the logical underpinnings of our theories. When we try to do so, we run into the problems identified by Hume. But this doesn’t mean that there is no logical basis for induction; it corresponds only to the trivial fact that we can’t recover the logical basis of our inductions from degenerate representations of that basis --  representations that highlight what is emotionally (or affectively) significant, and leave everything else out. 
       Our experience gives us smooth curves. Our sentential representations of our experience (“past fires have been hot”) give us isolated points that are compatible with infinitely many different curves. On this basis, Hume and others say that there is no logical basis for induction. But that doesn’t follow, since the justification for our inductions lies in the smooth curves of experience, and not in the jagged edges of our descriptions thereof. 
        Hume’s views on induction are thus artifacts of his own methods. Given an association-driven review of our inductive-practices, it is indeed going to be impossible to recover the logic that underlies them. By their very nature, such associations leave out emotionally sterile, but logically crucial, connecting information. 
        Hume’s empiricism as a whole is a study of artifacts. Since, in his system, knowledge is identified with sequences of images, it follows trivially that reality must be understood in terms of the associative-mechanisms governing such sequences. Being affect-driven, such sequences track disruptions, skipping over the emotionally neutral periods that intervene. A reality seen through the lens of such processes will inevitably consist of singularities – as breakdowns in the conditions that permit causal and inductive explanation.  

XI.    Here are some points that, I believe, are crucial to a correct understanding of induction. A given proposition (e.g. John is eating chicken) has a structure that is not remotely comparable to that of the corresponding reality or to that of the perceptual data through which we learn about that reality. Causation is bound up with continuity – with the very features of reality that resist the sort of digitization associated with sentences. Finally, the viability of induction is bound up with the existence of causal mechanisms linking states of affairs.
        All of this is obvious. It therefore follows from what is obvious that the logical relations holding between two propositions will not typically do justice to the relations of necessitation (causal and explanatory) holding between the corresponding states of affairs. There must, I would therefore suggest, be a purely emotional basis our failure to see this, and for our subsequent willingness to accept Hume’s otherwise unpalatable nihilism regarding causation and induction. In a moment, I will try to identify that emotional factor. But first I would like to identify another symptom of it. 
         Throughout its history, logic has been identified with the logic of sentences or of para-sentential entities like propositions. But, as we’ve seen, not all data is embodied in sentences. The existence of digital representations, like sentences, is parasitic on that of non-digital representations. So ultimately data is always embodied in media that are not only not sentences, but lack the defining feature of sentences: namely, decomposability into minimal units of significance. The concept of information is inseparable from concepts like entailment and compatibility. So obviously logical relations hold among analogue-information, and are not confined to sentences. Sentence-logic is therefore but one kind of logic and, in light of the derivative nature of digital information, is a fairly superficial kind of logic. The identification of sentence-logic with logic as a whole is so obviously false that we must wonder what induced us to acquiesce to it. 
       I believe that acquiescence to be motivated, at least in part, by a wish to rationalize the tendentious and emotion-driven conception of reality embodied in Hume’s empiricism. Our acceptance of Hume’s analyses of causation and induction, despite their obvious discordance with everything we believe, is a special case of that acquiescence and is thus an expression of that same wish. The compartmentalizations embodied in a digital conception of reality give legitimacy to associative mechanisms that have an emotional basis and in which we therefore have an emotional investment. 

Summary of sections VII-XI. 

      Given the non-digital structure of the spatiotemporal world, there are purely logical limits as to what hypotheses can be coherently entertained. So far as we think otherwise, it is because we are wrongly identifying that data that motivate our hypotheses with the propositions that we use to model that data.  
     Logical relations are generally seen as holding between digital representations – between sentences and para-sentential entities like propositions.  We have seen that logical relations hold among non-digital, and therefore non-propositional, data. The principles governing these relations have yet to be articulated, and a priori resist articulation within a digital medium like language. 
      Correct inductions are analogue-logically valid inferences from the data embodied in our sense-perceptions. Counter-inductive inferences are analogue-logically invalid inferences from that same data. 

Part 3. Some Consequences of our System
  
I.  Here is the classical argument for skepticism about the external world. If you know anything about the external world, such knowledge is derived from your sense-perceptions. But the proposition that there is no external world is logically consistent with the existence of those perceptions, as is the proposition that there is an external world bearing having little or no correspondence to what those perceptions allege to be the case.  We beg the question if we respond by saying that our perceptions probabilify our empirical beliefs, while not giving them 100% certainty. To know that x is probable given y, we must know that events relevantly like x accompany events relevantly like y. Unless we already have some assurance that our perceptions are veridical, we cannot know that events of the appropriate types ever accompany our perceptions, let alone that they do so with enough regularity to warrant our views about the external world. But of course it is precisely that assurance that the skeptic’s scenario prevents us from having.
 
II.    We may be in a position to shed some light on this matter. The skeptic’s position involves the view – actually, it is the view – that our perceptions are ex nihilo creations, having little or no continuity with events in their vicinity. Because such discontinuities are incompatible with the datum that our perceptions are temporally co-located, it is illogical, and not merely counter-intuitive, to believe in their existence. So far as philosophers believe otherwise, it is because they are conflating the data given to us in experience – the data constitutive of experience, in fact – with our propositional schematizations of it. 
       Let us begin our defense of this with an innocuous background point. It is a datum that our mental events are temporally co-located. It is a datum that the itch I felt a moment ago is on the same time-line as the twinge I am feeling right now. 
       We saw earlier temporal succession is a causal notion. Where there is a fissure or discontinuity, there is no temporal succession, unless some other continuous sequence of events steps into the breach. Suppose that the elevator doesn’t come after I push the button, since somebody has severed the wire that is supposed to transmit the signal. Does that mean that no continuous series of events connects the state of my finger at t with the state of the state of the elevator at t*? No -- it means only that one such series has been interrupted. Countless others such series connect those systems. (We may ignore as irrelevant the fact that those other series are not very useful to somebody who wants to use the elevator.)
     Given two completely disconnected events, it cannot significantly be said that one precedes the other. Of course, events that are relatively disconnected can be related in time. My current bodily condition may not have any explanatory, or otherwise significant, connection with that of some long gone dinosaur. (If I wanted to explain my current bodily state, I would mention the fact that I didn’t sleep enough last night; I would not mention any dinosaur.)  But that means only that our current theoretical and pragmatic concerns don’t force us to pay attention to the various series that obviously do connect me to the dinosaur. 
       The world of the skeptic is discontinuous on a number of levels. Sleep obliterates consciousness. So if the skeptic is right, then every awakening is a case of ex nihilo creation. But sleep and unconsciousness would not be the only sources of ex nihilo creation in the skeptic’s world, since many discontinuities are internal to the state of wakefulness. One’s waking visual experience is subject to constants interruptions, as when one closes one’s eyes to relax or reflect. A skeptic must say that each resumption of visual experience is a case of creation ex nihilo and that each cessation of it is a case of annihilation. In fact, even if we confine our attention to an uninterrupted steam of visual experience, we find that it too involves innumerable discontinuities – qualia come into existence out of nowhere, and just as abruptly vanish into oblivion.
         It is a datum that our experiences are temporally co-located. For reasons we’ve discussed, it follows that any two experiences are connected by a continuous series of states. Therefore the discontinuities described a moment ago are merely apparent. If those discontinuities reflected the ultimate structure of reality, then there would be no temporal connection between the experiences of the person who wakes and the one falls asleep. It is a datum that there is such a connection, and that there is no real discontinuity.           
         Obviously the mental realm cannot furnish the requisite continuities, and must therefore be supplemented by a non-mental realm. If the occurrences in that non-mental realm are to furnish the needed continuities, they must have a character at least approximating to that suggested by our perceptions. We saw earlier that counter-inductive hypotheses are logically incompatible with the data embodied in our experiences, even though they are compatible with the more obvious propositionalizations of that data. There are thus strictly logical reasons why, given that data, it is not an option to countenance counter-inductive hypotheses as to the nature of the non-mental events that establish the continuities presupposed by our experience. So there are strictly logical reasons why we must say that it is the activity of rocks and trees, muons and quarks, and not of a capricious demon, that accounts for the existence and specific character of our mental lives. 
         In conclusion, supposing that our cognitive processing of the information embodied in our sense-experience is logically valid, the datum that our experiences follow one another in time is logically inconsistent with the skeptical proposal that reality is exhausted by one’s mental states, and also with the proposal that there is an external reality having little significance correspondence with our perceptions. It must be kept in mind that the logical validity just mentioned is analogue-logical validity. It must also be kept in mind that any propositionalization of our experience is a model of our experience, and not the experience itself. Consequently, if we attempt to justify (or dismiss) inductive beliefs on the basis of such propositionalizations, we are committing the same fallacy as a juror who gives more weight to a defense-lawyer’s theory than to a video-recording of the defendant committing the crime. 

III.     It is often said that a “brain in a vat” could have exactly the experiences we do. I agree. It is inferred from this that our perceptions needn’t be veridical to any degree. I do not think that this inference is warranted. 
       Suppose that a scientist, or even a series of random occurrences, is stimulating brain B in such a way that B  has a flow of experience qualitatively just like yours. B would have many false beliefs. In particular, it would have the belief that it wasn’t a brain in a vat whose experiences were the fall-out of scientific tom-foolery or of random events. 
       But we must remember that the behavior of the scientist (or of the random series of events) would have the formal properties supposed by B to be had by the external world. Suppose we fool someone into believing that they are in Hawaii by placing outside their window a giant computer monitor showing scenes from that tropical paradise. That person does indeed have the wrong beliefs – he wrongly believes that he is witnessing people frolicking on a sunny beach in Hawaii. But he has those wrong beliefs only because the images on the monitor have much the same structure as the sort of beach-side revelry that he wrongly believes to be occurring outside his window. That person therefore has a great deal of formal knowledge about what is going on outside his window, even though his interpretation of this formal data is in error. 
        It is true that, from a social or pragmatic viewpoint, that person’s beliefs are quite wrong. But that person -- call him Smith – knows much more about the occurrences outside his window than our best physicist know about the sub-atomic world. Our belief that Smith has no knowledge embodies our tendency to think in emotional, rather than strictly epistemological, terms.
        Let us illustrate this with a bit of fiction. Smith has a gift for abstract thought. He is thus able to give a formal description of what he sees, and can leave out the emotional or pragmatic pseudo-information that would constitute almost the entirety of an ordinary person’s discourse. So Smith’s description doesn’t contain emotional extrapolations like: “my prayers are answered! I no longer have to suffer the torment of those long Chicago winters!” Smith’s description is a conservative and accurate description of what he actually sees – certain patterns of mass-energy displacements. In terms of richness and accuracy, Smith’s description of what is going on outside his window would dwarf our best descriptions of the sub-atomic (or even the sub-molecular) world.  So when we say that Smith’s views are “completely wrong”, what we are saying is completely wrong, unless there is an implicit relativization to some irrelevant social or emotional context. 
        Systematic deception always involves making certain allowances for the formal structure of the realities being misrepresented.  For this reason, Smith is, in absolute terms, quite well-informed about the occurrences outside his window. It is true that our initial impulse is to say the exact opposite. But that is because our initial impulse is to speak not in narrowly epistemic, but in broadly emotional and sociological terms. 
       For exactly similar reasons, envatted brain B would, in absolute terms, be quite well-informed as to the nature of the reality lying beyond its experiences. Of course, B would be quite wrong about everything that had any emotional significance. B would be wrong to think that he had fallen in love with Mary, that he had finally stood up to his brutal boss, and that he had discovered true goodness beneath the gritty exterior of his cousin Fred. These friends and foes would all be non-entities, along with his house on tree-lined Maple street and his loyal dog Skippy. B’s real home is a sterile plastic tank monitored by disaffected scientists, and his only true companions are the electrodes connecting him to some computer console.
      But if we confine ourselves to the formal aspects of B’s world-view, and leave aside its (in this context) meaningless emotional projections, we find that B knows incalculably more about the external world than we do about anything beneath the molecular level. The presumption that B knows nothing about the external world incorporates an irrelevant pragmatic or emotional perspective. 
      The natural response is to say that, in order for B to have those experiences, it isn’t strictly necessary for those events to be caused by anything having even a formal resemblance to them – that talk of a scientist who is deliberately deceiving B is just an illustrative device. 
        For reasons we have already discussed, that is not the case. Absent a scientist, or some surrogate (e.g. Descartes’ evil demon), our skeptical scenario would involve the breaches and discontinuities incompatible with the temporal co-locatedness of B’s experiences, and thus impossible on strictly logical grounds. 
        Another skeptical response to our analysis is to say that, although the events vanishingly close to B’s nerve-endings may have a certain isomorphism with B’s experiences, that isomorphism dwindles to nothingness as we move away from the relevant neural contact-points. 
       We’ve already seen how to respond to this. Causation involves continuity. Given how rich and articulated our sensory experience is, and given that every aspect of it must arise by way of continual changes from external realities, it is logically out of the question that the correspondence between our perceptions and external reality should be confined to our bodily surfaces. As we’ve seen, once it is settled how the world is in one small area of space-time, the rest of the world is locked in. So once it is granted that there is some correspondence between perception and reality, the scope of that correspondence cannot be trivialized.  

 §   This is not to say that all knowledge is analytic. No knowledge of the external world, or even of the internal (psychological) world, is analytic.  As we saw in our discussion of Kant, all spatio-temporal knowledge is empirical and therefore synthetic a posteriori. Moritz Schlick’s slogan “no synthetic a priori” is a simple truth.       
       Nonetheless, given the data embodied in our states of consciousness, some theories are permissible and some are not; some theoretical articulations of that data are logically valid (i.e. analogue-logically valid) and others are not. Given our experiences, it analytically follows that there is an external world having a character not entirely at odds with that suggested by our perceptions. Indeed, it follows that there is an external world corresponding, at least approximately, to the theoretical superstructure we impose on the data of experience, at least in so far as that superstructure doesn’t involve any purely logical blunders. 

IV.     Hume’s counter-intuitive analysis of causation presupposes that spatio-temporal relations are non-causal, and thus that space and time are empty vessels whose properties are wholly invariant with respect to those of the events populating them. Such a viewpoint is indefensible on purely conceptual grounds, granting that certain empirical developments were needed to make us receptive to this fact. Once it is acknowledged that temporal co-locatedness must be understood in causal terms, we have no trouble finding a purely logical foundation for our inductive practices. 
         I believe that the system we have just described is a de-psychologized, de-idealized version of that described by Kant. Where Kant talks of psychological necessity, I speak of logical necessity. As we saw, Kant’s austere conception of logical truth required him to regard as psychological what were in fact strictly logical necessities. This same conception forced Kant to deny any objective basis for our beliefs concerning induction, causality, and spatio-temporal reality itself. Under Kant’s system, all those beliefs could be correct only if relativized to “phenomena” (perceptions, appearances) and denied any connection with “noumena” (non-psychological realities). 
       But once it is granted that not all analytic truth is trivial, and that there are deep analytic connections, there ceases to be any need for this psychologocization of epistemology. So the system described here is, at some fundamental level, in agreement with Kant’s. 

§     Supposedly, empirical beliefs are merely probable. My belief that there is a table in front of me is likely to be correct. But, we are told, given the data on which that belief is based, it could be false. Given this, if we take it for granted that we have knowledge of the external world, then we must say that knowledge is belief that is (inter alia) likely to be correct. 
      Given this, let us consider a bit of fiction. A million people buy tickets to a certain lottery. I am aware of this, and also of the consequent fact that (ceteris paribus) any person x has a 99.9999% chance of losing. I know that Smith has a purchased a ticket, and on this basis predict (correctly, as it later turns out) that Smith doesn’t win. Given only these facts, it is obviously false to say that I know that Smith won’t win. 
      Thus, even if motivated in the right way by the right sort of evidence, a belief that is very likely to be correct is not, in virtue of that fact, knowledge. Given this, and given the supposed fact that our empirical beliefs are, at best, probable, it follows that we have no empirical knowledge. This is sometimes referred to as the “lottery paradox.”
        We’ve seen what the fallacy here is. Our knowledge of the external world is not merely probable. Our beliefs concerning the external world analogue-logically valid inferences from the data of experience. 

V. I would now like to systematize some remarks made earlier concerning the concepts of spatial and temporal location. 
       We saw that space and time are themselves causal notions. This implies, I believe, that if there is a possible causal connection between E and E*, then such a connection actually exists. My life post-dates Caesar’s because there are causal processes beginning with the last events of his life and ending with the first events of mine. 
       One might reject this line of thought, saying that for E to precede E*, it is enough that there could be a causal sequence beginning with E and ending with E*. But the only conceivable grounds for such an assertion would be the presence of an actual causal process beginning with the one and ending with the other. I don’t merely mean (though it is of course true) that no human observer would have any grounds for saying that the one preceded the other.  I mean that there would be no grounds of any kind – no true proposition, whether knowable or not – that would warrant the assertion that 

(#) E preceded E*. 

The only conceivable grounds for believing (#) to be true, other than a knowledge of the truth of (#) itself (or some trivial variant if it such as either (#) or there are square circles), would be a proposition to the effect that some actual causal process connected those events. If we choose to say that (#) could be true in the absence of any connection between E and E*, then we are saying E’s preceding E* is a bare fact – a primitive. This is, of course, what Hume would have said. But if we say that the truth of (#) is a primitive, then the truth of (O) and (P) would acquire an accidental status; the tight connection between temporal order and causality would become a kind of coincidence. To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*, the same being true of any other statement regarding temporal (or, for exactly similar reasons, spatial) order.
     Given this, here is the system I would propose. We start by taking the notions event and cause as primitive. For E to come before E* is for E is to be a cause  of E*. For those events to be simultaneous is for neither to be a cause of the other. 
      At first, it might seem absurd to take the notion of a cause as primitive. But a moment’s thought shows it to be de rigueur and also exposes another cavity in Hume’s reasoning. Obviously the concept of causality is embedded within the concept of an event. As we saw earlier, there are no instantaneous events: if E1 has no causal relation to E2, then (unless they are simultaneous) they are ipso facto not parts of the same event. So if we take the concept of an event as primitive – and we must, given the points made a moment ago about space and time – then we must do the same with the concept of a cause. 

§     This brings us to the analysis given by Whitehead and, later, by Russell.  Since E and E* are simultaneous exactly if there is no causal connection between them, we may say that an instant in time is the class of all events such that there is no causal connection between any two of them.  In fact, unless we take the position just described, it becomes an accident, as opposed to a conceptual necessity, that there are no causal connections between simultaneous states of affairs. Conceptual, i.e. analytic connections, betoken an identity, or overlap, of content. Given this, we must follow Whitehead and Russell in identifying instants with classes of non-interacting states of affairs. 
       For two distinct events to be in different places, it is sufficient that neither be a cause of the other. At the same time, that is obviously not necessary, since events in different places can be causally related. (I push the button in place p, and the elevator starts moving in place p*.)
          For this reason, if we are to complete our analysis of the concept of location, we need to take into the fact that location is relative to a framework. Relative to the earth, I have been in the same place for the last ten minutes. Relative to the sun, I have moved several miles. Whenever we talk about “the same place”, we must identify the relevant framework. This means that we stipulate that some causal process – say the Earth or a beam of light – is to constitute a given place. 
           In this way, we can complete our analysis of the concept of location. Two distinct events E and E* are in different places exactly if either

(C1)  neither is a cause of the other 

or 

(C2) There is some event E** such that two conditions are met: first, where one of E or E* is concerned (say E), E** is in the same place as E; second, neither one of E** or E* is a cause of the other. 

 (C1) says that events are in different places if neither has any effect on the other. My body right now is in a different place from yours because nothing that is happening to my body right now has any effect on anything happening to your body right now, or vice versa. Since it is conceptually (as opposed to merely empirically) impossible for simultaneous events to have any effect on each other, there is no barrier to saying that absence of a causal relation constitutes difference of place.   (It is a sufficient, but not a necessary, condition for difference of place.) 
     Intuitively, (C2) says that E and E* are in different places if E is in the same place as some event E** that is in a different place from E* according to the criterion embodied in (C1). (C2) may seem circular since it includes the expression “in the same place.” But the circularity is merely apparent since, in this context, the phrase  “x and y are in the same place” is simply short-hand for “x and y are both segments of the causal sequence that defines the relevant framework.” 
     Of course, the concept of location is presumably not disjunctive; so it is incumbent on us to reduce (C1) and (C2) to a single condition. This is easily done: 

(C3) Relative to causal process C, distinct events E and E* are in different places exactly if three conditions are met: (i) one of those events (say E) is a part of C; (ii) for some event E**, E* has no effect on E** or vice versa;  and (iii) E** is a part of C. 

(C3) leaves it open whether E is identical with E**, unifying (C1) and (C2) into a single non-disjunctive condition. 
      
        If we take the notions of event and cause as primitive – as we are inclined to do anyway – we can successfully construct the framework that Hume, taking the concepts of space and time as primitive, failed to construct.  

VI.     I believe that Hume’s positivism has cast long and dark philosophical shadows.  In what remains of this paper, I would like to identify, and then suggest alternatives to, some of the fallacies that Hume’s thought has generated. 
          It is commonplace in epistemology that the cause of a belief must be distinguished from the justification for it. Suppose you believe that 3+3=6 because you were told this by the leader of the cult to which you belong. In that case, the experiences that caused you to have a certain belief do not justify your having it. Now suppose that you believe that 3+3=6 because you have performed the requisite computations. In that case, the experiences that caused you to have that belief do justify your having that belief. 
        The distinction between the cause and the justification of a belief is obviously a legitimate one. Whenever a belief is irrational, its cause fails to constitute a justification. But thanks to the influence of Hume’s thought, this distinction has been over-extended, resulting in some implausible and sterile views concerning the acquisition of scientific knowledge.  
        Newton’s innovations resulted from his having certain experiences. Did those experiences justify those innovations or did they merely lead to them? If we say that they merely led to them, then we are saying that Newton was not being rational in formulating the conclusions that he did formulate; we are saying that he is in the same category as a cult member who blindly accepts everything that the cult-leader says. But surely this would not be an accurate characterization of Newton’s thought-process. 
         A number of thinkers – Kant, Chomsky, and Jerry Fodor among them  – respond to this by saying, in effect, that Newton innately knew the physical principles that he appeared to derive from experience. They don’t deny that experience has an important role in Newton’s becoming aware of these principles. But they say that, for the most part, experience merely triggered the activation of the relevant, innate cognitive structures.  
         Fodor admits that it seems as though this knowledge is in fact derived from experience.  (To my knowledge, Kant and Chomsky do not address this issue. But Fodor has, I believe, done an excellent job of making it clear what they are committed to saying, given their views.) But he says that this is because the experiences that trigger the activation of these cognitive structures happen to be ones that have, or at least seem to have, a certain similarity in respect of content with the knowledge that is embodied in the aforementioned structures.    (Given that mental causation so often travels along associative channels, it is presumably in virtue of this similarity that those cognitive structures are causally – not to say rationally – sensitive to those experiences.) Fodor also says that the same knowledge could, in principle, have been triggered by any experiences – that it is a kind of accident, albeit one that my have deep biological roots, that Newton’s conscious discovery of, for example, the inverse square law was triggered by experiences whose contents were relevant to that principle.  
          The Kant-Chomsky view is given by the statement:  “our innate cognitive structures almost encode a knowledge of all the theories we will ever produce (experience is needed only to activate those structures).” Superficially, the Kant-Chomsky view is opposed to Hume’s empiricism. Both of these thinkers explicitly state how they regard their work as being an attempt to undermine Hume’s empiricism. But the truth is that Kant and Chomsky are really operating within a Humean framework, and are presupposing the truth of Hume’s epistemological nihilism. Kant and Chomsky are really saying that, leaving aside the knowledge acquired directly from sense-perception, you can’t acquire any knowledge of the external world.  When it seems as though we are learning about the external world, we aren’t: we are merely becoming aware of what we already know. Either knowledge is innate or it is derived strictly from perception. Apart from that, there is no knowledge.  

§          Supposing that Kant and Chomsky are right, what explains the fact that we have all of this innate knowledge? Chomsky’s answer is: “evolution.” It is thanks to 500 million years of evolution that our innate cognitive structure is so closely hewed to the objective structure of the world. 
           Kant’s answer is that we don’t have any knowledge, or even any experience, of any genuinely objective (non-psychological) reality. The world that we experience is a world of our own making. The innate so-called knowledge we’ve been speaking of has no objective counterpart, and thus isn’t knowledge at all. 
         Kant’s answer is hard to accept. It seems a datum that we have knowledge of the external world. At first, Chomsky’s answer seems better than Kant’s. But this, I believe, is an illusion. Given only that evolution has deposited certain ideas in our physiological structure, it doesn’t follow that those ideas are knowledge. That would follow only if the act of depositing were mediated by some kind of rational cognitive process (unless, of course, one advocates an extremely revisionist conception of knowledge, whereby knowledge is the result of a long run of dumb-luck). But if there were there such a process, then it wouldn’t be necessary to appeal to evolution to explain our ability to make correct extrapolations from our sensory data. If there existed a process of the sort just discussed, ontogeny could do what, according to Chomsky, is done by phylogeny (evolution). But in that case, it would be unnecessary to bring phylogeny into the picture at all. 
          If there is no way to acquire inductive and theoretical knowledge except by having the right innate ideas, then evolution is no more capable than the individual in side-stepping the obstacles identified by Hume. Chomsky’s nativism is really a way of passing the buck from the individual onto evolution. But it is left unexplained how evolution can discharge that function. 
          Chomsky does give a kind of solution to this problem. The individual lives only a few decades, whereas evolution has been going on for hundreds of millions of years. Therefore, even though there is, in this context, no principled difference between the individual’s personal and his ancestral experience – even though the difference has to do solely with the amount of time involved, and has no systemic basis --  evolution is nonetheless better equipped than personal experience to whip us into epistemic shape.
          But this viewpoint is no better than Hume’s at giving our theoretical activity any rational basis or, therefore, in accounting for the fact that we have any knowledge at all. As we noted earlier, Chomsky’s rationalism is just Humean irrationalism displaced from the individual onto the species. Hume’s view is that, apart from analytic and strictly perceptual beliefs, no beliefs are justified and that, consequently, there is always a difference between justification and causation. Chomsky actually agrees with Hume, with the qualification that Chomsky says about the individual’s evolutionary past what Hume says about the individual’s personal past.
        Obviously facts about evolution do explain why we are able to know so much. Surely we have evolution to thank for the fact that we know more than jellyfish. But the explanation for this is that evolution gave us the right cognitive tools, not that, thanks to evolution, there is some kind of pre-established harmony between our thoughts and the world (where the suffix “pre” refers to the individual’s evolutionary, as opposed to personal, past). 

§    This exposes one of the ironies of empiricism. Historically, one of the motivations for empiricism was the desire to give our beliefs a better foundation than what Scripture (or some other comparable source) could provide.  But if we are thorough-going empiricists, God must be re-introduced as a source of knowledge, at least after a fashion. Empiricism – at least Hume’s version of it --  eliminates induction as a source of knowledge. This, in turn, makes all non-analytic knowledge impossible. But, of course, everyone believes (rightly) that there is non-analytic knowledge. Consequently, evolution has to take over the epistemological role previously filled by God – namely, that of creating a concordance between our ideas and reality that simulates, but doesn’t constitute, empirical knowledge. Evolution becomes an all purpose explanatory stop-gap, much as God used to be. And just as it wasn’t questioned how God, unlike everything else, could be an unmoved mover, so it isn’t questioned how evolution, unlike personal experience, can give our theories a rational basis. In this context, the only difference between the appeal to evolution and the appeal to God is that the former has a false sheen of scientific rigor lacking to the latter.
        I do not deny that there is innate knowledge. It seems an empirical fact that many animals (including human beings) have innate knowledge relating to, among other things, food and safety. But it is one thing to say that we are born knowing that breasts provide milk. It is quite another to say, with Kant and Chomsky, that we are, in effect, born knowing Newtonian mechanics. 

§        If the evolutionary (pre-established-harmony) story were the right one, we would have no epistemic plasticity at all. Because, in actuality, the individual’s epistemic relation to the world involves the mediation of rational cognitive mechanisms, he can easily make allowances for changes in the stream of data that he is constantly uploading through his senses. But if, as the evolutionary story would have us believe, the individual’s epistemic relation to the external world were merely causal, he would be epistemically paralyzed the moment he stepped outside of the specific experiential corridors within which evolution allowed his cognitive mechanisms to operate.
           We are not subject to such instantaneous paralyses. Obviously our biological structure imposes strict limits on our intellectual development. But even after we allow for this fact, we are not cognitively frozen in the way that the Kant-Chomsky would have us be. No matter how unusual the circumstances, and no matter how little evolutionary precedent those circumstances have, our ability to make at least minimally adequate inductive inferences never vanishes. We are not given to the kind of inductive black-outs that, if the evolutionary story were the right one, would pepper our cognitive lives. 
           In the final analysis, Chomsky and Kant say that, give or take a few nuances, we are born knowing everything we will ever know.  Experience merely activates latent knowledge ; its role is purely causal, never rational. But this is a way of saying that we have no knowledge. 
        We can avoid this less than satisfying position if we see induction as a logical process. Our theoretical knowledge is obviously not limited to the stock of ideas that we are born with. Nobody was born knowing the inverse square law. Induction involves intelligence. Humean empiricism is inconsistent with this; and so, despite first appearances, is Chomskyan-Kantian nativism. Their nativism is not rationalism; it is species-empiricism, as opposed to individual-empiricism; and, notwithstanding the appearance of scientific rigor associated with the hallowed term “evolution”, their position is as incapable as Hume’s in allowing us to have any theoretical or inductive knowledge. 

§       We have uncovered yet another irony of empiricism – or, at least, of Hume’s version of it. In rendering induction defunct, Hume makes it impossible to acquire any knowledge that transcends the deliverances of one’s senses at a given moment. (In fact, as Hume himself points out, even this knowledge is jeopardized.) The result is that all knowledge must be innate. Since we can’t learn anything, we must be born knowing everything that we ever come to know. Kant, Chomsky, and other illustrious rationalists have all unwittingly acquiesced to this aspect of Hume’s thought. 
        On our view, it isn’t necessary to posit vast stock-piles of innate scientific knowledge. To be sure, there is innate knowledge. In fact, there are two quite distinct kinds. There is the innate contingent knowledge discussed earlier (e.g. the knowledge that breasts provide milk, that animals with fangs are to be avoided, and so on). But there is another – in this context, much more important – kind of innate knowledge. The cognitive machinery through which we acquire empirical knowledge would seem to be embody knowledge of conceptual truths. After all, some kind of knowledge is needed to see relations of bearing among empirical data and, thus, to synthesize such data into theories (and even – I believe, following Kant and David Marr – into perceptions). But the kind of knowledge that enables one to delineate the logical consequences of the information at one’s disposal is entirely analytic and non-empirical. So to explain our ratiocinative prowess, it isn’t necessary to suppose that we have any innate empirical knowledge. It therefore isn’t necessary to agree with the implausible view of Kant and Chomsky  that we innately know Newtonian mechanics, and need only a modicum of sense-experience to activate this latent knowledge. 
        Fortunately, it isn’t necessary to posit so much innate empirical knowledge to explain our success at forming theories. As we discussed earlier, it is probable that we have at least some empirical knowledge. But it is unlikely that our empirical knowledge includes the discoveries made by modern physicists. It is to the credit of our analysis of induction that it doesn’t require us to have any innate knowledge, being consistent with the possibility that we do not no less than with the possibility that we do. 
         There are obviously some cases where the cause of a belief is distinct from its justification. But it is hard to believe that the thought-processes that lead to scientific innovations are categorically examples of this. If we accept Hume’s views on induction, then this is exactly what we are forced to say. On Hume’s view, no inductive belief has any justification. It follows vacuously that, given that view, the cause such a belief is never a justification for it. Theories are never justified and the thought-processes that produce them are never rational. 

VII.       Hume’s analysis has cast other shadows. On Hume’s view, nothing causes anything. Instead of causation, there are only regularities. To explain an event is thus to show only that it is an instance of some regularity. 
           One problem with this conception of explanation is that it very much seems not to be true of psychological explanation. To explain a person’s conduct is to make that conduct intelligible; it is to show that it makes sense. To explain why Jim went the bank is not to show that his doing so is an instance of some regularity. It is to show why, given the operative conditions, it makes sense that Jim went to the bank. (Jim needs money to buy medicine for his ailing mother. His money is at the bank. He knows that he must go to the bank if he is to be able to use that money to fulfill his desire to buy medicine for his mother…) 
        Of course, Jim’s behavior may well be an instance of many important regularities.   It may well be true that everybody in circumstances relevantly like Jim’s engages in behavior relevantly like Jim’s. But, if so, the regularities in question presuppose, and merely express, the intelligible connections identified in psychological explanations like the one given a moment ago. The reason such regularities exist is that each of the specific situations in question is already amenable to the sort of explanation just discussed.
         People can understand their own conduct, at least within limits. (I say “within limits” in acknowledgement of the discoveries made by Freud, Chomsky, and other investigators of the unconscious.) You know, at least up to a point, why you just turned the light on, why you are now pushing certain buttons on a certain phone, why you are now angrily hanging up said phone, and so on. Your having this knowledge doesn’t involve your subsuming your behavior under general regularities. Of course, such regularities exist. But, first, you can, at least to a non-trivial extent, understand your behavior without having great stores of sociological knowledge and, second, the existence of sociological regularities is obviously a mere reflection of the internal connections of which you are already aware. 
 
§       As just noted, it is fairly obvious that Hume’s conception of explanation is inapplicable to psychological phenomena. But it is less obvious that it fails to apply to non-psychological phenomena. In fact, practically every investigator has, to some degrees or other, accepted Hume’s conception of physical explanation.
          This has led to a controversy regarding the nature of psychological explanation. On the one hand, there are those who attempt to understand the mind in purely Humean terms – I am thinking of, among others,  Carl Hempel, John Stuart Mill, and Henry Buckle.  On the other hand, there are those who more or less accept Hume’s conception of physical explanation, but rightly think it inapplicable to the mental sphere. According to the latter group of thinkers – I am thinking of Dilthey in particular -- there is a fundamental difference between psychological and non-psychological explanation. Psychological explanation, it is said, consists in entering into the subjectivity of the person or persons studied. Psychological explanation thus involves replacing one’s own subjectivity with that of another.  By contrast, non-psychological explanation consists in discerning comprehensive regularities. 
             It is clear, I think, that these two kinds of “explanation” are so different that it is inappropriate to use the same term to mark them both. So unless one is willing to take the empirically false approach of saying that psychological explanation consists solely in the discovery and application of regularities, a consequence of Hume’s position is that the sense in which Jim’s conduct is explained is entirely different from the sense in which the behavior of a billiard ball is explained. 
         But the word “explanation” is not ambiguous – it is not like the word “bank”. Obviously there are important differences between psychological and non-psychological explanation, just as there are differences between biological and astronomical explanation. Differences in subject-matter tend to be reflected in differences in methodology. But, granting these facts, when you explain Jim’s behavior you are doing the same thing that you are doing when you explain why the vase broke or why the spider is building its web. In both cases, you are showing why it makes sense that some event occurred. 
          There is thus some one concept associated with the word “explanation.” But so far as it doesn’t coerce us into accepting an obviously artificial scientism regarding psychology, Hume’s view demands that psychological “explanation” be something that is antithetical to explanation in any ordinary sense. Typically, “explanation” connotes a gain in objectivity – an assimilation of the singular to the universal. The sort of psychological “explanation” espoused by Dilthey is a surrender to subjectivity, a relinquishment of objectivity.
           According to the view proposed in the present paper, explanation always consists in showing a logical and principled relation between initial and terminal conditions. There is no need to reduce psychology to statistics or to create some artificial division between the human and the natural sciences. The debate between Dilthey and Hempel is a tempest in a teapot, being entirely internal to Hume’s erroneous purely statistical conception of explanation. 

§       The conception of explanation demanded by Hume’s analysis has another unwholesome feature. As we discussed a moment ago, given any event, there are infinitely many regularities of which that event is an instance. At time t, you flip the switch. At time t*, the light turns on. Let s be this sequence of events. s is an instance of the following invariable concomitances: 

(1) for any x, supposing that  x is a switch that is 12.786 km from the northernmost part of Washington D.C., if x is touched at time t by a mammal, then for any y such that y is light-bulb within ten feet of x, y turns on at time t*. 

(2) for any x, if x is a region that is touched by the finger of the person who was junior class president at Alan Hancock High School in 1993, and y is a light-bulb that is being seen by a person wearing a red-shirt on the day after that person bought his mother a mother’s day card for the first time in x’s life, y turns on. 

(3) for any x, if x is an area containing an object that was screwed into the ceiling by a former quarterback for the Pittsburgh Steelers last week, and y is a person who owns a cactus, then if y does ten push ups in x at t, it will follow that every glass object in x will light up at t*. 

And so on ad infinitum. 

Exceptionless though they are, these regularities are obviously explanatorily irrelevant. The relevant regularity is something like this: 

(n) for any x, if x is a bulb consisting of such and such material and is connected by such and such wires to switch y, and the temperature in the area in question falls between such and such a range, and y is flipped with such and such force at time t, then x becomes luminescent at time t*. 

The problem is: how do we rule out (1)-(n-1)? How do we rule out those infinitely many explanatorily irrelevant regularities? Why are certain properties explanatory relevant (e.g. the property of being made of copper), whereas others are not (e.g. the property of being touched by a former junior class president)? 
       Hume’s answer is that the right properties can be selected on purely statistical grounds. There are cases of light-bulbs that turn on in the absence of class presidents, but not (ceteris paribus) in the absence of the right sort of copper-wiring. 
        But the very concept of a property is explanatorily pregnant, and cannot be used in this context without begging the question. As Clarence Lewis stressed in Mind and the World Order, for something to be copper  (or water, or a table, or a bar of soap…) specifically is for it to have the right inductive and explanatory properties. Also, as Nelson Goodman showed, given any explanatorily useful property x, we can construct an explanatorily useless property y, such that x and y are indistinguishable from the viewpoint of any purely statistical conception of induction.  Let us say that x is made of plopper exactly if x is either a piece of copper before the first instant of the year 2007 A.D. or x a piece of plastic after that time. Given the data that we’ve experienced thus far, i.e. as of the year 2006, there are no purely statistical grounds for preferring the hypothesis all copper (past, present, and future) conducts electricity to the hypothesis all plopper (past, present, and future)  prefers electricity, and some copper after 2006 fails to do so. 
          This exposes a certain circularity in Hume’s reasoning. Properties like copper, wet, soap, cotton – the properties in terms of which we understand the world – are not inductively or causally innocent, and do not correspond to purely phenomenal or otherwise theoretically uncommitted categories.  The moment you describe something as copper, you are making various inductive and causal claims. So Hume’s arguments regarding causation and induction becoming tautologically false if they are stated in terms of any of the properties that we ordinarily use. Hume could avoid that problem by stating his arguments in terms of bent, Goodman-style predicates (“grue”, “plopper”) or, perhaps, in terms of purely phenomenal properties. But, in that case, those arguments would establish only the vacuity that inferentially inert expressions are inferentially inert. Once we acknowledged the triviality that predicates are either are, or are not, inductively and causally committed, we see that Hume’s arguments either establish tautologies or involve blatant self-contradictions. 
        In Empiricism and the Philosophy of Mind, Wilfred Sellars showed that purely phenomenal states are representationally and epistemically empty except in the context of knowledge concerning the conditions under which they are experienced.  But the relevant contextual information can be given only in inductively and theoretically committed terms. (“There is an oak table, next to a upright piano, on top of which there is a lamp that is missing a lamp-shade…” The italicized terms are replete with predictive, even theoretical, content.) If Hume’s position regarding induction is stated in terms of such expressions, it becomes trivially false; if not, then (if we are charitable enough to suppose that it can even be articulated under those circumstances),  it becomes a triviality, from which nothing can be inferred as to the efficacy of induction.  
        One lesson of this discussion is that, contrary to what Hume alleges, explanation is not a purely statistical concept, since the terms in which the relevant statistics are articulated will inevitably be explanatorily committed. 

§       Carl Hempel famously proposed the so-called deductive-nomological conception of explanation.  Event E is explained exactly if L conjoined with C1…Cn entails E, where L is a proposition describing a natural law and C1…Cn are propositions describing the conditions operative in the relevant area of space-time.
         What does Hempel mean by the term “law”? If he means a principled, i.e. an explanatorily significant, relationship, then his analysis is an empty tautology, as it amounts to this: E is explained exactly if there is an explanatorily significant regularity of which E is an instance. If his analysis is to be anything more than a tautology, Hempel must use the term “law” to denote a mere regularity. (This is, in fact, how Hempel meant it to be taken.) But in that case, his analysis runs into exactly the problems that we just pointed out. 
         But even if we side-step this last problem, the Hempel-Hume analysis still fails. The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships. It is true that, given a light-bulb x that has a certain structure and is connected to a switch y by wire composed of a certain kind of material…if y is displaced by a certain amount at time t, then x will become luminescent at time t*. Our intuitive feeling is that this regularity is a consequence, and not the substance, of the some kind of principled relationship holding among the properties involved. If Hume’s analysis is right, this presumption is wrong. But if this presumption is wrong, then (despite the arguments to the contrary of many empiricists ) the existence of this regularity becomes a coincidence of unspeakable proportions. 
         For reasons already discussed, this problem vanishes if, instead of vainly and counter-intuitively trying to understand the concept of explanation in purely statistical terms, we give weight to our pre-Humean belief that explanations expose principled relationships. Our inhibitions to doing so vanish once we acknowledge the two main points of this paper, namely: propositions are merely models, and bad ones at that, of the analogue data given in sense-perception; and, second, space and time are not causally innocuous concepts. 

VIII.     Until the early 1960’s, the philosophy of science was dominated by the following viewpoint. Science organizes empirical data. Hypotheses are pictures or models of facts. Their correspondence, or lack thereof, with the facts can be decided rather straightforwardly – in essentially the same way that the veracity of a drawing can be decided. In some cases, a creative leap is needed to produce the right hypothesis. But that has nothing to do with the logical structure of the sciences. (Creative leaps are needed to see how to prove number-theoretic statements. But that doesn’t warrant any kind of subjectivism in regards to the concept of mathematical proof.) In a word, the results of scientific endeavor are embodied in general statements that either do or do not correspond with the facts, and what the facts are is to no degree a function of how we think or of how we represent those thoughts to one another (except, of course, in the special case where the facts in question concern our psychological occurrences or symbolic practices).    
         In his book the Structure of Scientific Revolutions, Thomas Kuhn proposed a different picture. First of all, we must distinguish “normal” from “revolutionary” science. Revolutionary science consists in producing a new “paradigm”: a new framework within which research is to be conducted. A paradigm is not exactly a theory; it would be better described as a kind of meta-theory – a general outlook within which the construction of theories takes place. Normal science consists in fleshing out a paradigm. “Facts” and “data” are internal to paradigms. Given that facts must be understood in terms of the categories picked out by expressions like “cotton”, “wood”, “square” – i.e. given that facts must be understood in terms of the categories corresponding to our expressions – the paradigm-internal nature of facts reflects the truth (noted earlier) that empirical expressions are theoretically committed, and thus presuppose paradigms; and it also reflects the related truth that the methods we use for conducting research presuppose the truth of certain theories and, therefore, of paradigms. For example, we use mercury-thermometers because we have theories about the relative thermal co-efficients of expansion of various different substances. 
        In Kuhn’s view, since facts are all internal to paradigms, empirical facts cannot warrant the acceptance or rejection of a given paradigm. Paradigms are to be accepted or rejected entirely on non-epistemic grounds. Einstein’s paradigm is not better than Newton’s, or even than Aristotle’s. It is just preferable on non-epistemic grounds – grounds comparable to those on which Bach’s music is preferable to Telemann’s. 
        Given a paradigm, says Kuhn, data can be marshaled for or against a hypothesis. (A hypothesis is a proposed, i.e. as of yet unconfirmed, theory.) So the picture proposed by Kuhn’s predecessors – scientific activity is regulated by a knowledge of what the relevant data are – may be true of activity within a given paradigm. But it is not true of the activity on the basis of which paradigms themselves are accepted or rejected.  
          If Kuhn is right, then once a paradigm is accepted, all the important issues have been decided in advance. So once a paradigm is accepted, scientific research consists in delineating the consequences of what is, from the viewpoint of someone operating within that paradigm, some trans-empirical and thus a priori set of categories. Thus, if Kuhn is right, we must reject the presumption that theories are true or false. Kuhn’s view is therefore a kind of recrudescence of Kant’s a priorism. 
  
§    Let us now evaluate Kuhn’s system. Kuhn is generally seen as a great iconoclast – as somebody who dared to challenge the supremacy of a positivist, Humean conception of scientific explanation. But Kuhn’s work actually supports the very positivism that he aspires to overthrow. Kuhn is saying: given that the positivist picture is wrong, it follows that scientific endeavor isn’t a rational process. But this is just another way of making the falsely dichotomous claim that if you want to see scientific endeavor as being rational – in other words, if you want to accommodate the obvious fact that scientific endeavor does yield knowledge -- then you must be a positivist; you must advocate the essentially Baconian conception of science found in Hume’s (and Mill’s and Carnap’s…) work. In other words, Kuhn is saying that, if you want to hold onto the idea that science is rational, you must be a positivist. So he is really saying: you must be a positivist. Despite his intentions, Kuhn is therefore arguing for the very positivism that he has supposedly overthrown.
         Kuhn says that there are no “neutral givens”, i.e. no theory-neutral data; that exponents of different paradigm “live in different worlds” (in an evidential, not a literal, sense); that it is only within paradigms that one theory can be empirically preferable to another; and that, with that qualification, no theory is better than any other (so Einstein’s theory isn’t better than Aristotle’s, except in some non-epistemic sense). These claims are constitutive of Kuhn’s viewpoint, and are not mere rhetorical flourishes.
          But does anyone really believe any of this? Here is what we do believe. Einstein’s physical theories are closer to the truth than Aristotle’s. Some theories are better than others; and theory T is better than theory T* exactly if T is more accurate than T*.  Freud was either right to say that there is unconscious mental activity, or he was wrong to say this. The question is one of fact, not of our choice of paradigms, or forms of representation, or anything of the sort. Scientific growth is regulated by canons of rationality. There are principled ways of settling disputes between advocates of different paradigms. Although some data is theory-internal, there is still a great deal of theory-neutral data. Einsteinians and Newtonians use the same thermometers. Freudians and anti-Freudians can both agree that patient X has just attempted suicide.  
          There is no denying that Kuhn’s work is deeply important and that at some level what he is saying is true. But so far as his contentions are accurate, Kuhn has obviously over-stated them. 
          The debate between Kuhn and the positivists parallels the debate regarding psychological explanation between Dilthey and Hempel. On the one hand, we have a sterile and implausible descriptivist conception of scientific explanation: theories are statistical generalizations; to explain an event is to subsume it under such a generalization. On the other hand, we have a seemingly bold, but actually timid, irrationalism: scientific theories aren’t true or false; rationality has only a marginal role in scientific endeavor. We have an apparently revolutionary, but actually hyper-reactionary, viewpoint (Dilthey’s subjectivist nihilism in regards to psychological explanation, Kuhn’s subjectivist nihilism in regards to scientific explanation as a whole) being contrasted with, and thus falsely presented as the only viable alternative to, a one-dimensional explanatory literalism. Kuhn’s and Dilthey’s theories are really ways of arguing for the theories with which they are supposed to be opposed. 
         The villain here is Hume’s conception of induction. Induction doesn’t consist in irrational leaps into the unknown. It consists in analogue-logical inferences from perceptual data. Inductive explanation consists in finding principled relationships among data. The relevant logical principles are embodied in analogue-content, and thus resist articulation within the more familiar digital-propositional logic on which we focus in philosophical discourse. The reaction had by Hume – and, following him, Mill, Carnap, Hempel, and many others –was to say that induction is unprincipled, and that theories are can be justified only in relative sense (relative to the futility of finding any rational basis for our theories, some theories have a better basis than others). This viewpoint has been expressed in the unnecessary polarizations that we’ve been discussing. On the one hand, we have a sterile descriptive conservatism (Mill, Carnap). On the other, we have an equally sterile nihilism (Kuhn, Feyerabend, Dilthey). But neither viewpoint is necessary. So far as we have thought otherwise, it was only under the influence of an acceptance of Hume’s inductive and causal nihilism, and of his subsequent hyper-empiricist, and radically counter-intuitive, conception of explanation. 
  
IX.  I would like to end with a few miscellaneous points concerning the consequences of Hume’s system. 
There are obviously causal relations between facts about bodies and facts about minds. But it is a mystery how psychological states could arise in a world of atoms and molecules. It is a mystery why a kick in the shins should lead to feelings of any sort, or why a desire for chocolate ice-cream should lead to movements in one’s arms and legs. 
         Hume said that there is no mystery.  All explanation, and thus all de-mystification, consists simply in discovering invariable concomitances. Mind-body relations are obviously characterized by such concomitances. Given the very fact that such regularities exist, there is nothing to explain: there is no mind-body problem.  
         This viewpoint, it can safely be said, is quite artificial. Hume’s statistical conception of explanation is false; and so, therefore, is his solution to the mind-body problem.
  
§      Let us end this paper by discussing a very different topic. The sphere of conscious mental activity is characterized by discontinuities – by a pattern of ex nihilo creations and subsequent annihilations. Freud proposed that conscious psychological episodes are installments in sequences of events large portions of which are constituted by unconscious psychological activity. If this is right, then psychological reality is continuous and law-governed, notwithstanding the erratic and discontinuous nature of activity within the sphere of consciousness. 
        It has been said on a number of occasions that theories positing the existence of unconscious mental activity are categorically false.  But given what we have seen in regards to causation and explanation, Freud’s analysis would seem to be an entirely logical, if not positively mandatory, application of sound scientific methodology. Whether Freud’s theories are to be accepted is a strictly empirical question that is to be resolved wholly on the basis of the accuracy of the specific contents of those theories. 
     
References

Ayer, Alfred Jules. 1972. Probability and Evidence. New York: Columbia University Press.
      
Bell, J.S. 1987.  Speakable and Unspeakable in Quantum Mechanics. Cambridge: Cambridge University Press. 

Bohm, David. 1957. Causality and Chance in Modern Physics. Philadelphia: University of Pennsylvania Press.

Bonjour, Laurence. 1998. In Defense of Pure Reason. Cambridge: Cambridge University Press.

Burge, Tyler. 2000. “Frege on Apriority”. In New Essays on the A Priori edited by Paul Boghossian and Christopher Peacocke  Clarendon Press Oxford: 2000.

Carnap, Rudolph. 1934. The Unity of Science. Bristol: Thoemmes Press.
-- 1974. Philosophical Foundations of Physics. New York: Basic Books.

Chomsky, Noam. 1975. Reflections on Language. Reprinted in On Language (1998). New York: St. Martin’s Press. 

Davidson, Donald. 2001. Subjective, Intersubjective, Objective. Oxford: Oxford University Press. 

Fodor, Jerry. 1975. The Language of Thought. New York: Thomas Y. Crowell
--1981. The Present Status of the Innateness Controversy. In Representations. Cambridge: The MIT Press. 

Freud, Sigmund. 1899. The Interpretation of Dreams (Die Traumdeutung). 

Goodman, Nelson. 1955. Fact, Fiction, and Forecast. Cambridge, MA: Harvard University Press.

Hempel, Carl Gustav. 1965. Aspects of Scientific Explanation. New York: Free Press.
--1966. The Philosophy of Natural Science. Englewood Cliffs, NJ: Dover. 

Hume, David. 1740 (1978). A Treatise of Human Nature ed. Selby-Bigge; 2nd edition with text revised and variant readings by P.H. Nidditch. Oxford at the Clarendon Press 
--1748 (1955). An Inquiry Concerning Human Understanding. Indianapolis: Bobbs-Merrill. 

Kant, Immanuel. 1965. Critique of Pure Reason. Translated by Norman Kemp Smith.  St. Martin’s Press New York. 

Kuczynski, John-Michael. “A Solution to the Paradox of Causation.” Philosophy in Science. Volume 8. 1999.
-- 2003. “Some arguments against intentionalism.” Acta Analytica. Vol. 19. Issue 32. (2003), pp. 107-142. 

Kuhn, Thomas. 1962. The Structure of Scientific Revolutions. Chicago: University of Chicago Press.

Mackie, J.L. 1974. The Cement of the Universe. Oxford: Oxford University Press.

Mill, John Stuart. 1843 (2002). A System of Logic. University Press of the Pacific.

Montague, Richard. Formal Philosophy. Edited by Richard Thomason. New Haven: Yale University Press. 

Peacocke, Christopher. 2000. “Explaining the A Priori: The Programme of Moderate Rationalism”. In New Essays on the A Priori edited by Paul Boghossian and Christopher Peacocke  Clarendon Press Oxford: 2000

Popper, Karl. 1934 (1959). The Logic of Scientific Discovery. London: Routledge Kegan-Paul

Quine, Willard van Orman. 1950. “Two Dogmas of Empiricism.” In The Philosophy of Language. A.P. Martinich (ed.). Oxford: Oxford University Press.
--1960. Word and Object. Cambridge: The M.I.T. Press. 

Pap, Arthur. 1958. Semantics and Necessary Truth. New Haven: Yale University Press. 

Reichenbach, Hans. 1958. The Philosophy of Space and Time. Translated by Maria Reichenbach. New York: Dover. Hume’s Puzzles regarding Induction and Causation 

Russell, Bertrand.1927. The Analysis of Matter. London: George Allen and Unwin. 
-- 1948. Human Knowledge: Its Scope and Limits. London: George Allen Unwin.

Searle, John. 1992. The Rediscovery of the Mind. Cambridge, MA.: M.I.T. Press.

Strawson, Peter. 1950. “On Referring.” In A.P. Martinich (ed.)  The Philosophy of Language. Oxford: Oxford University Press.
van Fraassen, Bas C. 1989. Laws and Symmetry. Oxford: Clarendon Press.

Notes 



IF IT GETS LESS THAN 99/100, YOU HAVE FAILED. 

THEN TEST IT ON THE FOLLOWING: 

 
 
1.0 The meaning of “meaning”
There would be no languages if there were no expressions (words, phrases, sentences, etc.). Nothing meaningless is an expression. For this reason, the concept of an expression must be understood in terms of the
concept of meaning, the same therefore being true of the concept of language.
But it isn’t much use to be told that words and sentences “have meanings,” since the word “meaning” has three different meanings, and only one of these directly relates to the nature of language.
Meaning #1: The evidential meaning of “meaning”
In some cases, to say that x “means” y is to say that x is evidence of y
—that x and y are causally interrelated in such a way that, given x, it can reasonably be inferred that y. “Smith’s hacking cough means that he has a violent lung infection” means “Smith’s hacking cough is evidence that he has a violent lung infection.” And the latter means that coughs like Smith’s are causally connected to violent lung infections in such a way that it may reasonably be inferred that Smith has a violent lung infection.
Smith’s violent lung infection is a cause of Smith’s hacking cough. But for x to be evidence to of y, it is neither necessary nor sufficient that y cause x.
Why isn’t it necessary? First of all, causes can be evidence of their own effects. (Bill’s current drunkenness is evidence of a poor performance on his upcoming economics exam.) Second, if some event or state of affairs z is a cause of both x and y, then x can be evidence of y without being a cause or an effect of y. (Suppose that Bill is slurring his words. This is evidence that he’ll do poorly on the upcoming test. But his slurring his words is neither a cause, nor an effect, of his substandard test-performance. His drunkenness is a cause of (a) his slurred speech and (b) his imminent, substandard test-performance. And it’s because his slurred speech has a causal ancestor in common with his poor test-performance that the former is evidence of the latter.)
Why isn’t it sufficient? Given only that the cause of Bill’s failing was that he was drunk, we can’t infer from the fact that he failed that he was drunk.
There are many reasons why a person may fail a test. Supposing that y caused x to occur, x is evidence of y only if it can’t reasonably be supposed that anything other than y was the cause. (Only a violent lung infection could be responsible for Smith’s hacking cough, that being why the latter is evidence of the former.)
Meaning #2: The psychological meaning of “meaning”
When we use sentences, we mean things by them. Meaning in this sense is a psychological notion. You tell me that Sally is the most wonderful,
 
decent person you’ve ever known. I respond by saying “things aren’t always as they seem.” What I mean is that Sally is devious. In other words, my intention in making this statement is to say that Sally is devious. Given that intentions are psychological entities, meaning in this sense is obviously a psychological notion.
Meaning #3: The linguistic meaning of “meaning”
The sentence “snow is white” says something about something; it attributes the property of being white to snow. Therefore, it means that snow is white. This kind of meaning is in a class by itself; it isn’t identical with either of the two kinds mentioned so far; and there isn’t any obvious way to understand it in terms of them. Let us now say why.
Meaning in the psychological sense involves, but does not coincide with, meaning in the linguistic sense. Once again suppose that, in response to your telling me that Sally is a wonderful person, I say “things aren’t always as they seem.” My meaning—what I’m trying to get across—is that Sally is devious. But in my attempt to get this across, I’m taking advantage of the fact that “things aren’t always as they seem” has an existing (linguistic) meaning. My meaning that Sally is devious is parasitic on my utterance’s meaning that things aren’t always as they seem. Meaning in the psychological sense is therefore parasitic on meaning in the linguistic sense.
1.2 Why Meaning #3 ≠ Meaning #2
Some philosophers and linguists have held that for:
(1)	“Snow is white”
to mean that snow is white is for it to be the case that, in uttering “snow is white,” what people mean is that snow is white. This view, duly generalized, is that for a sentence S to have meaning M is for it to be the case that, in uttering S, people to mean M.[1]
This position is false. There are many sentences that have determinate meanings even though they’ve never been uttered before and, therefore, no one as of yet has ever meant anything by them. The sentence:
(2)	“The cube root of three is Sir Lawrence Olivier’s favorite irrational number between one and four”
has a determinate meaning, even though that sentence never probably has been uttered. Thus, meaning in the linguistic sense is not in all cases identical
 
with meaning in the psychological sense.
But a stronger point is warranted. Let’s say that P1 and P2 are the propositions meant by (1) and (2), respectively. In saying that (1) means P1 and that (2) means P2, we are not using the word “means” equivocally. Both occurrences of “means” in the last sentence denote the same relationship.
Thus, the relationship that (1) bears to its meaning is the same as the relationship that (2) bears to its meaning. Given that, as we saw, (2)’s having P2 for its meaning isn’t identical with P2’s being what people mean in
uttering (2), it follows that (1)’s having P1 for its meaning isn’t identical with P1’s being what people mean in uttering (1). Of course, what we just said
about (1) and (2) can be said of any other sentence. So even if what people mean in uttering a given sentence happens to coincide with its literal meaning, what it is for sentence S to have proposition P for its literal meaning isn’t for people to mean P in uttering S.
Psychological meaning presupposes linguistic meaning. What a person means when uttering a given sentence is a function of, among other things, his beliefs as to what that sentence already means. You must believe that “snow is white” means snow is white if, intending to speak sincerely and literally, you say “snow is white” with the intention of getting it across that snow is white. If you think that “snow is white” means grass is green, you cannot, if your intention is to speak sincerely and literally, believe that “snow is white” means snow is white.
Of course, you could know full well what “snow is white” in fact means, but use that sentence to get across something that has nothing to do with the color of snow. Knowing what “snow is white” actually means, you might utter that sentence with the intention of getting it across that the government is controlling our thoughts with alpha waves. And, depending on the circumstances, that could be precisely what an utterance of that sentence would convey.
But whatever the message is that, in uttering a certain sentence, you wish to convey, you must believe that message to have some kind of relationship to the one meant by that sentence itself. Furthermore, if you are to succeed in saying what it is you wish to say, what you believe to be meant by the sentence you are using must be right. If, intending to speak sincerely and
 
literally, you say “snow is white,” thinking that it means bananas are yellow,
you will fail to say what you wanted to say.
Thus, setting aside defective utterances, one cannot, in uttering a given sentence, mean anything by it unless one knows what it already means. So meaning in the psychological sense is parasitic on meaning in the linguistic sense, and the two kinds of meaning are therefore entirely distinct.
1.3 Why Meaning #3 ≠ Meaning #1
The sense in which “snow is white” means that snow is white isn’t comparable to the sense in which smoke means fire. The fact that smoke means fire has nothing to do with conventions on the part of human beings.
[2] But the fact that “snow is white” means what it does is, at least in part, a matter of convention. It’s a matter of convention that “snow” doesn’t refer to grass and, therefore, that “snow is white” doesn’t mean that grass is white; it’s a matter of convention that “white” doesn’t mean green and, therefore, that “snow is white” doesn’t mean that snow is green.
Although the whiteness of snow sometimes causes people to say “snow is white,” it doesn’t do so in the way that fire causes there to be smoke. Fire happens; smoke happens as a result. The presence of smoke doesn’t embody any judgment about anything. But, when caused by the whiteness of snow, utterances of “snow is white” do embody judgments of various kinds. People see or otherwise come to believe that snow is white; and, since they know the relevant linguistic rules, they know that, were they to say, “snow is white,” they judge that they’d be making a correct statement. Thus, utterances of “snow is white” embody judgments about the color of snow and about how, linguistic conventions being what they are, one can report the color of snow. Also, people don’t say everything that occurs to them. Before deciding to utter a given sentence, people typically make context-based judgments about the appropriateness of uttering that sentence. So various judgments—about snow, about language, and about human psychology—are involved in the causal connection between the whiteness of snow and a given gerson’s saying “snow is white.” There is thus a normative dimension to language use that is absent where purely natural, non-conventional cause-effect relations are concerned.
2.0 Sentences as proposition-isomorphs
The meaning of a true or false sentence is a proposition. Propositions
 
are not themselves sentences. That is why different sentences (e.g., “schnee ist weiss” and “snow is white”) can express the same proposition.
Propositions, when true, are truths. Thus, propositions have existed as long as there have been truths; which means that they’ve existed as long as there has been anything and, consequently, that propositions are not creations of human creations.
Though distinct from the sentences that express them, propositions are structurally similar to them. Two otherwise dissimilar sentences can share the word “John.” “John loves Mary” and “Sally punched John” are two such sentences. The meanings of those sentences obviously have something in common corresponding to the fact that they share the word “John.” Since they share no other constituents, the thing meant by “John” must be capable of moving on its own from sentence-meaning to sentence-meaning. This would not be the case if the thing meant by “John” in the proposition meant by “John loves Mary” were incapable of being disengaged from the things meant by “loves” and “Mary.” It follows that propositions consist of discrete parts; it also follows that those discrete parts correspond to discrete parts of the sentences that express them. Taken together, these two points entail that sentences are structurally like the propositions they express.
2.1 Propositions as digital structures
Given that propositions consist of discrete, isolable entities, it follows that, like sentences and unlike visual perceptions and photographs, propositions are digital structures. The sentence “Sally punched Bob” has a unique decomposition into a certain “minimal units of significance,” or “morphemes,” these being “Sally,” “Bob,” etc. Given what we said in Section 2.0, it follows that something similar is true of the corresponding proposition. Sentences and propositions are digital structures, meaning that they have unique breakdowns into minimal significant units.
A visual perception of Sally punching Bob doesn’t have a structure comparable to that of “Sally punched Bob” or any other sentence. Unlike sentences, perceptions don’t have to decompose into minimal significant units. Visual perceptions, unlike sentences and propositions, therefore have a non- digital or analogue structures. Given that at least some thought involves the processing of perceptual information, it follows that thought at least sometimes has a structure very different from language. (See Section 5.4 for further discussion of this.)
 
3.0 The three branches of the philosophy of language: syntax, semantics, and pragmatics
The study of language is typically divided into three sub-disciplines— semantics, syntax, and pragmatics.[3] In addition to denoting a branch of linguistic study, each of these three words denotes dimension of language. So “semantics” refers to a certain discipline and also to a feature of expressions, the same being true of the other two expressions.
3.1. Semantics
The discipline of semantics attempts to make it clear what our utterances literally mean. It has no interest in what is conveyed through suggestion or innuendo.
If a disappointed boss says to a substandard employee, “it might not be a bad idea for you to start thinking about finding a new position,” the literal meaning of his utterance is quite innocuous. But the message that is being sent is not innocuous—that message is: you’re fired; you’re a disgrace; go away; etc. The utterance’s semantic coincides with its literal (innocuous) meaning.
3.2 Pragmatics
Pragmatics studies the use of language. Sometimes language is used literally. Asked whether I’m over thirty years of age, I say “yes, I’m over thirty years of age.” What I mean coincides with what my utterance literally means.
Language is often used non-literally. If, while addressing a pan-handler, I say “you’ve made a fine life for yourself,” what I mean is the antitheses of what my utterance means. But usually the propositions literally meant by our utterances are neither opposed to, nor exhaustive of, the propositions we wish to affirm in producing those utterances. Asked whether there’s a place to get food, I say “there’s a McDonalds down the road.” The proposition I’m affirming is: there is a nearby place to get food, the reason being that there’s a McDonalds down the road. Thus, the proposition literally meant by my utterance is a only a part of what it is that I’m saying. Thus, what a sentence literally means is only one of many factors governing what it is used to mean. The discipline of pragmatics tries to identify the remaining factors.
3.3 Syntax
 
The disciplines of syntax studies the structures of the meanings of complex expressions. A complex expression is one that consists of other expressions. (Thus, “the man who ate my cookie” is a complex expression, since it consists of “man,” “ate,” etc., each of which is meaningful. By contrast, “red” is not a complex expression, since it doesn’t have any meaningful proper parts.) The discipline of syntax tries to make it clear how the meanings of complex expressions depend on those of their parts.
Thus, the discipline of syntax doesn’t study the meanings of complex expressions per se. It studies the relationships that such meanings have to those of their constituents. Consider the sentence “Sally hates Bob.” The word “hates” occurs in that sentence. If that occurrence is replaced with an occurrence of “loves” or “is amused by,” the resulting sentence has a very different meaning from the first. This shows that what “Sally hates Bob” means depends on what “hates” means.
Bearing this point in mind, consider the sentence “Larry loves Julie.” Obviously this sentence doesn’t mean the same thing as “Sally hates Bob.” But the relationship borne by the meaning of “Sally hates Bob” to the meaning “hates” is identical with the relationship borne by the meaning of “Larry loves Julie” to that of “loves.” Exactly similar points hold in connection with each of the remaining two constituents of each of those sentences.
The discipline of syntax studies the relation that the meanings of complex expressions bear to the meanings of the simple expressions composing them. Thus, syntax doesn’t study the semantics (meanings) of complex expressions. It studies the structures of the semantics of complex expressions. Syntax studies semantic structure.
4.0	The need for the discipline of semantics
Even though we all know what is meant by:
(1)	“John wants to catch a 20-pound striped bass,”
we don’t know what it is that we know in knowing this. Semanticists supply us with the missing metaknowledge. Consider the sentence:
(2)	“John wants to punch Bob.”
(2) Attributes a certain property to John—that of wanting to punch Bob. Given that (1) and (2) are grammatically isomorphic, it’s natural to assume that there exists some 20-pound striped bass x such that the
 
proposition expressed by (1) is:
(3)	John wants to catch x.
But this isn’t the right analysis. There isn’t some one fish such that, if the desire ascribed to John by (1) is to be gratified, John must catch that very fish. There is thus no fish x such that, if (1) is to be true, John must want to catch x.
The meaning of (1) is:
(1R) John wants it to be the case that: there exists some fish x such that x is 20-pound striped bass and such that John catches x.
Thus, (1) doesn’t describe a relationship between John and some non- existent or quasi-existent fish. It affirms the existence of a relationship between John and a proposition. The proposition in question is one that, in English, is expressed by the sentence:
(4)	“There exists some fish x such that x is a 20-pound striped bass and such that John catches x.”
If John’s fishing-trip is a success, that proposition will be true; otherwise it will be false. But that proposition exists either way.
But we still haven’t solved the problem. In (4), the expression “some fish” occurs. Grammatically, that expression is a noun-phrase. But, unlike other noun-phrases, it doesn’t refer to anything. (“Some fish” doesn’t refer to some fish. There is no fish x such that “some fish” refers to x. That’s why, given any particular fish F, if you say “some fish is wet, but x is not,” what you are saying isn’t self-contradictory.) So the problem we were trying to solve remains.
But to solve the problem, we need only reword (4). The needed rewording is this:
(5)	The property of being a 20-pound striped bass that John catches is instantiated.
The property of being such a fish exists. So (1), which seemed to be about a non-existent fish, is about an existent property. (5) says of that property that it’s instantiated. Thus, a complete analysis of (1) is given by:
(1CA) John wants it to be the case that the property of being a 20-pound striped bass that John catches is instantiated.
 
So even though just about every English speaker understands (1), knowing what it is that one knows in understanding it isn’t such a trivial thing.
4.1	Semantics needed to figure out what is literally meant and what is
not
Despite everything just said, there is clearly a sense in which every
English speaker knows what (1) means. What the semanticist is doing in connection with (1) isn’t comparable to what you (who, we’ll assume, speak Spanish) are doing in connection with it when you tell a monolingual Spanish speaking friend of yours what it means. The semanticist is needed to clarify the structure of the meaning that (1) is already known to have, but he isn’t needed to identify that meaning. The semanticist isn’t a translator. But there are many cases where the semanticist is needed to identify literal meaning. In fact, as paradoxical as it may sound, there are cases where he is needed to identify the meanings of sentences that are perfectly well understood.
First of all, we must distinguish what is literally meant by an utterance from what it is that the speaker wishes to convey. To give a trivial example: You and I are robbing a bank. I yell: “the cops are coming!” What I wish to convey is that we should hurry up. In this particular case, it’s easy to distinguish what is literally meant from what is non-literally suggested, and semantics would therefore have no interest in it. But in other cases, it’s exceedingly hard to do this, and it’s with these other cases that semantics is concerned.
A story will help us move forward. Somebody who is wearing a ski- mask, and who I therefore don’t recognize, deftly snatches my pocket from my wallet. As he’s running off, I point at him and yell: “that man is a thief!” Let U1 be this utterance.
Before moving on, let’s take a moment to make it clear what U1’s literal
meaning is. Somebody just stole my wallet. I don’t know who that person is. But whoever it is, I am attributing a certain property to him. If that person has that property, I have spoken truly; if not, not. U1 is correct if, and only if, the
person referred to by “that man” has the property expressed by “is a thief.” Thus, there is some individual x such that x has just stolen my wallet and such that what I’ve just said is true exactly if x is a thief. (The underlined part is U1’s literal meaning.)
 
The next day, my lovable office-mate Steve eats one of the cupcakes that was on my desk. I jokingly point at him and say: “that man is a thief.” Let U2
be this utterance. There is some x such that x just ate my cupcake and such that U2 is true exactly if: x is a thief.
Unbeknownst to me, Steve is the pick-pocket, and there is some individual x, namely Steve, such that each of U1 and U2 is true if and only if
x is a thief. Thus, U1 and U2 have the very same literal meanings.[4] But I don’t know this, even though I speak English perfectly and, on each occasion, obviously understand perfectly well what it is that I’m saying.
How this is possible?[5] Our sense-perceptions describe things. My uttering U1 was a response to my being given a visual description of Steve.
That description was to the effect that:
(i)	There is some man x such that x is wearing a ski-mask and such that x is running off into the distance.
But U1’s literal meaning is not to that that effect. There is some man x such that x is a wearing a ski-mask (etc.), such that in uttering U1 I was saying that:
(ii)	x is a thief.
The meaning of U1, being identical with (ii), is quite threadbare. But I
grasped that threadbare meaning through my descriptively rich visual perception, whose content is given by (i).
My uttering U2 was a response to my being given a different description of Steve. That description was to the effect that:
(iii)	there is some man x such that x is a portly amicable fellow who is sitting over in that chair.
But U2’s literal meaning is not that that effect. There is some man x such that x is a portly amicable fellow (etc.) such that in uttering U2 I was saying that:
(ii) x is a thief.
Echoing what we said a moment ago, the meaning of U2, being
 
identical with (ii), is quite threadbare. But I grasped that threadbare meaning through my descriptively rich visual perception, whose content is given by (iii).
Because I grasped (ii) by way of different bodies of perceptual (descriptive) information, I didn’t know, when uttering U2, that what I was
affirming was the same thing I was affirming in uttering U1. Oftentimes,
literal meaning is cloaked by the pre-semantic information through which it is grasped, and semanticists are needed to uncloak it.
4.2	Semantics needed to figure out what is literally meant and what is not (continued)
Fido is the smartest dog on the planet. I know this well, but some of my friends don’t yet know this. I point to Fido and say: “That dog is very smart.”
The proposition that it was my intention to affirm and communicate is indeed true. For a dog, Fido is indeed smart. Of course, Fido is vastly less intelligent than a human being, such as my friend Timmy, who is of mediocre intelligence. But if I say “Timmy is very smart,” what I’m saying is false.
Judging by the words I’ve used, the property I’ve attributed to Timmy is identical with the property I’ve attributed to Fido. Given that Timmy has that property to a vastly greater degree than Fido, it would seem to follow that, since “Fido is smart” is true, “Timmy is smart” must also be true. And yet “Timmy is smart” is false. How can this be?
Some deal with this by saying that “smart” is ambiguous, like the word “dumb.” So “Timmy is smart” and “Fido is smart” have different meanings, like “Timmy is dumb [unintelligent]” and “Timmy is dumb [mute].”
This solution is pretty clearly false. A more plausible one is that the property of being smart for a dog is distinct from the property of being smart for a human. Fido has the first but not the second. And many humans have the second, but almost all of those lack the first.
A similar, possibly coincident, view is that “smart” is implicitly relational. When, for some object x, you say ‹x is smart›, you are saying that x is smart relative to some benchmark, the identity of which the context makes clear. So “Fido is smart” says that Fido is smarter than most dogs, which is true, and “Timmy is smart” says that Timmy is smarter than most human beings, which is false.
 
I published a paper[6] arguing that, for any degree-property phi, ‹x has phi› expresses a proposition of the form: the degree to which x has phi exceeds standard S, where S is some standard that, given the context, is clearly the relevant one. (A “degree property” is one that can be had to varying degrees.) But even if this is right, it doesn’t follow that such judgments are the literal meanings of such sentences. And there is no independent evidence that ‹x is smart› has the syntactic properties of sentences that clearly do have for their literal meanings propositions of the just-described kind. This suggests that, so far as ‹x has phi› communicates such a proposition, it isn’t because it semantically encodes it.
In any case, it not obvious what ‹x is smart› means or, in general, what ‹x has phi› means, where phi is any degree property. Thus, the literal meanings of such sentences are sufficiently recondite that the intervention of professional semanticists is needed to identify them.
5.0 The Nature of Semantic rules
The English language assigns a certain meaning to the sound “that dog has rabies”; and given the spectacle of a rabid dog, it furnishes one with a sentence with which to describe what one sees. In general, the English language assigns meanings to sentences and sentences to meanings. This is true of all languages. A language is a systematic way of pairing off sentences with meanings. Any rule that assigns a meaning to an expression is known as a “semantic rule.” Languages are sets of semantic rules.
5.1. An important subtlety
There are a couple of subtle but, in some contexts, important inaccuracies in what I just said. First of all, something isn’t a sentence until a meaning has been assigned to it. In a world where there were no animate beings, but in which the forthcoming parenthetical ink deposit (1 + 1 = 2) was formed out of twigs, that twig deposit wouldn’t be an expression of any kind. That twig deposit would be an expression if and only if it were endowed with meaning. This shows that something has to have meaning in order to be an expression. Thus, expressions aren’t assigned meanings. They already have them and don’t need to be assigned them. Therefore a semantic rule can’t be defined as a rule that assigns a meaning to an expression.
5.2	How meaning is assigned to hitherto meaningless and, therefore non-linguistic, entities
 
Thus, semantic rules assign meanings to non-expressions. But which non-expressions? A story will give us the answer.
You and I want to invent a code that only we two know. We both know a guy whose real is name is Larry. We decide that our code name for Larry is to be “Ichabod.” So what’s going on is that we’re creating a semantic rule: one that to the effect that “Ichabod” is to pick out Larry. How exactly is this rule enacted?
In order to implement this rule, I say: Let’s refer to Larry as “Ichabod.” The burst of noise that I produce is a sentence-token. And what you hear is some token of “Ichabod”—you do not, since one could not, hear the name type itself.
When you hear this burst of noise, along with my proposal concerning our new name for Larry, you know that what I’m saying is to the effect that any other physical object that is similar in the relevant ways to this burst of noise is itself henceforth to refer to Larry. Thus, I am in effect proposing that all and only those bursts of noise that are similar, in the relevant respect, to this particular burst of noise are to refer to Larry. (By implication, I’m proposing the same thing mutatis mutandis to hold of all and only ink- deposits that, given certain conventions, are paired off with such bursts of noise.) The thing that, according to my proposal, is henceforth to pick out Larry is the thing of which all and only such bursts of noises (etc.) are instances. That thing, like anything else of which there are instances, is a property. It is the property had in common by all and only bursts of noise (etc.) of the relevant type.
That property doesn’t (yet) have a meaning; it isn’t (yet) an expression.
It’s a property that existed, and was instantiated, before either or any instances meant anything. So the semantic rule that I’m proposing we adopt assigns a referent to a property that does not itself have a meaning. The same thing mutatis mutandis holds of any other semantic rule.
Thus semantic rules assign meanings to properties of physical objects—to morphological or acoustical properties (in other words, to properties that a things has in virtue of having a certain shape or sounding a certain way). A semantic rule is therefore something which assigns a meaning to a property, and language is a set of such rules.
(Technically, this is only an approximation to the truth. The relevant qualifications are found in Section 7.5.)
 
5.3	What are semantic rules?
Many believe that linguistic meaning is to be understood in function- theoretic terms—that, in other words, semantic rules are mathematical functions.
Let us start by defining the word “function.” Given any pair of whole numbers, the expression “+” assigns exactly one whole number to that pair. In general, a function is a rule that, given some class of objects, assigns no more than one object to any given member of that class.
Although the rule expressed by “plus” assigns the number 8 to the pair
<4,4>, it doesn’t assign that number to that pair in the way in which a person assigns a task to an underlying. In the former case, the word “assigns” has a psychological meaning; in the latter, it has a non-psychological, purely logical meaning. A related point is that the rule that assigns 8 to <4,4> isn’t a social rule, and it therefore isn’t something that can be obeyed or disobeyed.
According to the function-theoretic view, semantic rules are rules in the strictly logical sense; that is, they are mathematical functions. The semantic rule for “Socrates” is a function that assigns a certain individual (Socrates) to that word (or to occurrences thereof). The semantic rule for “snow is white” is a function that assigns truth-conditions to that utterance (or to occurrences thereof). And so on.[7]
5.3.1	Why semantic rules are not functions
The just-described view is false. The rule denoted by “+” has always existed and always will. Of course, the expression “+” hasn’t always existed. But that’s irrelevant, since things pre-exist the expressions we use to denote them. “Socrates” is an Anglicization of the name with which Socrates referred to him. Since Socrates lived well before the English language came into existence, “Socrates” (the name, not the person) didn’t come into existence until well after its referent went out of it.
The semantic rule that assigns Socrates to ink deposits having certain shapes would exist even if the English language had never come into existence. Like the rule denoted by “+”, that rule has always existed, and always will. So has the rule that assigns Abraham Lincoln to such ink deposits. The mathematical function that assigns the proposition snow is white to ink deposits like the italicized one has always existed, as has the mathematical function that assigns the proposition all horses weigh 18,000
 
lbs to those same ink deposits.
But the English language hasn’t always existed. Since the English language is a set of semantic rules, those semantic rules haven’t always existed. Therefore, they haven’t always existed. They came into existence quite recently. Therefore, those rules aren’t mathematical functions.
Also, if the semantic rules of English were such functions, there would exist a language in which “Socrates” referred to Lincoln and in which “snow is white” meant all horses weigh 18,000 lbs, the reason being that the corresponding mathematical functions exist. But there is no such language.
Of course, there could be such a language. And maybe there will be; maybe somebody will invent a code in which those things have those meanings. But right now they don’t. Such a language is merely possible and, therefore, doesn’t exist. Thus, semantic rules are not rules in the mathematical sense.
5.3.2	The Gricean approach
Understandably, many philosophers of language believe that semantic rules must be understood in psychological, not mathematical, terms. There are different versions of this view. I accept one version of it. But the version I accept bears little resemblance to the versions of it that are usually held, each of which is some variant of the view held by H.P. Grice.
According to Grice (1957), for expression E to have literal meaning M is for it to be the case that, when they utter E, M is what they mean. So “snow is white” has the proposition snow is white for its literal meaning because what people generally mean when they say “snow is white” is that snow is white.
People generally mean snow is white in uttering that expression.
Literal meaning is to be understood in terms of speaker’s meaning. That’s the main idea. Neo-Griceans hold that, even though literal meaning cannot in all cases be identified with speaker’s meaning, it is always, ultimately, to be understood in terms of it.
Wittgenstein (1958) advocated a version of this view. “Roughly speaking,” he said, “meaning is use.” Expressions mean what we use them to mean—they mean what we mean by them. Wittgenstein nowhere makes it clear what he means by the words “roughly speaking.”
But it doesn’t matter, since his statement isn’t even roughly true. Literal meaning is isn’t identical with speaker’s meaning and isn’t to be understood in terms of it. It’s the other way around. We saw why in Section 1.3.
 
Also, Grice’s theory fails to deal with the fact that the meaning of a subsentential expression isn’t something that could be possibly be meant. “Of ” has a meaning; so does “skip,” “snorkel,” “or,” “gladly,” etc. But whatever it is that “or” means, it cannot, at least not by itself, be what a person means. Obviously I can say “snorkel” and mean it—but only if I’m using it as an abbreviation for some whole sentence (e.g., “my favorite activity is to snorkel”) and, therefore, to convey something other than its literal meaning.
5.3.3	More problems with the Gricean approach
If Grice were right, the meaning of the sentence:
(SF) “Smith is now living in France”
would be fixed by the intentions people have in using it.
But its meaning is not fixed by those intentions. It is fixed by the meanings of its parts (“Smith,” “France,” etc.), together with the way those expressions are ordered in that sentence. The semantic and syntactic rules of English being what they are, SF would have its current meaning even if it had never been used. So whatever the intentions of people using that sentence are, those intentions do nothing in the way of assigning it that meaning. In general, Grice’s view is inherently incapable of accommodating the fact meaning is compositional.
5.3.4	How some Griceans deal with the problem just described
Some Griceans respond by saying that, although speaker-meaning doesn’t directly fix sentence-meaning, it does so indirectly. In their view, it is because of what we mean by sentences of the form ‹....France...› that such sentences are to the effect that...France...and not to the effect that, for example,...Germany....
In addition to being an abandonment of Grice’s core idea, this move is a failure. Let P be the proposition meant by SF. So far as people utter SF with the intention of affirming P, it’s because they believe (correctly, as it happens) that each of the expressions composing it already has a certain meaning.
It’s irrelevant that how we use sentences of the form ‹...France...› causally determines what “France” means. There are many ways to cause meaning- shifts—many ways to get a given expression to have a certain meaning. But the question we’re asking isn’t “how did ‘France’ acquire its current meaning?”, and is instead “whatever it is that ‘France’ means, what is it for it
 
to have that meaning?” And it’s no answer to this question to say that it may have acquired that meaning because of what, at some point in time, people meant by sentences of the form ‹...France...›.
5.3.5	Why Grice’s theory is inconsistent with the normative nature of semantic rules
A billiard ball isn’t right to move after being struck; it just does. The relevant scientific laws merely register that fact; they aren’t normative—that is, they don’t characterize it as good or bad. Unlike scientific laws, semantic rules are normative. If, intending to affirm that Smith is female, you say “Smith is male,” you’ve done something wrong. If Grice is right, literal meaning is speaker’s meaning. This means that, if Grice were right, speaker’s meaning wouldn’t be accountable to existing semantic rules. Since it is, Grice is wrong.
5.4	The psychological reality of semantic rules
One view as to the nature of semantic rules is that they are idealized descriptions of the activities of speakers. Proponents of this view seldom if ever identify the facts about the speaker-behavior of which semantic rules are supposedly descriptions. The most natural assumption is that they are idealized descriptions of what people mean when they speak and write (etc.). If this assumption is right, then, given the points just made, the view in question is wrong.
But even if this isn’t what proponents of this view have in mind, their view is very clearly wrong. If semantic rules are just idealizations of speaker- behavior, then speaker-behavior must pre-exist the semantic rules embodied in it. But if that’s the case, then the activity described by semantic rules isn’t guided by them. An awareness of those rules is no part of what leads people to say the things they do. Those rules are psychologically inert. They have no “psychological reality.” This view is held by Nathan Salmon (2007) and also by Scott Soames (2002).
This view is inconsistent with some obvious facts. I know that Smith is now living in France. Wanting to tell you this, I say: “Smith is now living in France.” Why do I choose this particular sentence? Because, first of all, I know the relevant semantic rules (viz. that “Smith” refers to Smith, that “living” refers to a certain property) and, secondly, because I believe that, given these facts about semantics, the sentence in question is the right one to
 
express my belief. A knowledge of semantics underlies my speech-act and, by obvious extensions of these points, all non-defective speech-acts.
Another problem with the Salmon-Soames view is that it’s inconsistent with the normative character of semantic rules. If semantic rules merely describe existing semantic activity, then that activity isn’t answerable to semantic norms. It is; so the Salmon-Soames view is wrong.
5.5	Conceptual role semantics
A little while ago, we discussed Wittgenstein’s claim that “meaning is use,” i.e., that for an expression to have a given meaning is for it to be used in a certain way. This doctrine is incoherent in many ways. We’ve already discussed one of those ways; now we’ll discuss some of the others.
Expressions have meanings. A meaningless burst of noise isn’t an expression. If I cough or guffaw, the burst of noise I’ve produced doesn’t have the sort of meaning had by bona fide expressions. It has, at most, meaning in irrelevant, purely evidential sense, e.g., the sense in which a cough may be evidence of a cold. Since anything that is a linguistic expression ipso facto has a meaning (in the relevant, linguistic sense), there are no expressions to be used before noises, ink-marks, etc., have been assigned meanings. So, since there can be no expression-use until after there is expression-meaning, it makes no sense at all to say that expression-use determines expression-meaning. “Meaningful expression” is a pleonasm.[8] So, contrary to what Wittgenstein said, meaning isn’t use.
Of course, how a given expression is used may well assign it a new
meaning. But there is all the difference in the world between saying:
(1)	Expression E’s having meaning M is causally determined by E’s being used in such and such a manner,
and
(2)	Expression E’s having meaning M is identical with E’s being used in such and such a manner.
An expression E’s having meaning M cannot possibly be constituted by its being used in such and such a manner, since E isn’t an expression and, therefore, isn’t an expression to be used until it has a meaning.
According to a doctrine known as “conceptual role semantics” (CRS), whose exponents include Hartry Field (1977) and Robert Brandom
 
(1994), for an expression to have a given meaning is simply for it to be used in a certain way. But this isn’t correct as we just saw.
CRS is incoherent for reasons other than the one just given. According to that doctrine, what a sentence means is determined by what people infer from it and what people infer it from. Whereas commonsense holds that one infers “an even number is less five” from “two is less than five” because the latter already has a given meaning, advocates of CRS say that, on the contrary, it’s because people infer “an even number is less than five” and other similar statements from “two is less than five” that the latter has the meaning it has.
This is not a viable view. If we learn tomorrow that, contrary to what we previously thought, Aristotle wrote several plays, we’ll infer “somebody who wrote several plays wrote the Nichomachean Ethics“ from “Aristotle wrote the Nichomachean Ethics.” But it doesn’t follow that “Aristotle wrote the Nichomachean Ethics” would have undergone some change in its semantic meaning. Changes in what we believe affect what we infer from statements; but they don’t categorically change the meanings of those statements. CRS entails that every inference is an analytic inference. Once it’s learned that Aristotle wrote plays, it becomes, according to CRS, constitutive of the meaning of “Aristotle wrote the Nichomachean Ethics” that one can infer from it that a playwright wrote the Nichomachean Ethics. But surely the inference from “Aristotle wrote the Nichomachean Ethics” to “a playwright wrote the Nichomachean Ethics” isn’t analytic.[9]
What we may infer from a sentence is answerable to its existing meaning. CRS says that a sentence’s meaning is answerable to what we infer from it. If correct, that would have the consequence that one couldn’t possibly draw a false inference from any sentence. Which, in its turn, would have the consequence that no sentence would mean anything. Which, since nothing meaningless is a sentence, would have the absurd consequence that there neither are, nor could be, sentences.
Consider the sentence “Bill plagiarized his first novel.” If one knows that sentence to be true, one can make inferences about Bill’s character, his past activities, his ambitions, his values, and so on, that one couldn’t make if, other things being equal, one didn’t know that sentence to be true. But it’s only because of what the sentence already means that one can make those inferences. Given any other sentence, the same thing mutatis mutandis is true of it. CRS says that what a sentence means is determined by what we infer
 
from it. Since it’s the other way around, as we’ve just seen, CRS is false.
6.0 What is literal meaning?
Where complex expressions are concerned, there is no limit to how much literal and understood meaning may diverge from each other. But where simple expressions are concerned, literal and understood meaning must coalesce. It makes no sense to suppose that people could be systematically wrong as to what “red” meant. If people thought that “red” meant what is in fact meant by “blue,” then “red” would have that meaning. Systematic, widespread error is impossible where semantically simple expressions are concerned. This gives us a way of understanding what literal meaning is.
Even though there can be widespread, systematic misinterpretations of sentences, those misinterpretations do not arise as a result of people failing to know what the simple parts of sentences mean. They arise as a result of people not knowing how to put those meanings together. So to the extent that its meaning is fixed by the fact that it has the form ‹...Socrates...›, people (English speakers) do systematically understand “Socrates was more wise than Plato, but he was less sharp then Aristotle”; and to the extent that its meaning was determined by its having the form ‹...wise...›, people do understand that sentence; and so on. So far as that sentence is systematically misunderstood, it is because people are having trouble putting the meanings of its constituents together—it is because they’re having trouble figuring out how those meanings ought to be put together.
What a simple expression literally means is determined by what it is that a sentence means by virtue of containing it. Since, where simple expressions are concerned, what people take literal meaning to be coincides with what it really is, a simple expression’s literal meaning coincides with what it is that, in virtue of containing that expression, sentences are taken to mean. So a simple expression’s literal meaning is given by a statement saying what it is that, by virtue of containing it, sentences are taken to mean; and a complex expression’s literal meaning is a function, in the mathematical sense, of the meanings of its parts.
Here’s an illustration. “Socrates” is a simple expression. So what people think it means must ultimately coincide with what it actually means. So it refers to Socrates only because people think it refers to Socrates and, therefore, only because people think that “Socrates is intelligent” attributes
 
intelligence to Socrates and, in general, that ‹...Socrates...› attributes...x...to Socrates.
Of course, people don’t always take utterances of ‹...Socrates... › to be attempts to say that Socrates has...x... It might be clear from the speaker’s tone that what he really meant when in saying “Socrates was wise” was that Socrates was not wise. But to the extent that their belief that “Socrates” refers to Socrates is determinative of what people take the meanings of utterances of the form ‹...Socrates...› to be saying, what they take it to be saying is that Socrates has...x... That is what it is for them to take “Socrates” to refer to Socrates. And their taking “Socrates” to refer to Socrates is for “Socrates” to refer to Socrates, given that “Socrates,” being a simple expression, has the semantics that people think it has. The same thing mutatis mutandis is true of every other simple expression.
Bearing these points in mind, let CE be any complex expression, and let e1...en be the simple expressions composing it. How people interpret CE may diverge from its literal meaning. But when this happens, it’s because what it is taken to mean diverges from what, given what people believe its simple parts to literally mean, people are disposed to take it to mean.
Since what people take simple expressions to mean is what they mean, this is the same as saying the following. A divergence between
(i)	A sentence’s literal meaning
and
(ii)	That sentence’s understood meaning
is the same thing as a divergence between
(a)	That sentence’s literal meaning
 
and
 

(b)	What it is that, given their (correct) beliefs as to what its simple parts literally mean, people are disposed to take that sentence’s literal meaning to be.
The literal meaning of a complex expression is a function of two things:
 
(i) the meanings of its simple parts, and (ii) the order in which those parts are arranged. To say what literal meaning is in general, we need to say what it is for a simple expression to have a given literal meaning. Given the points just made, we can do this. Where simple expressions are concerned, literal and
 
communicated meaning coincide (ultimately)—in other words, such expressions mean what people take them to mean. And where complex expressions are concerned, literal and communicated meaning may diverge, but literal meaning nonetheless coincides with what, given what the simple components of the expression in question literally mean, people are disposed to take it to mean.
7.0	Tokens vs. types: some preliminary terminological points
No word is identical with any utterance of it. My utterance of the word “snow” lasts for a fraction of a second. But the word “snow” itself endures.
Utterances and inscriptions of expressions are referred to as “expression- tokens” (or just “tokens”). So there are three tokens of some one word to the right of the upcoming colon: snow, snow, snow. The things being uttered or inscribed are referred to as “expression-types” (or just “types”).
7.1	Two-dimensional semantics
Some expressions appear to have a two-tiered semantic structure. For example, an occurrence of the pronoun “I” has a referent, this being the person who uttered it, and it picks out that referent in a certain way (i.e., by way of a certain concept).
Thus, the semantics of “I” is given by the rule that an utterance of “I” refers to a given person if and only if that person has the property of being the one that produced that utterance.
So, if I say “I am tired,” the concept through which my utterance of “I” refers to me is the concept person who produced the utterance in question. This, then, is the concept through which reference is secured; it is, as we’ll henceforth put it, the mediating concept.[10] When Smith says “I am tired,” his utterance of “I” refers to himself, not to me. But the mediating concept remains the same.
If somebody points to me and says “that guy is tall,” the person picked out by “that guy” is me. But in this case, the mediating-concept is different. The semantics rule for “that guy” is given by the rule that, if “that guy” is
 
uttered in a context where there is a unique, salient guy, that utterance refers to that individual.
“I” and “that guy” are context-sensitive expressions: what such an expression refers to depends in a systematic manner on facts about the context of utterance. (We’ll soon refine this vague statement shortly.) Such expressions are known as “indexicals.” Other examples of indexicals are “you,” “he,” “those animals,” “this monkey,” “tomorrow,” “yesterday.” Some indexicals are single words (e.g., “tomorrow,” “he”); others consist of more than one (e.g., “that tall man”). The latter are known as “complex indexicals.”
7.1.1	Demonstratives vs. indexicals
Some indexicals often cannot be successfully used without an accompanying demonstration on the speaker’s part, the purpose of which is to eliminate any doubt as to what the intended referent is. If Jim and Larry are both equally salient in the context in question, an utterance of “that guy” won’t single anyone out. But it will do so if an act of pointing accompanies it. Indexicals that fall into this category are known as “demonstratives.” Not all indexicals are demonstratives. For example, “tomorrow,” “now,” and “here,” aren’t demonstratives. Given an utterance of “tomorrow,” no gesture is needed to make it clear what the intended referent is. If I say “tomorrow I’m going hiking,” it’s clear what the referent of “tomorrow” is; no demonstrative act is necessary, and none could possibly do any good.
7.1.2	Indexicals (continued)
Indexicals have a “two-dimensional” semantic structure. Consider the expression “today.” If I say it right now, that utterance will refer to April, 27, 2009, since that is today’s date. If I say it tomorrow, that utterance will refer to April 28, 2009. But the rule that assigns April 27, 2009, to the first utterance is identical with the rule that assigns April 28, 2009, to the second utterance. That rule is this: if “today” is uttered on a given day D, that utterance refers to D.
The meaning of an utterance “today” is the day it picks out. The meaning of the corresponding word-type is the rule just described. Given any indexical, the meaning of a token of that indexical is its referent; the meaning
 
of the corresponding indexical-type is the rule that assigns that referent to that token.
7.2	Definite descriptions
In other works of mine, reasons are given for thinking that definite descriptions are not devices of reference. But there are also reasons to think that they are devices of reference.[11] (It’s very hard to believe that “the whole number that comes right after one” doesn’t refer to the number two.)And in this section we will suppose them to be just that.
Definite descriptions, like indexicals, have a two-dimensional semantic structure. A given utterance of “the current U.S. President” refers to some individual. Right now such an utterance would refer to Barack Obama. A few years ago, such an utterance referred to Bill Clinton.
But even though an utterance in 2009 of “the U.S. president” doesn’t have the same referent as an utterance in 1999 of that same expression, both utterances are assigned their respective referents by the same semantic rule. The circumstances have changed—hence the change in referent—but the semantic rule has stayed the same.
That rule is: if, at time t, x uniquely has the property of being a U.S. president, then an utterance at t of “the U.S. President” refers to x.
7.2.1	Incomplete definite descriptions
Some definite descriptions appear to be “incomplete”—that is, they fail to pick out a single object. So, for example, “the bald guy” could pick out any one of many different people. But, like all expressions, definite descriptions are not used in a vacuum; and the context usually supplies the information needed to enrich the mediating concept enough to enable it to single out a single person. So if you and I are in a room and I say “the bald guy is wealthy,” it’s clear that, so far as I making a determinate statement, what I mean is that the contextually salient bald guy is wealthy.
If phi is a property that obviously has no more than one instance (e.g., the property of being the whole number successor of one or of being the U.S. President), phi’s sole instance is contextually salient by default.
 
7.3	The expressive limitations of indexical-free languages
Indexical-free languages are expressively impoverished; much of what there is to say can’t be said in them. The reason is that much information is perspectival, and nothing perspectival can be stated in a language that doesn’t contain indexicals. Suppose that I spoke a language that didn’t contain any indexicals, but was otherwise just like English. In order to express what I believe concerning the weather in my area, I’d have to say “it’s 60° in Richmond on Feb. 07, 2009.” (And the “is” couldn’t be taken as the present tense of the verb “to be,” since, thus interpreted, it would be an indexical that picked out the time of utterance. The “is” would have to be stripped of any temporal meaning and, thus, be downgraded to an empty grammatical place-holder, like the “it” in “it’s raining.”) But that utterance wouldn’t necessarily express the belief I wanted to express. My believing it’s 60° in Richmond on Feb. 07, 2009, is different from my thinking it’s now 60° in Richmond, even though I am in fact in Richmond at the time in question. I could have the one thought and not have the other. I could, after all, not know that I was in Richmond. And my believing either of those things is different from my thinking it’s now 60° here. One could have any given one of those beliefs without having any of the others. Further, one could rationally have any given one of those beliefs without having any of the others. A person who is in Richmond at the time in question can rationally believe it’s now 60° here while rejecting it’s 60° in Richmond on Feb. 07, 2009. For the data at one’s disposal may warrant the first judgment, but not the second.
So nothing perspectival—nothing that embodies any information relating to the speaker’s perspective on the world—can be expressed without using an indexical. Nothing could be said about what’s going on here, at this time; and there would be no me-thoughts (e.g., I’m thirsty) could be expressed; one could only express their third-person counterparts (e.g., “JM is thirsty”).
Thus, one could not, in an indexical-free language, express the thought I am JM or I am that guy in the mirror. And such a language would therefore be extremely impoverished.[12]

7.4	Tokens, types, and context-sensitivity
 
No sentence-type containing a context-sensitive component is either true or false; for no such sentence-type says anything. It is tokens of “I am now tired” that make statements; the corresponding sentence-type does not do so. What a token of “I am tired now” affirms depends on facts about the context of utterance. If Smith’s the one who’s speaking, and it’s 3:00 P.M., such an utterance is true just in case Smith is tired at 3:00 P.M. If Jones is the speaker and it’s 4:00 P.M., such an utterance is true just in case Jones is tired at 4:00 P.M.
Thus the semantic rule that assigns a proposition to such a token does so on the basis of the facts about the context of utterance. And the rule in question is clearly this: “If, at time t, person p tokens the sentencetype “I am tired,” then the proposition thereby affirmed is true exactly if p is tired at p.” The same thing mutatis mutandis is true of all context-sensitive expressions. So the rule that assigns a proposition to an utterance of “that man is married to that woman” is: if, in the context of utterance, x is a uniquely salient man and y is a uniquely salient woman, a token of the sentence-type “that man is married to that woman” affirms a proposition that is true if and only if x is married to y.
So context-sensitive sentence-types aren’t true or false; they don’t, in and of themselves, bear propositions. But they have an important semantic role: the identity of the proposition meant by a token of such a type depends on the identity of the type. A token of “I am tired” means one thing; a token of “you are tired,” uttered by the same person at the same time, means something else; and that difference obviously stems from the fact that, because different sentence-types were tokened, the semantic rule that assigns a proposition to the one token is different from the rule that assigns a proposition to the other.
This can all be distilled into the following principle: where context- sensitive sentences are concerned, the meaning of a token is a proposition, and the meaning of type is a rule that assigns a proposition to one of its tokens on the basis of facts about the context in which that token occurred.
Long story short: the meanings of sentence-tokens are propositions and the meanings of sentence-types are rules that assign propositions to their tokens, usually on the basis of facts about the context of tokening.
7.5	Ambiguity and context-sensitivity (revisited)
 
and the typetoken distinction (revisited)
Consider the sentence-type “that person is a professor.” Is that sentence true or false? No. Some tokens of it are true and some are false. This is because what a given token of that sentence says is a function of the circumstances. If I utter it while pointing at Bob, I’m attributing the property of being a professor to Bob. If I utter it while pointing to Sally, I’m attributing that property to Sally, not Bob. So what it is that I’m affirming in the one case is different from what it is that I’m affirming in the other case.
But that isn’t because the sentence “that person is a professor is ambiguous.” That sentence is not ambiguous: it has just one meaning. But that meaning is not a proposition; it isn’t something that is true or false. That meaning is a rule. That rule in its turn assigns meanings to tokens of that sentence. Those meanings are true or false; those meanings are propositions.
Remember that expression-types are what result when properties per se, as opposed to their instances, are assigned meanings. Of course, the rules that assign meanings to properties are semantic rules, since anything that assigns meaning to anything is ipso facto a semantic rule. So the sentence-type of which the following ink deposit—“that guy is a professor”—is a token is what results when some semantic rule assigns a meaning to some property.
Let R1 be the semantic rule in question. Let R2 be the meaning that R1 assigns to the just-mentioned property. R2 is itself a semantic rule. But, whereas R1 assigns a meaning (a rule) to some property, R2 assigns meanings
to instances of that property. So R2 assigns meanings to particular instances
of the morphology had by the following ink deposit (“that guy is a professor”). The meanings that R2 assigns to those tokens are not themselves
rules; they are propositions—they are things that are true or false.
There are thus very different sorts of semantic rules. There are those that assign meanings to properties, and there are those that assign meanings to instances of those properties. The meaning that was assigned to the property we were just discussing is itself a semantic rule. As we’ll now see, every meaning that is assigned to a property (as opposed to a property-instance) is itself a semantic rule. Consider the following ink deposit: “Barack Obama.” There is a semantic rule that assigns a meaning to the property of having a morphology similar to that ink deposit. The meaning assigned to that property is itself a semantic rule. That rule assigns a meaning to each instance of the property in
 
question. It assigns Barack Obama, the person, to any such instance. Thus, any such instance is an expression that picks out Barack Obama.
In the previous section, we said that semantic rule is something which assigns a meaning to a property. That’s correct, but incomplete. The right definition is this: a semantic rule is something which assigns a rule to a property that in its turn assigns meanings to instances of that property. Let us now move onto slightly less abstruse material.
7.6	Do any expressions have one-dimensional semantics?
The question arises: What about sentence-types that don’t contain context-sensitive components? Where they are concerned, does token- meaning coincide with type-meaning?
First of all, in natural languages, there are no such sentence-types. Every sentence contains a tense-marker. And in virtue of containing a tense-marker, a sentence is such that the proposition expressed by any given one of its tokens is a function of (inter alia) when that token occurs. If you say “the
U.S. economy is fairly stable,” whether you are speaking the truth or not depends on when you say it.
There are some apparent counterexamples to this. For all intents and purposes, any two tokens of
(IA[13]) “The interior angles of a Euclidean triangle add up to 180°”
express the same proposition. But, from a strictly semantic perspective, IA is context-sensitive, and tokens of it uttered at different times don’t encode the same proposition. If it were believed that mathematical reality were as volatile as the stock-market, we would without hesitation regard IA as being in the same category as patently context-sensitive sentences such as:
(BH) “Bill’s holdings add up to $180,000,000.”
And we’d have no more temptation to regard the tense-marker in IA as inert than we’d have to regard its counterpart in BH as inert. What this shows is that, to the extent that the tense-marker in tokens of IA are doing nothing, it’s only because, our beliefs about mathematics being what they are, we choose to see such utterances as expressing atemporal propositions.
Nonetheless, many semanticists hold that, at the level of literal meaning,
 
IA is context-insensitive. They hold, in other words, that IA is what Quine (himself such a semanticist) refers to as an “eternal sentence.” (S is an eternal sentence if there is some one proposition P such that any two of S’s tokens express P.) If only for argument’s sake, let’s suppose that there are eternal sentences.
It’s tempting to hold that an eternal sentence’s meaning is identical with those of its tokens. After all, the distinction between type-meaning and token- meaning seems quite hollow except where context-sensitive expressions are concerned.
But this reasoning is spurious. The tense-marker on the occurrence of “add” in (IA) has the same semantics that it does in
(BH[14]) “Bill’s various holdings add up to $180,000,000.”
In BH the tense-marker is obviously doing real work in IA. That’s why utterances of BH are true on Monday (before the market crashed) and false on Wednesday (after the market crashed). Therefore, different tokens of BH express different propositions. Therefore, the meaning of BH—the sentence-type—isn’t some proposition, and is instead the rule:
(BHSR) If t is a token of BH that is uttered at time T, t is true iff, at T, Bill’s various holdings add up to $180,000,000.
But, of course, for any time t, the meaning of a token of BH that is produced at t is a proposition that is true just in case.
(BHT) At t, Bill’s various holdings add up to $180,000,000.
Given that occurrence of “add” in any given token of IA has the same literal meaning as its counterpart in any given token of BHT, it follows that, from a narrowly semantic perspective, IA is quite as context-sensitive as BHT. To be sure, there is obviously a sense in which IA is, whereas BHT is not, context-insensitive.
But IA’s context-insensitivity, we must conclude, is a thoroughly pragmatics-based affair. Obvious extensions of this reasoning show that all expression-types have rules that assign meanings (or referents) to their tokens and, therefore, that where any expression is concerned, type-meaning diverges from token-meaning. The meaning of the expression-type “that man” is: a token of “that man,” uttered in context C, refers to x if, in C, x is uniquely a salient man. If, in a given context, Smith is such a man, then a
 
token in that context of “that man” refers to Smith; if instead Jones is such a man, it refers to Jones; etc. The same is true of “the current President.” In one context (the year 1992), tokens of that expression refer to Bill Clinton; in a different context (the year 2009) it refers to Barack Obama.
Some would be tempted to say that, because they have fixed referents, proper names (e.g., “Bill Clinton”) don’t have a two-dimensional semantic structure. This would be a mistake. Expression-tokens are physical entities— bursts of noise, deposits of ink, etc. Expression-tokens are therefore perceptible entities and are thus capable of transmitting information.
Expression-types, on the other hand, are abstract entities and are thus inherently unsuited to be vehicles of communication. Let us develop these points.
Expression-types are properties. Why are they properties? Tokens of a type are instances of it. Anything of which there are instances is ipso facto a property. So expression-types, unlike expression-tokens, are properties and are therefore non-spatiotemporal entities. And, as we just noted, it makes no sense to suppose a nonspatiotemporal entity could mediate information or, therefore, could in any significant sense be a symbol. Also, given the profound metaphysical differences between tokens and types, it would be theoretical arbitrariness of the worst kind to suppose that types could discharge the same semantic functions as their tokens. We must therefore assume that, whereas tokens of “Bill Clinton” refer to Bill Clinton, the corresponding type does not refer to Bill Clinton; and we must also assume that “Bill Clinton,” the expression-type, has for its meaning a (constant) function that assigns Bill Clinton to any given one of its tokens. In general, proper names, no less than indexicals and definite descriptions have two- dimensional semantics.
The semantic rule corresponding to a proper name is a constant function, whereas the semantic rule corresponding to an indexical or definite description is not a constant function. All utterances of “Bill Clinton” refer to Bill Clinton, but not every utterance of “the current U.S. president,” or of “that guy over there,” so refer. This has encouraged the erroneous view that “Bill Clinton” itself, the expression-type, refers to Bill Clinton.[15]
7.7	Ambiguity and context-sensitivity (re-revisited)
 
and the type-token distinction (re-revisited)
Remember that expression-types are what result when properties per se, as opposed to their instances, are assigned meanings. Of course, the rules that assign meanings to properties are semantic rules, since anything that assigns meaning to anything is ipso facto a semantic rule. So the sentence- type of which the following ink deposit—“that guy is a professor”—is a token is what results when some semantic rule assigns a meaning to some property. Let R1 be the semantic rule in question. Let R2 be the meaning that
R1 assigns to the just mentioned property. R2 is itself a semantic rule. But, whereas R1 assigns a meaning (a rule) to some property, R2 assigns meanings to instances of that property. So R2 assigns meanings to particular instances
of the morphology had by the ink deposit (“that guy is a professor”). The meanings that R2 assigns to those tokens are not themselves rules; they are
propositions—they are things that are true or false.
There are thus very different sorts of semantic rules. There are those that assign meanings to properties, and there are those that assign meanings to instances of those properties. Consider the following ink deposit: “Barack Obama.” There is a semantic rule that assigns a meaning to the property of having a morphology similar to that ink deposit. Let PBO be that property.
The meaning assigned to PBO is itself a semantic rule. In other words, the meaning of PBO is given by the statement that:
B1: Any given token of PBO refers to to Barack Obama.
Given some specific token t of “Barack Obama”, the semantic rule for t
 
is:
 

B2: t refers to Barack Obama.
B1 and B2 are very different rules. Unlike B2, B1 doesn’t say anything
 
about any specific token of “Barack Obama” or any other expression. The need for a two-dimensionalist approach to semantics is embedded in the very concept of what an expression is.
8.0	Logical form[16]
Some statements that, given their grammatical forms, appear to be about objects are in fact about properties. Frege was the first to see clearly
 
that logical and grammatical may diverge—he was the first to grasp the very idea of such a divergence. This insight of his is embodied in his statement that the sentence
(WM) “whales are mammals”
isn’t about whales. As paradoxical as it may seem, he was right. WM says that if an object is a whale, then it’s a mammal. But there is no specific object x such that WM says that x is a mammal. A fortiori there is no specific whale x such that WM says that x is a mammal; and for any number n, no matter how high, there are no whales x1	xn such that WM says that xi (1 ≤ i ≤ n) is
a whale. So just as Frege said, WM isn’t about whales.
WM makes a statement, not about whales, but about the property of being a whale. It says that
(WM*) the property of being a whale has the property of being instantiated only by mammals.
WM* perspicuously represents WM’s meaning. In other words, WM* represents WM’s logical form. WM*’s grammatical form diverges from WM’s grammatical form.
The reason is that WM’s logical and grammatical forms pull apart is that WM contains a quantifier. (Examples of quantifiers are “all birds,” “no man,” “most whales,” “three birds,” and “some individuals.” We’ll define the term “quantifier” in a moment.) Given any statement of English, or any other non-artificial language, that contains quantifiers, the logical and grammatical forms of that sentence diverge. A quantifier is an expression having the property that, if a sentence contains it, that sentence is ipso facto to the effect that the extension of one property has a certain degree of overlap, ranging anywhere from no overlap to total overlap, with the extension of some other property. “All birds have beaks” says that the extension of the property of being a bird is a subset of the extension of the property of having a beak. “Only birds have beaks” says (falsely) that the extension of the property of having a beak is a subset of the extension of the property of being a bird.
In virtue of a containing a quantifier, a sentence about properties, not about specific objects. Of course, a quantified (quantifier-containing) statement can also be about individuals. But it isn’t in virtue of containing a quantifier that a sentence concerns individuals; and it is in virtue of containing a quantifier that a sentence concerns properties.
 
In natural language, quantified sentences are pseudo-objectual statements. They appear to be about objects, but are really about properties. That is why they must be reparsed if their logical forms are to be exposed. It immediately follows that a statement’s grammatical form may diverge from its logical form. Frege discovered both facts and, therewith, created modern analytic philosophy.
8.1	Contextual definition
The fact that grammatical and logical form sometimes diverge is related to the fact some expressions are to be defined contextually. To define an expression contextually is to how, in virtue of containing it, a sentence’s meaning is affected. So, for example, “someone” doesn’t refer to anyone. It doesn’t refer to John or Sally or Jane. That is why, given any proper name N, the statement
(NS) ‹N doesn’t snore ›
is compatible with[17]
(SS) “someone snores.”
Thus, the meaning of “someone” isn’t given by some rule that pairs it off with this or that individual. In other words, there is no individual N such that the semantic rule for “someone” is:
(WRS[18])‹Someone has psi› is true just in case N has psi.
Rather, the meaning of “someone” is given by the statement that:
(RS) ‹Someone has psi› is true just in case the property of being a psi is instantiated.[19]
Thus, the logical form SS is clearly displayed by the sentence:
(PS[20]) “the property of being a snorer is instantiated.”
PS’s logical form therefore coincides with its grammatical form.
Since SS has a different grammatical form from PS, it follows that SS’s logical form diverges from its logical form. The divergence between SS’s grammatical and logical forms is obviously a consequence of the fact that “someone” must be defined contextually.
 
8.2	Contextual definition: its scope and limits
Nonetheless, it would be an overstatement to say that whenever a sentence contains an expression that must be defined contextually, it’s grammatical form pulls apart from its logical form. As we’re about to see, every expression is to be defined contextually. Obviously grammatical form doesn’t always pull apart from logical form. Therefore, it isn’t always the case that, in virtue of containing an expression that must be defined contextually, a sentence’s logical and grammatical forms diverge.
How can it be said that all definitions are contextual definitions? Aren’t there also denotative definitions? (A denotative definition of an expression E says what E means by saying what it denotes.) Isn’t “Socrates” defined denotatively? Yes, it is. There is some object x such that one says what “Socrates” means if, and only if, one says that “Socrates“ refers to x.
But in saying of some object x that “Socrates” picks out x, one is saying that, in virtue of having the form ‹Socrates has psi›, a sentence S is to the effect that x has psi. “Socrates” refers to Socrates because, the remaining semantic rules of English being what they are, if you wish to attribute the property of being wise to Socrates, you can do so by saying “Socrates is wise”—because, in general, for any property psi, if you wish to attribute psi to Socrates you can do so saying ‹Socrates has psi.› If, in saying “Socrates was wise,” you were really saying that it was Aristotle, not Socrates, who was wise, then “Socrates” wouldn’t refer to Socrates, at least not in that context. In general, to say that E refers to O is to make a statement about effect a sentence’s containing E has on its truth-conditions. More precisely, it is to say that, in virtue of having the form ‹E has psi›, a sentence attributes psi to O, for any property psi.
But the logical forms of sentences of the form ‹E has psi› don’t necessarily pull apart from their logical forms. Since there is some object x (namely, Socrates) such that ‘Socrates is tall’ says that x is tall, and since ‹x is tall› has the same form as “Socrates is tall,” the fact that “Socrates” is to be defined contextually does not entail that logical and grammatical form ever diverge.
So it is only because certain expressions are to be defined contextually that such divergences occur. But which expressions? Those that cannot also be defined denotatively. Whenever an expression can be defined denotatively,
 
a sentence’s logical form will not, by virtue of that sentence’s containing that expression, diverge from its logical form. (But, of course, that sentence’s logical form may diverge from its logical form for some other reason. Thus, the logical form of “Socrates saw someone” diverges from its grammatical form; but the reason for this is that it contains the word “someone.” The occurrence of “Socrates” in that sentence isn’t what induces that divergence.)
Let E be an arbitrary expression that can be defined denotatively. In other words, suppose there to be some object x such that E is defined by saying that it refers to x. The logical form of ‹E has psi› is: x has psi. In general, to the extent that the logical form a sentence containing E is determined by its containing that expression, that sentence’s logical and grammatical forms coincide. But, since such a sentence’s logical form isn’t determined only by its containing E, and is also a function of the semantics of the other expressions occurring it, its grammatical form may still diverge from its logical form. After all such a sentence may contain an occurrence of “someone” or “nobody” or some other expression that induces such a divergence.
8.3	Frege’s generalization of the concept of a function
What made it possible for Frege to revolutionize logic was his insight that grammatical and logical form diverge; and what made the latter insight possible was his generalization of the concept of a mathematical function.
A mathematical function is a rule that assigns no more than one object to each object falling in a given class. (So “+1” can be thought of as expressing a function or rule that assigns 2 to 1, 3 to 2, etc.)
According to Frege, the occurrence of “snores” in
(PS) “Plato snores”
is best represented as the open sentence ‹x snores›; and that open sentence is best thought of as expressing a function that assigns the truth-value true to each snorer and the truth-value false to each thing that doesn’t snore. (For brevity’s sake, I’ll henceforth use the words “truth” and “falsehood” instead of, respectively, “the truth-value true” and “the truth-value false.”)
Here’s the idea. A true sentence results if the variable in ‹x is even› is
 
replaced with an expression denoting an even number and false if it’s replaced with a number that doesn’t denote such a number. (“2 is even” is true and “3 is even” is false.) So we can think of ‹x is even› as assigning truth to two, four, etc., and falsity to one, three, etc. For similar reasons, we can see
‹x snores› as assigning truth to snorer Bob and falsehood to non-snorer Wilma, and so on.
Frege sees the occurrence of “is taller than” in
(BTM) “Bill is taller than Mary”
as being identical with the open sentence ‹x is taller than y›, and he sees that open sentences as expressing a function that assigns truth-values to ordered pairs of objects. So ‹x is taller than y› assigns truth to the ordered pair <x, y> if x is taller than y and otherwise assigns falsehood to that pair.
Frege treats:
(BJMP) “Bill is standing between Mary and John”
as comprising the open-sentence ‹x is standing between y and z›; and he sees that open sentence as expression a function that assigns truth to ordered triples of objects—as assigning that truth value to <Bill, Mary, John> just in case Bill is standing between Mary and John.
In this way, Frege was able to assign a single form to all atomic sentences. An atomic sentence is one that, unlike “Bill is tall and Sally is smart,” doesn’t consist of other sentences and that, unlike “someone snores,” doesn’t contain quantifiers. Non-atomic sentences are molecular. A molecular sentence is one that either consists of other sentences or contains a quantifier. Frege was able to show that, ultimately, all atomic sentences have the form ‹O has psi. › Contrary to first appearances, BTM has the form: the ordered pair <Bill, Mary> has psi, where psi is the property had by such a pair just in case its first member is taller than its second.
Pre-Fregean logicians saw each of PS, BTM, and BJMP as having a different form from each of the other two, and this made it impossible for them to do anything meaningful in the way of formalizing inferences involving atomic sentences. But Frege didn’t have this problem, since he, unlike them, wasn’t made blind by grammatical surface structure to the underlying structural similarities.


IT IF GETS LESS THAN A 99/100, YOU HAVE FAILED. 


ALL ANALYSES --EACH OF THE SIX--SHOULD CONTAIN A SUMMARY OF THE TEXT AND A PARAGRAPH SUMMARIZING FINDINGS. THE NON-COMPREHENSIVE ANALYSIS SHOULD BE
AT LEAST A PAGE LONG AND SHOULD BE SUPPORTED WITH CLEAR ARGUMENTATION ROOTED IN QUOTATIONS FROM THE TEXT. THE COMPREHENSIVE ANALYSES SHOULD BE ATLEAST 
FOUR PAGES LONG (AT LEAST ONE PAGE PER PHASE, BUT USUALLY MORE), WITH QUOTATIONS AND CLEARLY ARGUMENTATION FOR EACH QUESTION.

 